{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-\\.]+"},"docs":[{"location":"","text":"What is Sherlock? # Sherlock is a shared computing cluster available for use by all Stanford Faculty members and their research teams, for sponsored or departmental faculty research. All research teams on Sherlock have access to a base set of managed computing resources, GPU-based servers, and a multi-petabyte, high-performance parallel file system for short-term storage. Faculty can supplement these shared nodes by purchasing additional servers, and become Sherlock owners. By investing in the cluster, PI groups not only receive exclusive access to the nodes they purchase, but also get access to all of the other owner compute nodes when they're not in use, thus giving them access to the whole breadth of Sherlock resources. Why should I use Sherlock? # Using Sherlock for your work provides many advantages over individual solutions: hosted in an on-premises, state-of-the-art datacenter dedicated to research computing systems, the Sherlock cluster is powered and cooled by installations that are optimized for scientific computing. On Sherlock, simulations and workloads benefit from performance levels that only large scale HPC systems can offer: high-performance I/O infrastructure, petabytes of storage, large variety of hardware configurations, GPU accelerators, centralized system administration and management provided by the Stanford Research Computing Center (SRCC). Such features are not easily accessible at the departmental level, and often require both significant initial investments and recurring costs. Joining Sherlock allows researchers and Faculty members to avoid those costs and benefit from economies of scale, as well as to access larger, professionally managed computing resources that what would not be available on an individual or even departmental basis. How much does it cost? # Sherlock is free to use for anyone doing sponsored research at Stanford. Any Faculty member can request access for research purposes, and get an account with a base storage allocation and unlimited compute time on the global, shared pool of resources. Stanford Research Computing provides faculty with the opportunity to purchase from a catalog a recommended compute node configurations , for the use of their research teams. Using a traditional compute cluster condominium model, participating faculty and their teams get priority access to the resources they purchase. When those resources are idle, other \"owners\" can use them, until the purchasing owner wants to use them. When this happens, those other owners jobs are re-queued to free up resources. Participating owner PIs also have shared access to the original base Sherlock nodes, along with everyone else. How big is it? # Quite big! It's actually difficult to give a definitive answer, as Sherlock is constantly evolving and expanding with new hardware additions. As of May 2021, Sherlock features over 5,200 CPU cores available to all researchers, and more than 37,700 additional CPU cores available to Sherlock owners, faculty who have augmented the cluster with their own purchases. With a computing power over 3.3 Petaflops, Sherlock would have its place in the Top500 list of the 500 most powerful computer systems in the world. For more details about Sherlock size and technical specifications, please refer to the tech specs section of the documentation. And for even more numbers and figures, see the Sherlock facts page. OK, I'm sold, how do I start? # You can request an account right now, take a look at the documentation , and drop us an email if you have any questions. I want my own nodes! # If you're interested in becoming an owner on Sherlock, and benefit from all the advantages associated, please take a look at the catalog of configurations, feel free to use the ordering form to submit your request, and we'll get back to you.","title":"Sherlock"},{"location":"#what-is-sherlock","text":"Sherlock is a shared computing cluster available for use by all Stanford Faculty members and their research teams, for sponsored or departmental faculty research. All research teams on Sherlock have access to a base set of managed computing resources, GPU-based servers, and a multi-petabyte, high-performance parallel file system for short-term storage. Faculty can supplement these shared nodes by purchasing additional servers, and become Sherlock owners. By investing in the cluster, PI groups not only receive exclusive access to the nodes they purchase, but also get access to all of the other owner compute nodes when they're not in use, thus giving them access to the whole breadth of Sherlock resources.","title":"What is Sherlock?"},{"location":"#why-should-i-use-sherlock","text":"Using Sherlock for your work provides many advantages over individual solutions: hosted in an on-premises, state-of-the-art datacenter dedicated to research computing systems, the Sherlock cluster is powered and cooled by installations that are optimized for scientific computing. On Sherlock, simulations and workloads benefit from performance levels that only large scale HPC systems can offer: high-performance I/O infrastructure, petabytes of storage, large variety of hardware configurations, GPU accelerators, centralized system administration and management provided by the Stanford Research Computing Center (SRCC). Such features are not easily accessible at the departmental level, and often require both significant initial investments and recurring costs. Joining Sherlock allows researchers and Faculty members to avoid those costs and benefit from economies of scale, as well as to access larger, professionally managed computing resources that what would not be available on an individual or even departmental basis.","title":"Why should I use Sherlock?"},{"location":"#how-much-does-it-cost","text":"Sherlock is free to use for anyone doing sponsored research at Stanford. Any Faculty member can request access for research purposes, and get an account with a base storage allocation and unlimited compute time on the global, shared pool of resources. Stanford Research Computing provides faculty with the opportunity to purchase from a catalog a recommended compute node configurations , for the use of their research teams. Using a traditional compute cluster condominium model, participating faculty and their teams get priority access to the resources they purchase. When those resources are idle, other \"owners\" can use them, until the purchasing owner wants to use them. When this happens, those other owners jobs are re-queued to free up resources. Participating owner PIs also have shared access to the original base Sherlock nodes, along with everyone else.","title":"How much does it cost?"},{"location":"#how-big-is-it","text":"Quite big! It's actually difficult to give a definitive answer, as Sherlock is constantly evolving and expanding with new hardware additions. As of May 2021, Sherlock features over 5,200 CPU cores available to all researchers, and more than 37,700 additional CPU cores available to Sherlock owners, faculty who have augmented the cluster with their own purchases. With a computing power over 3.3 Petaflops, Sherlock would have its place in the Top500 list of the 500 most powerful computer systems in the world. For more details about Sherlock size and technical specifications, please refer to the tech specs section of the documentation. And for even more numbers and figures, see the Sherlock facts page.","title":"How big is it?"},{"location":"#ok-im-sold-how-do-i-start","text":"You can request an account right now, take a look at the documentation , and drop us an email if you have any questions.","title":"OK, I'm sold, how do I start?"},{"location":"#i-want-my-own-nodes","text":"If you're interested in becoming an owner on Sherlock, and benefit from all the advantages associated, please take a look at the catalog of configurations, feel free to use the ordering form to submit your request, and we'll get back to you.","title":"I want my own nodes!"},{"location":"docs/advanced-topics/connection/","text":"Advanced connection options # Login nodes # Sherlock login nodes are regrouped behind a single DNS alias: login.sherlock.stanford.edu . This alias provides a load-balanced login environment, and the assurance that you will be connected to the least loaded login node when you connect to Sherlock. If for any reason, you want to directly connect to a specific login node and bypass the automatic load-balanced dispatching of new connections (which we don't recommend ), you can use that login node's hostname explicitly. For instance: $ ssh <sunetid>@ln21.sherlock.stanford.edu This can be useful if you run long-standing processes on the login nodes, such as screen or tmux sessions. To find them back when you reconnect to Sherlock, you will indeed need to login to the same login node you started them on. The drawback is that by connecting to a specific login node, you will forfeit the load-balancing benefits, which could result in a crowded environment, or even in login errors in case that specific login node is unavailable. Authentication methods # Public-key authentication SSH public-key authentication is not supported on Sherlock. Password (recommended) # The recommended way to authenticate to Sherlock is to simply use your SUNet ID and password, as described in the Connecting page. Passwords are not stored on Sherlock. Sherlock login nodes will delegate password authentication to the University central Kerberos service . GSSAPI # For compatibility with previous generations of Sherlock, GSSAPI 1 authentication is still allowed, and could be considered a more convenient option, as this mechanism doesn't require entering your password for each connection. GSSAPI authentication relies on a token system, where users obtain Kerberos ticket-granting tickets, transmit them via SSH to the server they want to connect to, which will, in turn, verify their validity. That way, passwords are never stored locally, and never transit over the network. That's why Kerberos is usually considered the most secure method to authenticate. To connect using GSSAPI on Sherlock, you'll need to go through a few steps 2 : make sure the Kerberos user tools are installed on your local machine. You'll need the kinit (and optionally klist and kdestroy ) utilities. Please refer to your OS documentation to install them if required. download and install the Stanford krb5.conf file, which contains information about the Stanford Kerberos environment: $ sudo curl -o /etc/krb5.conf https://web.stanford.edu/dept/its/support/kerberos/dist/krb5.conf configure your SSH client, by modifying (or creating if it doesn't exist already) the .ssh/config file in your home directory on your local machine. Using a text editor, you can add the following lines to your ~/.ssh/config file (indentation is important): Host login.sherlock.stanford.edu GSSAPIDelegateCredentials yes GSSAPIAuthentication yes Once everything is in place (you only need to do this once), you'll be able to test that your Kerberos installation works by running kinit <sunetid>@stanford.edu . You should get a password prompt, and upon success, you'll be able to list your Kerberos credentials with the klist command: $ kinit kilian@stanford.edu Password for kilian@stanford.edu: $ klist Ticket cache: FILE:/tmp/krb5cc_215845_n4S4I6KgyM Default principal: kilian@stanford.edu Valid starting Expires Service principal 07 /28/17 17 :33:54 07 /29/17 18 :33:32 krbtgt/stanford.edu@stanford.edu renew until 08 /04/17 17 :33:32 Kerberos ticket expiration Kerberos tickets have a 25-hour lifetime. So you'll need to run the kinit command pretty much once a day to continue being able to authenticate to Sherlock. Please note that when your Kerberos ticket expire, existing Sherlock connections will not be interrupted. So you'll be able to keep connections open to Sherlock for several days without any issue. You're now ready to connect to Sherlock using GSSAPI. Simply SSH as usual: $ ssh <sunetid>@login.sherlock.stanford.edu and if everything goes well, you should directly see the two-factor (Duo) prompt, without having to enter your password. If you want to destroy your Kerberos ticket before its expiration, you can use the kdestroy command. SSH options # OpenSSH offers a variety of configuration options that you can use in ~/.ssh/config on your local computer. The following section describe some of the options you can use with Sherlock that may make connecting and transferring files more convenient. Avoiding multiple Duo prompts # In order to avoid getting a second-factor (Duo) prompt every time you want to open a new connection to Sherlock, you can take advantage of the multiplexing features provided by OpenSSH. Simply add the following lines to your ~/.ssh/config file on your local machine to activate the ControlMaster option. If you already have a Host login.sherlock.stanford.edu block in your configuration file, simply add the Control* option lines in the same block. Host login.sherlock.stanford.edu ControlMaster auto ControlPath ~/.ssh/%l%r@%h:%p It will allow SSH to re-use an existing connection to Sherlock each time you open a new session (create a new SSH connection), thus avoiding subsequent 2FA prompts once the initial connection is established. The slight disadvantage of this approach is that once you have a connection open to one of Sherlock's login nodes, all your subsequent connections will be using the same login node. This will somewhat defeat the purpose of the load-balancing mechanism used by the login nodes. Connection failure with unix_listener error If your connection fails with the following error message: unix_listener: \"...\" too long for Unix domain socket you're being hit by a macOS limitation, and you should replace the ControlPath line above by: ControlPath ~/.ssh/%C Connecting from abroad # VPN As a good security practice, we always recommend to use the Stanford VPN when connecting from untrusted networks. Access to Sherlock is not restricted to campus, meaning that you can connect to Sherlock from pretty much anywhere, including when traveling abroad. We don't restrict inbound SSH connections to any specific IP address range or geographical location, so you shouldn't have any issue to reach the login nodes from anywhere. Regarding two-step authentication, University IT provides alternate authentication options when phone service or Duo Mobile push notifications are not available. The Generic Security Service Application Program Interface (GSSAPI, also GSS-API) is an application programming interface for programs to access security services. It allows program to interact with security services such as Kerberos for user authentication. \u21a9 Those instructions should work on Linux and MacOs computers. For Windows , we recommend using the WSL, as described in the Prerequisites page. \u21a9","title":"Connection"},{"location":"docs/advanced-topics/connection/#advanced-connection-options","text":"","title":"Advanced connection options"},{"location":"docs/advanced-topics/connection/#login-nodes","text":"Sherlock login nodes are regrouped behind a single DNS alias: login.sherlock.stanford.edu . This alias provides a load-balanced login environment, and the assurance that you will be connected to the least loaded login node when you connect to Sherlock. If for any reason, you want to directly connect to a specific login node and bypass the automatic load-balanced dispatching of new connections (which we don't recommend ), you can use that login node's hostname explicitly. For instance: $ ssh <sunetid>@ln21.sherlock.stanford.edu This can be useful if you run long-standing processes on the login nodes, such as screen or tmux sessions. To find them back when you reconnect to Sherlock, you will indeed need to login to the same login node you started them on. The drawback is that by connecting to a specific login node, you will forfeit the load-balancing benefits, which could result in a crowded environment, or even in login errors in case that specific login node is unavailable.","title":"Login nodes"},{"location":"docs/advanced-topics/connection/#authentication-methods","text":"Public-key authentication SSH public-key authentication is not supported on Sherlock.","title":"Authentication methods"},{"location":"docs/advanced-topics/connection/#password-recommended","text":"The recommended way to authenticate to Sherlock is to simply use your SUNet ID and password, as described in the Connecting page. Passwords are not stored on Sherlock. Sherlock login nodes will delegate password authentication to the University central Kerberos service .","title":"Password (recommended)"},{"location":"docs/advanced-topics/connection/#gssapi","text":"For compatibility with previous generations of Sherlock, GSSAPI 1 authentication is still allowed, and could be considered a more convenient option, as this mechanism doesn't require entering your password for each connection. GSSAPI authentication relies on a token system, where users obtain Kerberos ticket-granting tickets, transmit them via SSH to the server they want to connect to, which will, in turn, verify their validity. That way, passwords are never stored locally, and never transit over the network. That's why Kerberos is usually considered the most secure method to authenticate. To connect using GSSAPI on Sherlock, you'll need to go through a few steps 2 : make sure the Kerberos user tools are installed on your local machine. You'll need the kinit (and optionally klist and kdestroy ) utilities. Please refer to your OS documentation to install them if required. download and install the Stanford krb5.conf file, which contains information about the Stanford Kerberos environment: $ sudo curl -o /etc/krb5.conf https://web.stanford.edu/dept/its/support/kerberos/dist/krb5.conf configure your SSH client, by modifying (or creating if it doesn't exist already) the .ssh/config file in your home directory on your local machine. Using a text editor, you can add the following lines to your ~/.ssh/config file (indentation is important): Host login.sherlock.stanford.edu GSSAPIDelegateCredentials yes GSSAPIAuthentication yes Once everything is in place (you only need to do this once), you'll be able to test that your Kerberos installation works by running kinit <sunetid>@stanford.edu . You should get a password prompt, and upon success, you'll be able to list your Kerberos credentials with the klist command: $ kinit kilian@stanford.edu Password for kilian@stanford.edu: $ klist Ticket cache: FILE:/tmp/krb5cc_215845_n4S4I6KgyM Default principal: kilian@stanford.edu Valid starting Expires Service principal 07 /28/17 17 :33:54 07 /29/17 18 :33:32 krbtgt/stanford.edu@stanford.edu renew until 08 /04/17 17 :33:32 Kerberos ticket expiration Kerberos tickets have a 25-hour lifetime. So you'll need to run the kinit command pretty much once a day to continue being able to authenticate to Sherlock. Please note that when your Kerberos ticket expire, existing Sherlock connections will not be interrupted. So you'll be able to keep connections open to Sherlock for several days without any issue. You're now ready to connect to Sherlock using GSSAPI. Simply SSH as usual: $ ssh <sunetid>@login.sherlock.stanford.edu and if everything goes well, you should directly see the two-factor (Duo) prompt, without having to enter your password. If you want to destroy your Kerberos ticket before its expiration, you can use the kdestroy command.","title":"GSSAPI"},{"location":"docs/advanced-topics/connection/#ssh-options","text":"OpenSSH offers a variety of configuration options that you can use in ~/.ssh/config on your local computer. The following section describe some of the options you can use with Sherlock that may make connecting and transferring files more convenient.","title":"SSH options"},{"location":"docs/advanced-topics/connection/#avoiding-multiple-duo-prompts","text":"In order to avoid getting a second-factor (Duo) prompt every time you want to open a new connection to Sherlock, you can take advantage of the multiplexing features provided by OpenSSH. Simply add the following lines to your ~/.ssh/config file on your local machine to activate the ControlMaster option. If you already have a Host login.sherlock.stanford.edu block in your configuration file, simply add the Control* option lines in the same block. Host login.sherlock.stanford.edu ControlMaster auto ControlPath ~/.ssh/%l%r@%h:%p It will allow SSH to re-use an existing connection to Sherlock each time you open a new session (create a new SSH connection), thus avoiding subsequent 2FA prompts once the initial connection is established. The slight disadvantage of this approach is that once you have a connection open to one of Sherlock's login nodes, all your subsequent connections will be using the same login node. This will somewhat defeat the purpose of the load-balancing mechanism used by the login nodes. Connection failure with unix_listener error If your connection fails with the following error message: unix_listener: \"...\" too long for Unix domain socket you're being hit by a macOS limitation, and you should replace the ControlPath line above by: ControlPath ~/.ssh/%C","title":"Avoiding multiple Duo prompts"},{"location":"docs/advanced-topics/connection/#connecting-from-abroad","text":"VPN As a good security practice, we always recommend to use the Stanford VPN when connecting from untrusted networks. Access to Sherlock is not restricted to campus, meaning that you can connect to Sherlock from pretty much anywhere, including when traveling abroad. We don't restrict inbound SSH connections to any specific IP address range or geographical location, so you shouldn't have any issue to reach the login nodes from anywhere. Regarding two-step authentication, University IT provides alternate authentication options when phone service or Duo Mobile push notifications are not available. The Generic Security Service Application Program Interface (GSSAPI, also GSS-API) is an application programming interface for programs to access security services. It allows program to interact with security services such as Kerberos for user authentication. \u21a9 Those instructions should work on Linux and MacOs computers. For Windows , we recommend using the WSL, as described in the Prerequisites page. \u21a9","title":"Connecting from abroad"},{"location":"docs/advanced-topics/job-management/","text":"Job submission limits # You may have encountered situations where your jobs get rejected at submission with errors like this: sbatch: error: MaxSubmitJobsPerAccount sbatch: error: MaxSubmitJobsPerUser There are a number of limits on Sherlock, that are put in place to guarantee that all of the users can have a fair access to resources and a smooth experience while using them. One of those limits is about the total number of jobs a single user (and a single group) can have in queue at any given time. This helps ensuring that the scheduler is able to continue operating in an optimal fashion, without being overloaded by a single user or group. Minimizing the number of jobs in queue # It's generally a good practice to try reducing the number of jobs submitted to the scheduler, and depending on your workflow, there are various approaches for this. One solution may be to pack more work within a single job, which could help in reducing the overall number of jobs you'll have to submit. Imagine you have a 100-task array job, where you run 1 app task per array item, which looks like this: #!/bin/bash #SBATCH --array=1-100 #SBATCH -n 1 ./app ${ SLURM_ARRAY_TASK_ID } This script would create 100 jobs in queue (even though they would all be regrouped under the same job array), each using 1 CPU to run 1 task. Instead of that 100-task array job, you can try something like this: #!/bin/bash #SBATCH --array=0-99:10 #SBATCH -n 10 for i in { 0 ..9 } ; do srun -n 1 ./app $(( SLURM_ARRAY_TASK_ID+i )) & done wait # important to make sure the job doesn't exit before the background tasks are done --array=1-100:10 will use job array indexes 0, 10, 20 ... 90 -n 10 will make sure each job can be subdivided in 10 1- CPU steps the for loop will launch 10 tasks, with indexes from SLURM_ARRAY_TASK_ID to SLURM_ARRAY_TASK_ID + 9 . This would submit a 10-task array job, each of them running 10 steps simultaneously, on the 10 CPUs that each of the job array item will be allocated. In the end, you'll have run the same number of app instances, but you'll have divided the number of jobs submitted by 10, and allow you to submit the same amount of work to the scheduler, while staying under the submission limits.","title":"Job management"},{"location":"docs/advanced-topics/job-management/#job-submission-limits","text":"You may have encountered situations where your jobs get rejected at submission with errors like this: sbatch: error: MaxSubmitJobsPerAccount sbatch: error: MaxSubmitJobsPerUser There are a number of limits on Sherlock, that are put in place to guarantee that all of the users can have a fair access to resources and a smooth experience while using them. One of those limits is about the total number of jobs a single user (and a single group) can have in queue at any given time. This helps ensuring that the scheduler is able to continue operating in an optimal fashion, without being overloaded by a single user or group.","title":"Job submission limits"},{"location":"docs/advanced-topics/job-management/#minimizing-the-number-of-jobs-in-queue","text":"It's generally a good practice to try reducing the number of jobs submitted to the scheduler, and depending on your workflow, there are various approaches for this. One solution may be to pack more work within a single job, which could help in reducing the overall number of jobs you'll have to submit. Imagine you have a 100-task array job, where you run 1 app task per array item, which looks like this: #!/bin/bash #SBATCH --array=1-100 #SBATCH -n 1 ./app ${ SLURM_ARRAY_TASK_ID } This script would create 100 jobs in queue (even though they would all be regrouped under the same job array), each using 1 CPU to run 1 task. Instead of that 100-task array job, you can try something like this: #!/bin/bash #SBATCH --array=0-99:10 #SBATCH -n 10 for i in { 0 ..9 } ; do srun -n 1 ./app $(( SLURM_ARRAY_TASK_ID+i )) & done wait # important to make sure the job doesn't exit before the background tasks are done --array=1-100:10 will use job array indexes 0, 10, 20 ... 90 -n 10 will make sure each job can be subdivided in 10 1- CPU steps the for loop will launch 10 tasks, with indexes from SLURM_ARRAY_TASK_ID to SLURM_ARRAY_TASK_ID + 9 . This would submit a 10-task array job, each of them running 10 steps simultaneously, on the 10 CPUs that each of the job array item will be allocated. In the end, you'll have run the same number of app instances, but you'll have divided the number of jobs submitted by 10, and allow you to submit the same amount of work to the scheduler, while staying under the submission limits.","title":"Minimizing the number of jobs in queue"},{"location":"docs/getting-started/connecting/","text":"Connecting to Sherlock # Sherlock account required To be able to connect to Sherlock, you must first obtain a Sherlock account . Credentials # All users must have a Stanford SUNet ID and a Sherlock account to log in to Sherlock. Your Sherlock account uses the same username/password as your SUnet ID: Username: SUNet ID Password: SUNet ID password To request a Sherlock account, please see the Prerequisites page. Resetting passwords Sherlock does not store your SUNet ID password. As a consequence, we are unable to reset your password. If you require password assistance, please see the SUNet Account page . Connection # Access to Sherlock is provided via Secure Shell ( SSH ) login. Most Unix-like operating systems provide an SSH client by default that can be accessed by typing the ssh command in a terminal window. To login to Sherlock, open a terminal and type the following command, where <sunetid> should be replaced by your actual SUNet ID: $ ssh <sunetid>@login.sherlock.stanford.edu Upon logging in, you will be connected to one of Sherlock's load-balanced login node. You should be automatically directed to the least-loaded login node at the moment of your connection, which should give you the best possible environment to work. Host keys # Upon your very first connection to Sherlock, you will be greeted by a warning such as : The authenticity of host 'login.sherlock.stanford.edu' can't be established. ECDSA key fingerprint is SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg. Are you sure you want to continue connecting (yes/no)? The same warning will be displayed if your try to connect to one of the Data Transfer Node ( DTN ) : The authenticity of host 'dtn.sherlock.stanford.edu' can't be established. ECDSA key fingerprint is SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg. Are you sure you want to continue connecting (yes/no)? This warning is normal: your SSH client warns you that it is the first time it sees that new computer. To make sure you are actually connecting to the right machine, you should compare the ECDSA key fingerprint shown in the message with one of the fingerprints below: Key type Key Fingerprint RSA SHA256:T1q1Tbq8k5XBD5PIxvlCfTxNMi1ORWwKNRPeZPXUfJA legacy format: f5:8f:01:46:d1:f9:66:5d:33:58:b4:82:d8:4a:34:41 ECDSA SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg legacy format: 70:4c:76:ea:ae:b2:0f:81:4b:9c:c6:5a:52:4c:7f:64 If they match, you can proceed and type \u2018yes\u2019. Your SSH program will then store that key and will verify it for every subsequent SSH connection, to make sure that the server you're connecting to is indeed Sherlock. Host keys warning # If you've connected to Sherlock 1.0 before, there's a good chance the Sherlock 1.0 keys were stored by your local SSH client. In that case, when connecting to Sherlock 2.0 using the sherlock.stanford.edu alias, you will be presented with the following message: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: POSSIBLE DNS SPOOFING DETECTED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ The RSA host key for sherlock.stanford.edu has changed, and the key for the corresponding IP address 171.66.97.101 is unknown. This could either mean that DNS SPOOFING is happening or the IP address for the host and its host key have changed at the same time. @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the RSA key sent by the remote host is SHA256:T1q1Tbq8k5XBD5PIxvlCfTxNMi1ORWwKNRPeZPXUfJA. Please contact your system administrator. You can just check that the SHA256 key listed in that warning message correctly matches the one listed in the table above, and if that's the case, you can safely remove the sherlock.stanford.edu entry from your ~/.ssh/known_hosts file with the following command on your local machine: $ ssh-keygen -R sherlock.stanford.edu and then connect again. You'll see the first-connection prompt mentioned above , and your SSH client will store the new keys for future connections. Authentication # Password # To ease access and increase compatibility 1 with different platforms, Sherlock allows a simple password-based authentication mechanism for SSH . 2 . Upon connection, you will be asked for your SUNet ID password with the following prompt: <sunetid>@login.sherlock.stanford.edu ' s password: Enter your password, and if it's correct, you should see the following line: Authenticated with partial success. Second factor ( 2FA ) # Sherlock implements Stanford's Minimum Security Standards policies which mandate two-step authentication to access the cluster. Two-step authentication protects your personal information and credentials by combining something only you know (your password) with something only you have (your phone, tablet or token). This prevents an attacker who would steal your password to actually use it to impersonate you. For more details about two-step authentication at Stanford, please refer to the University IT two-step page. After successfully entering your password, you'll be prompted for your second authentication factor with a message like this: Duo two-factor login for <sunetid> Enter a passcode or select one of the following options: 1 . Duo Push to XXX-XXX-9999 2 . Phone call to XXX-XXX-9999 3 . SMS passcodes to XXX-XXX-9999 ( next code starts with: 9 ) Passcode or option ( 1 -3 ) : Avoiding two-factor prompt on each connection If you routinely open multiple sessions to Sherlock, having to confirm each one of them with a second authentication factor could rapidely become cumbersome. To work around this, the OpenSSH client allows multiplexing channels and re-using existing authenticated for opening new sessions. Please see the Advanced Connection Options page for more details. If your second factor is accepted, you'll see the following message: Success. Logging you in... Troubleshooting # Timeouts # If you ever encounter timeout errors when connecting to Sherlock, like these: $ ssh login.sherlock.stanford.edu ssh: connect to host login.sherlock.stanford.edu port 22 : Operation timed out you can try to either: switch to a wired connection if you're connecting over wifi, connect via the Stanford VPN Authentication failures # Excessive authentication failures Entering an invalid password multiple times will result in a (temporary) ban of your IP address. To prevent brute-force password guessing attacks on Sherlock login nodes, we automatically block IP addresses that generate too many authentication failures in a given time span. This results in a temporary ban of the infringing IP address, and the impossibility for the user to connect to Sherlock from that IP address. When this happens, your SSH connection attempts will result in the following error: ssh: connect to host login.sherlock.stanford.edu port 22: Connection refused IP blocked by this mechanism will automatically be authorized again after a few minutes. SSHFS on macOS SSHFS on macOS is known to try to automatically reconnect filesystem mounts after resuming from sleep or uspend, even without any valid credentials. As a result, it will generate a lot of failed connection attempts and likely make your IP address blacklisted on login nodes. Make sure to unmount your SSHFS drives before putting your macOS system to sleep to avoid this situation. VPN If your IP got blocked and you have an urgent need to connect, before the automatic blacklist expiration, we recommend trying to connect through Stanford's VPN : your computer will then use a different IP address and will not be affected by the ban on your regular IP address. Login # Congratulations! You've successfully connected to Sherlock. You'll be greeted by the following message of the day : --*-*- Stanford Research Computing Center -*-*-- ____ _ _ _ / ___ || | __ ___ _ __ | | ___ ___ | | __ \\_ __ \\| '_ \\ / _ \\ ' __ | | / _ \\ / __ | | / / ___ ) | | | | __/ | | | ( _ ) | ( __ | < | ____/ | _ | | _ | \\_ __ | _ | | _ | \\_ __/ \\_ __ | _ | \\_\\ ----------------------------------------------------------------------------- This system is for authorized users only and users must comply with all Stanford computing, network and research policies. All activity may be recorded for security and monitoring purposes. For more information, see https://doresearch.stanford.edu/policies/research-policy-handbook and https://adminguide.stanford.edu/chapter-6/subchapter-2/policy-6-2-1 ----------------------------------------------------------------------------- Sherlock is *NOT* approved for storing or processing HIPAA, PHI, PII nor any kind of High Risk data. Users are responsible for the compliance of their data. See https://uit.stanford.edu/guide/riskclassifications for details. ----------------------------------------------------------------------------- Docs https://www.sherlock.stanford.edu/docs Support https://www.sherlock.stanford.edu/docs/#support Web https://www.sherlock.stanford.edu News https://news.sherlock.stanford.edu Status https://status.sherlock.stanford.edu ----------------------------------------------------------------------------- Once authenticated to Sherlock, you'll see the following prompt: [ <sunetid> @sh03-ln01 login! ~]$ It indicates the name of the login node you've been connected to, and a reminder that you're actually connected to a login node , not a compute node. Login nodes are not for computing Login nodes are shared among many users and therefore must not be used to run computationally intensive tasks. Those should be submitted to the scheduler which will dispatch them on compute nodes. By contrast, the shell prompt on a compute node looks like this: [ <sunetid> @sh03-01n01 ~]$ Start computing # To start computing, there's still a extra step required, which is requesting resources to run your application. It's all described in the next section . On Sherlock 1.0, GSSAPI tokens (based on Kerberos tickets) were the only allowed authentication method, which could cause some interoperability with third-party SSH clients. \u21a9 For other methods of authentication, see the Advanced Connection Options page. \u21a9","title":"Connecting"},{"location":"docs/getting-started/connecting/#connecting-to-sherlock","text":"Sherlock account required To be able to connect to Sherlock, you must first obtain a Sherlock account .","title":"Connecting to Sherlock "},{"location":"docs/getting-started/connecting/#credentials","text":"All users must have a Stanford SUNet ID and a Sherlock account to log in to Sherlock. Your Sherlock account uses the same username/password as your SUnet ID: Username: SUNet ID Password: SUNet ID password To request a Sherlock account, please see the Prerequisites page. Resetting passwords Sherlock does not store your SUNet ID password. As a consequence, we are unable to reset your password. If you require password assistance, please see the SUNet Account page .","title":"Credentials"},{"location":"docs/getting-started/connecting/#connection","text":"Access to Sherlock is provided via Secure Shell ( SSH ) login. Most Unix-like operating systems provide an SSH client by default that can be accessed by typing the ssh command in a terminal window. To login to Sherlock, open a terminal and type the following command, where <sunetid> should be replaced by your actual SUNet ID: $ ssh <sunetid>@login.sherlock.stanford.edu Upon logging in, you will be connected to one of Sherlock's load-balanced login node. You should be automatically directed to the least-loaded login node at the moment of your connection, which should give you the best possible environment to work.","title":"Connection"},{"location":"docs/getting-started/connecting/#host-keys","text":"Upon your very first connection to Sherlock, you will be greeted by a warning such as : The authenticity of host 'login.sherlock.stanford.edu' can't be established. ECDSA key fingerprint is SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg. Are you sure you want to continue connecting (yes/no)? The same warning will be displayed if your try to connect to one of the Data Transfer Node ( DTN ) : The authenticity of host 'dtn.sherlock.stanford.edu' can't be established. ECDSA key fingerprint is SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg. Are you sure you want to continue connecting (yes/no)? This warning is normal: your SSH client warns you that it is the first time it sees that new computer. To make sure you are actually connecting to the right machine, you should compare the ECDSA key fingerprint shown in the message with one of the fingerprints below: Key type Key Fingerprint RSA SHA256:T1q1Tbq8k5XBD5PIxvlCfTxNMi1ORWwKNRPeZPXUfJA legacy format: f5:8f:01:46:d1:f9:66:5d:33:58:b4:82:d8:4a:34:41 ECDSA SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg legacy format: 70:4c:76:ea:ae:b2:0f:81:4b:9c:c6:5a:52:4c:7f:64 If they match, you can proceed and type \u2018yes\u2019. Your SSH program will then store that key and will verify it for every subsequent SSH connection, to make sure that the server you're connecting to is indeed Sherlock.","title":"Host keys"},{"location":"docs/getting-started/connecting/#host-keys-warning","text":"If you've connected to Sherlock 1.0 before, there's a good chance the Sherlock 1.0 keys were stored by your local SSH client. In that case, when connecting to Sherlock 2.0 using the sherlock.stanford.edu alias, you will be presented with the following message: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: POSSIBLE DNS SPOOFING DETECTED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ The RSA host key for sherlock.stanford.edu has changed, and the key for the corresponding IP address 171.66.97.101 is unknown. This could either mean that DNS SPOOFING is happening or the IP address for the host and its host key have changed at the same time. @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the RSA key sent by the remote host is SHA256:T1q1Tbq8k5XBD5PIxvlCfTxNMi1ORWwKNRPeZPXUfJA. Please contact your system administrator. You can just check that the SHA256 key listed in that warning message correctly matches the one listed in the table above, and if that's the case, you can safely remove the sherlock.stanford.edu entry from your ~/.ssh/known_hosts file with the following command on your local machine: $ ssh-keygen -R sherlock.stanford.edu and then connect again. You'll see the first-connection prompt mentioned above , and your SSH client will store the new keys for future connections.","title":"Host keys warning"},{"location":"docs/getting-started/connecting/#authentication","text":"","title":"Authentication"},{"location":"docs/getting-started/connecting/#password","text":"To ease access and increase compatibility 1 with different platforms, Sherlock allows a simple password-based authentication mechanism for SSH . 2 . Upon connection, you will be asked for your SUNet ID password with the following prompt: <sunetid>@login.sherlock.stanford.edu ' s password: Enter your password, and if it's correct, you should see the following line: Authenticated with partial success.","title":"Password"},{"location":"docs/getting-started/connecting/#second-factor-2fa","text":"Sherlock implements Stanford's Minimum Security Standards policies which mandate two-step authentication to access the cluster. Two-step authentication protects your personal information and credentials by combining something only you know (your password) with something only you have (your phone, tablet or token). This prevents an attacker who would steal your password to actually use it to impersonate you. For more details about two-step authentication at Stanford, please refer to the University IT two-step page. After successfully entering your password, you'll be prompted for your second authentication factor with a message like this: Duo two-factor login for <sunetid> Enter a passcode or select one of the following options: 1 . Duo Push to XXX-XXX-9999 2 . Phone call to XXX-XXX-9999 3 . SMS passcodes to XXX-XXX-9999 ( next code starts with: 9 ) Passcode or option ( 1 -3 ) : Avoiding two-factor prompt on each connection If you routinely open multiple sessions to Sherlock, having to confirm each one of them with a second authentication factor could rapidely become cumbersome. To work around this, the OpenSSH client allows multiplexing channels and re-using existing authenticated for opening new sessions. Please see the Advanced Connection Options page for more details. If your second factor is accepted, you'll see the following message: Success. Logging you in...","title":"Second factor (2FA)"},{"location":"docs/getting-started/connecting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"docs/getting-started/connecting/#timeouts","text":"If you ever encounter timeout errors when connecting to Sherlock, like these: $ ssh login.sherlock.stanford.edu ssh: connect to host login.sherlock.stanford.edu port 22 : Operation timed out you can try to either: switch to a wired connection if you're connecting over wifi, connect via the Stanford VPN","title":"Timeouts"},{"location":"docs/getting-started/connecting/#authentication-failures","text":"Excessive authentication failures Entering an invalid password multiple times will result in a (temporary) ban of your IP address. To prevent brute-force password guessing attacks on Sherlock login nodes, we automatically block IP addresses that generate too many authentication failures in a given time span. This results in a temporary ban of the infringing IP address, and the impossibility for the user to connect to Sherlock from that IP address. When this happens, your SSH connection attempts will result in the following error: ssh: connect to host login.sherlock.stanford.edu port 22: Connection refused IP blocked by this mechanism will automatically be authorized again after a few minutes. SSHFS on macOS SSHFS on macOS is known to try to automatically reconnect filesystem mounts after resuming from sleep or uspend, even without any valid credentials. As a result, it will generate a lot of failed connection attempts and likely make your IP address blacklisted on login nodes. Make sure to unmount your SSHFS drives before putting your macOS system to sleep to avoid this situation. VPN If your IP got blocked and you have an urgent need to connect, before the automatic blacklist expiration, we recommend trying to connect through Stanford's VPN : your computer will then use a different IP address and will not be affected by the ban on your regular IP address.","title":"Authentication failures"},{"location":"docs/getting-started/connecting/#login","text":"Congratulations! You've successfully connected to Sherlock. You'll be greeted by the following message of the day : --*-*- Stanford Research Computing Center -*-*-- ____ _ _ _ / ___ || | __ ___ _ __ | | ___ ___ | | __ \\_ __ \\| '_ \\ / _ \\ ' __ | | / _ \\ / __ | | / / ___ ) | | | | __/ | | | ( _ ) | ( __ | < | ____/ | _ | | _ | \\_ __ | _ | | _ | \\_ __/ \\_ __ | _ | \\_\\ ----------------------------------------------------------------------------- This system is for authorized users only and users must comply with all Stanford computing, network and research policies. All activity may be recorded for security and monitoring purposes. For more information, see https://doresearch.stanford.edu/policies/research-policy-handbook and https://adminguide.stanford.edu/chapter-6/subchapter-2/policy-6-2-1 ----------------------------------------------------------------------------- Sherlock is *NOT* approved for storing or processing HIPAA, PHI, PII nor any kind of High Risk data. Users are responsible for the compliance of their data. See https://uit.stanford.edu/guide/riskclassifications for details. ----------------------------------------------------------------------------- Docs https://www.sherlock.stanford.edu/docs Support https://www.sherlock.stanford.edu/docs/#support Web https://www.sherlock.stanford.edu News https://news.sherlock.stanford.edu Status https://status.sherlock.stanford.edu ----------------------------------------------------------------------------- Once authenticated to Sherlock, you'll see the following prompt: [ <sunetid> @sh03-ln01 login! ~]$ It indicates the name of the login node you've been connected to, and a reminder that you're actually connected to a login node , not a compute node. Login nodes are not for computing Login nodes are shared among many users and therefore must not be used to run computationally intensive tasks. Those should be submitted to the scheduler which will dispatch them on compute nodes. By contrast, the shell prompt on a compute node looks like this: [ <sunetid> @sh03-01n01 ~]$","title":"Login"},{"location":"docs/getting-started/connecting/#start-computing","text":"To start computing, there's still a extra step required, which is requesting resources to run your application. It's all described in the next section . On Sherlock 1.0, GSSAPI tokens (based on Kerberos tickets) were the only allowed authentication method, which could cause some interoperability with third-party SSH clients. \u21a9 For other methods of authentication, see the Advanced Connection Options page. \u21a9","title":"Start computing"},{"location":"docs/getting-started/prerequisites/","text":"To start using Sherlock, you will need: an active SUNet ID , What is a SUNet ID? A SUNet ID is a unique 3-8 character account name that identifies you as a member of the Stanford community, with access to the Stanford University Network of computing resources and services. Not to be confused with University ID (a 8-digit number that appears on your Stanford ID Card), your SUNet ID is a permanent and visible part of your Stanford identity and often appears in your Stanford email address (eg. sunetid@stanford.edu ). SUNet IDs are not managed by Research Computing. For more information, see https://accounts.stanford.edu/ SUNet ID service levels and external collaborators Base-level service is sufficient for Sherlock accounts. External collaborators, or users without a SUNet ID, can be sponsored by a PI a get a sponsored SUNet ID at no cost. Please see the sponsorship page for more information. a Sherlock account , a SSH client , good understanding of the concepts and terms used throughout that documentation, some familiarity with Unix/Linux command-line environments , and notions of shell scripting . How to request an account # To request an account, the sponsoring Stanford faculty member should email srcc-support@stanford.edu , specifying the names and SUNet IDs of his/her research team members needing an account. Sherlock is open to the Stanford community as a computing resource to support departmental or sponsored research, thus a faculty member's explicit consent is required for account requests. Sherlock is a resource for research Sherlock is a resource to help and support research, and is not suitable for course work, class assignments or general-use training sessions. There is no fee associated with using Sherlock, and no limit in the amount of accounts each faculty member can request. We will periodically ensure that all accounts associated with each PI are still active, and reserve the right to close any Sherlock account whose SUNet ID is expired. SSH clients # Linux # Linux distributions usually come with a version of the OpenSSH client already installed. So no additional software installation is required. If not, please refer to your distribution's documentation to install it. MacOS # MacOS systems usually come with a version of the OpenSSH client already installed. So no additional software installation is required Windows # Microsoft Windows doesn't provide any SSH client by default. To install one, you have several options, depending on the version of Windows. WSL recommended Windows 10 provides a feature called the \"Windows Subsystem for Linux\" (WSL). Please refer to the official documentation or this howto for installation instructions. Once installed, you'll be able to use the ssh command from a Windows terminal to connect to Sherlock. Cygwin The Cygwin project predates WSL and provides similar features, which among other things, allow users to install a command-line SSH client on their Windows machines. The two options above will ensure the best compatibility with the Sherlock environment. If you'd like to explore other avenues, many other SSH client implementations are available, but have not necessarily been tested with Sherlock, so your mileage may vary. Unix/Linux resources # A full tutorial on using Unix/Linux is beyond the scope of this documentation. However, there are many tutorials for beginning to use Unix/Linux on the web. A few tutorials we recommend are: Unix Tutorial for Beginners (University of Surrey, UK) Introduction to Unix (Imperial College, London) The Unix Shell (Software Carpentry) More specifically about HPC and Research Computing: Intro to HPC ( HPC Carpentry) HPC in a day (Software Carpentry} Research Computing Q&A (Ask.Cyberinfrastructure) Text editors # Multiple text editors are available on Sherlock. For beginners, we recommend the use of nano . And for more advanced uses, you'll also find below some resources about using vim Nano guide (Gentoo wiki) Vim guide (Gentoo wiki) Note: you can also create/edit files with the Sherlock OnDemand File editor Shell scripting # Compute jobs launched on Sherlock are most often initialized by user-written shell scripts. Beyond that, many common operations can be simplified and automated using shell scripts. For an introduction to shell scripting, you can refer to: Bash Programming - Introduction HOWTO","title":"Prerequisites"},{"location":"docs/getting-started/prerequisites/#how-to-request-an-account","text":"To request an account, the sponsoring Stanford faculty member should email srcc-support@stanford.edu , specifying the names and SUNet IDs of his/her research team members needing an account. Sherlock is open to the Stanford community as a computing resource to support departmental or sponsored research, thus a faculty member's explicit consent is required for account requests. Sherlock is a resource for research Sherlock is a resource to help and support research, and is not suitable for course work, class assignments or general-use training sessions. There is no fee associated with using Sherlock, and no limit in the amount of accounts each faculty member can request. We will periodically ensure that all accounts associated with each PI are still active, and reserve the right to close any Sherlock account whose SUNet ID is expired.","title":"How to request an account"},{"location":"docs/getting-started/prerequisites/#ssh-clients","text":"","title":"SSH clients"},{"location":"docs/getting-started/prerequisites/#linux","text":"Linux distributions usually come with a version of the OpenSSH client already installed. So no additional software installation is required. If not, please refer to your distribution's documentation to install it.","title":"Linux "},{"location":"docs/getting-started/prerequisites/#macos","text":"MacOS systems usually come with a version of the OpenSSH client already installed. So no additional software installation is required","title":"MacOS "},{"location":"docs/getting-started/prerequisites/#windows","text":"Microsoft Windows doesn't provide any SSH client by default. To install one, you have several options, depending on the version of Windows. WSL recommended Windows 10 provides a feature called the \"Windows Subsystem for Linux\" (WSL). Please refer to the official documentation or this howto for installation instructions. Once installed, you'll be able to use the ssh command from a Windows terminal to connect to Sherlock. Cygwin The Cygwin project predates WSL and provides similar features, which among other things, allow users to install a command-line SSH client on their Windows machines. The two options above will ensure the best compatibility with the Sherlock environment. If you'd like to explore other avenues, many other SSH client implementations are available, but have not necessarily been tested with Sherlock, so your mileage may vary.","title":"Windows "},{"location":"docs/getting-started/prerequisites/#unixlinux-resources","text":"A full tutorial on using Unix/Linux is beyond the scope of this documentation. However, there are many tutorials for beginning to use Unix/Linux on the web. A few tutorials we recommend are: Unix Tutorial for Beginners (University of Surrey, UK) Introduction to Unix (Imperial College, London) The Unix Shell (Software Carpentry) More specifically about HPC and Research Computing: Intro to HPC ( HPC Carpentry) HPC in a day (Software Carpentry} Research Computing Q&A (Ask.Cyberinfrastructure)","title":"Unix/Linux resources"},{"location":"docs/getting-started/prerequisites/#text-editors","text":"Multiple text editors are available on Sherlock. For beginners, we recommend the use of nano . And for more advanced uses, you'll also find below some resources about using vim Nano guide (Gentoo wiki) Vim guide (Gentoo wiki) Note: you can also create/edit files with the Sherlock OnDemand File editor","title":"Text editors"},{"location":"docs/getting-started/prerequisites/#shell-scripting","text":"Compute jobs launched on Sherlock are most often initialized by user-written shell scripts. Beyond that, many common operations can be simplified and automated using shell scripts. For an introduction to shell scripting, you can refer to: Bash Programming - Introduction HOWTO","title":"Shell scripting"},{"location":"docs/getting-started/submitting/","text":"Principle # Login nodes are not for computing Login nodes are shared among many users and therefore must not be used to run computationally intensive tasks. Those should be submitted to the scheduler which will dispatch them on compute nodes. Requesting resources # A mandatory prerequisite for running computational tasks on Sherlock is to request computing resources. This is done via a resource scheduler, whose very purpose is to match compute resources in the cluster (CPUs, GPUs, memory, ...) with user resource requests. The scheduler provides three key functions: it allocates access to resources (compute nodes) to users for some duration of time so they can perform work. it provides a framework for starting, executing, and monitoring work (typically a parallel job such as MPI ) on a set of allocated nodes. it arbitrates contention for resources by managing a queue of pending jobs Slurm # @media only screen and (max-width: 720px) { #slurm_logo { display: none; } } Sherlock uses Slurm , an open-source resource manager and job scheduler, used by many of the world's supercomputers and computer clusters . Slurm supports a variety of job submission techniques. By accurately requesting the resources you need, you\u2019ll be able to get your work done. Wait times in queue As a quick rule of thumb, it's important to keep in mind that the more resources your job requests (CPUs, GPUs, memory, nodes, and time), the longer it may have to wait in queue before it could start. In other words: accurately requesting resources to match your job's needs will minimize your wait times. How to submit a job # A job consists in two parts: resource requests and job steps. Resource requests describe the amount of computing resource (CPUs, GPUs, memory, expected run time, etc.) that the job will need to successfully run. Job steps describe tasks that must be executed. Batch scripts # The typical way of creating a job is to write a job submission script. A submission script is a shell script (e.g. a Bash script) whose first comments, if they are prefixed with #SBATCH , are interpreted by Slurm as parameters describing resource requests and submissions options 1 . The submission script itself is a job step. Other job steps are created with the srun command. For instance, the following script would request one task with one CPU for 10 minutes, along with 2 GB of memory, in the default partition: #!/bin/bash # #SBATCH --job-name=test # #SBATCH --time=10:00 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=2G srun hostname srun sleep 60 When started, the job would run a first job step srun hostname , which will launch the command hostname on the node on which the requested CPU was allocated. Then, a second job step will start the sleep command. You can create this job submission script on Sherlock using a text editor such as nano or vim , and save it as submit.sh . #SBATCH directives syntax #SBATCH directives must be at the top of the script Slurm will ignore all #SBATCH directives after the first non-comment line (that is, the first line in the script that doesn't start with a # character). Always put your #SBATCH parameters at the top of your batch script. Spaces in parameters will cause #SBATCH directives to be ignored Slurm will ignore all #SBATCH directives after the first white space. For instance directives like those: #SBATCH --job-name=big job #SBATCH --mem=16 G #SBATCH --partition=normal, owners will cause all following #SBATCH directives to be ignored and the job to be submitted with the default parameters. Job submission # Once the submission script is written properly, you can submit it to the scheduler with the sbatch command. Upon success, sbatch will return the ID it has assigned to the job (the jobid). $ sbatch submit.sh Submitted batch job 1377 Check the job # Once submitted, the job enters the queue in the PENDING state. When resources become available and the job has sufficient priority, an allocation is created for it and it moves to the RUNNING state. If the job completes correctly, it goes to the COMPLETED state, otherwise, its state is set to FAILED . You'll be able to check the status of your job and follow its evolution with the squeue -u $USER command: $ squeue -u $USER JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 1377 normal test kilian R 0 :12 1 sh02-01n01 The scheduler will automatically create an output file that will contain the result of the commands run in the script file. That output file is names slurm-<jobid>.out by default, but can be customized via submission options. In the above example, you can list the contents of that output file with the following commands: $ cat slurm-1377.out sh02-01n01 Congratulations, you've submitted your first batch job on Sherlock! What's next? # Actually, quite a lot. Although you now know how to submit a simple batch job, there are many other options and areas to explore in the next sections: Data transfer Storage Running jobs You can get the complete list of parameters by referring to the sbatch manual page ( man sbatch ). \u21a9","title":"Submitting jobs"},{"location":"docs/getting-started/submitting/#principle","text":"Login nodes are not for computing Login nodes are shared among many users and therefore must not be used to run computationally intensive tasks. Those should be submitted to the scheduler which will dispatch them on compute nodes.","title":"Principle"},{"location":"docs/getting-started/submitting/#requesting-resources","text":"A mandatory prerequisite for running computational tasks on Sherlock is to request computing resources. This is done via a resource scheduler, whose very purpose is to match compute resources in the cluster (CPUs, GPUs, memory, ...) with user resource requests. The scheduler provides three key functions: it allocates access to resources (compute nodes) to users for some duration of time so they can perform work. it provides a framework for starting, executing, and monitoring work (typically a parallel job such as MPI ) on a set of allocated nodes. it arbitrates contention for resources by managing a queue of pending jobs","title":"Requesting resources"},{"location":"docs/getting-started/submitting/#slurm","text":"@media only screen and (max-width: 720px) { #slurm_logo { display: none; } } Sherlock uses Slurm , an open-source resource manager and job scheduler, used by many of the world's supercomputers and computer clusters . Slurm supports a variety of job submission techniques. By accurately requesting the resources you need, you\u2019ll be able to get your work done. Wait times in queue As a quick rule of thumb, it's important to keep in mind that the more resources your job requests (CPUs, GPUs, memory, nodes, and time), the longer it may have to wait in queue before it could start. In other words: accurately requesting resources to match your job's needs will minimize your wait times.","title":"Slurm"},{"location":"docs/getting-started/submitting/#how-to-submit-a-job","text":"A job consists in two parts: resource requests and job steps. Resource requests describe the amount of computing resource (CPUs, GPUs, memory, expected run time, etc.) that the job will need to successfully run. Job steps describe tasks that must be executed.","title":"How to submit a job"},{"location":"docs/getting-started/submitting/#batch-scripts","text":"The typical way of creating a job is to write a job submission script. A submission script is a shell script (e.g. a Bash script) whose first comments, if they are prefixed with #SBATCH , are interpreted by Slurm as parameters describing resource requests and submissions options 1 . The submission script itself is a job step. Other job steps are created with the srun command. For instance, the following script would request one task with one CPU for 10 minutes, along with 2 GB of memory, in the default partition: #!/bin/bash # #SBATCH --job-name=test # #SBATCH --time=10:00 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=2G srun hostname srun sleep 60 When started, the job would run a first job step srun hostname , which will launch the command hostname on the node on which the requested CPU was allocated. Then, a second job step will start the sleep command. You can create this job submission script on Sherlock using a text editor such as nano or vim , and save it as submit.sh . #SBATCH directives syntax #SBATCH directives must be at the top of the script Slurm will ignore all #SBATCH directives after the first non-comment line (that is, the first line in the script that doesn't start with a # character). Always put your #SBATCH parameters at the top of your batch script. Spaces in parameters will cause #SBATCH directives to be ignored Slurm will ignore all #SBATCH directives after the first white space. For instance directives like those: #SBATCH --job-name=big job #SBATCH --mem=16 G #SBATCH --partition=normal, owners will cause all following #SBATCH directives to be ignored and the job to be submitted with the default parameters.","title":"Batch scripts"},{"location":"docs/getting-started/submitting/#job-submission","text":"Once the submission script is written properly, you can submit it to the scheduler with the sbatch command. Upon success, sbatch will return the ID it has assigned to the job (the jobid). $ sbatch submit.sh Submitted batch job 1377","title":"Job submission"},{"location":"docs/getting-started/submitting/#check-the-job","text":"Once submitted, the job enters the queue in the PENDING state. When resources become available and the job has sufficient priority, an allocation is created for it and it moves to the RUNNING state. If the job completes correctly, it goes to the COMPLETED state, otherwise, its state is set to FAILED . You'll be able to check the status of your job and follow its evolution with the squeue -u $USER command: $ squeue -u $USER JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 1377 normal test kilian R 0 :12 1 sh02-01n01 The scheduler will automatically create an output file that will contain the result of the commands run in the script file. That output file is names slurm-<jobid>.out by default, but can be customized via submission options. In the above example, you can list the contents of that output file with the following commands: $ cat slurm-1377.out sh02-01n01 Congratulations, you've submitted your first batch job on Sherlock!","title":"Check the job"},{"location":"docs/getting-started/submitting/#whats-next","text":"Actually, quite a lot. Although you now know how to submit a simple batch job, there are many other options and areas to explore in the next sections: Data transfer Storage Running jobs You can get the complete list of parameters by referring to the sbatch manual page ( man sbatch ). \u21a9","title":"What's next?"},{"location":"docs/overview/about/","text":"About us # img[alt=\"logo\"] { width: 400px; } SRCC # The Stanford Research Computing Center ( SRCC ) is a joint effort of the Dean of Research and IT Services to build and support a comprehensive program to advance computational research at Stanford. That includes offering and supporting traditional high performance computing ( HPC ) systems, as well as systems for high throughput and data-intensive computing. The SRCC also helps researchers transition their analyses and models from the desktop to more capable and plentiful resources, providing the opportunity to explore their data and answer research questions at a scale typically not possible on desktops or departmental servers. Partnering with national initiatives like NSF XSEDE program as well as vendors, the SRCC offers training and learning opportunities around HPC tools and technologies. For more information, please see the SRCC website Credits # We would like to thank the following companies for their generous sponsorship, and for providing services and resources that help us manage Sherlock every day: img[alt=\"favicon\"] { vertical-align: middle; height: 1rem; } img[alt=\"screencap\"] { width: 320px; margin: 5px; } ZenHub GitHub Travis CI Hund Noticeable updown.io The Sherlock website and documentation also rely on the following projects: MkDocs Material for MkDocs Why the Sherlock name? # If you're curious about where the Sherlock name came from, we always considered that computing resources in general and HPC clusters in particular should be the catalyst of innovation, be ahead of their time, and spur new discoveries. And what better account of what's happening on a high-performance computing cluster than Benedict Cumberbatch describing his role as Sherlock Holmes in the BBC's modern adaptation of Arthur Conan Doyle's classic? Benedict Cumberbatch, about Sherlock There's a great charge you get from playing him, because of the volume of words in your head and the speed of thought \u2013 you really have to make your connections incredibly fast. He is one step ahead of the audience, and of anyone around him with normal intellect. They can't quite fathom where his leaps are taking him. Yes, exactly. That's Sherlock. Sherlock, of HBO fame # And finally, we couldn't resist to the pleasure of citing the most prestigious accomplishment of Sherlock to date: a mention in HBO's Silicon Valley Season 4 finale ! Yep, you got that right, Richard Hendricks wanted to use our very own Sherlock. Kudos to the show's crew and whomever did the research and got it right, you made our day.","title":"About"},{"location":"docs/overview/about/#about-us","text":"img[alt=\"logo\"] { width: 400px; }","title":"About us"},{"location":"docs/overview/about/#srcc","text":"The Stanford Research Computing Center ( SRCC ) is a joint effort of the Dean of Research and IT Services to build and support a comprehensive program to advance computational research at Stanford. That includes offering and supporting traditional high performance computing ( HPC ) systems, as well as systems for high throughput and data-intensive computing. The SRCC also helps researchers transition their analyses and models from the desktop to more capable and plentiful resources, providing the opportunity to explore their data and answer research questions at a scale typically not possible on desktops or departmental servers. Partnering with national initiatives like NSF XSEDE program as well as vendors, the SRCC offers training and learning opportunities around HPC tools and technologies. For more information, please see the SRCC website","title":"SRCC"},{"location":"docs/overview/about/#credits","text":"We would like to thank the following companies for their generous sponsorship, and for providing services and resources that help us manage Sherlock every day: img[alt=\"favicon\"] { vertical-align: middle; height: 1rem; } img[alt=\"screencap\"] { width: 320px; margin: 5px; } ZenHub GitHub Travis CI Hund Noticeable updown.io The Sherlock website and documentation also rely on the following projects: MkDocs Material for MkDocs","title":"Credits"},{"location":"docs/overview/about/#why-the-sherlock-name","text":"If you're curious about where the Sherlock name came from, we always considered that computing resources in general and HPC clusters in particular should be the catalyst of innovation, be ahead of their time, and spur new discoveries. And what better account of what's happening on a high-performance computing cluster than Benedict Cumberbatch describing his role as Sherlock Holmes in the BBC's modern adaptation of Arthur Conan Doyle's classic? Benedict Cumberbatch, about Sherlock There's a great charge you get from playing him, because of the volume of words in your head and the speed of thought \u2013 you really have to make your connections incredibly fast. He is one step ahead of the audience, and of anyone around him with normal intellect. They can't quite fathom where his leaps are taking him. Yes, exactly. That's Sherlock.","title":"Why the Sherlock name?"},{"location":"docs/overview/about/#sherlock-of-hbo-fame","text":"And finally, we couldn't resist to the pleasure of citing the most prestigious accomplishment of Sherlock to date: a mention in HBO's Silicon Valley Season 4 finale ! Yep, you got that right, Richard Hendricks wanted to use our very own Sherlock. Kudos to the show's crew and whomever did the research and got it right, you made our day.","title":"Sherlock, of HBO fame"},{"location":"docs/overview/concepts/","text":"Sherlock, a shared resource # Sherlock is a shared compute cluster available for use by all Stanford faculty members and their research teams to support sponsored research. Sherlock is a resource for research Sherlock is not suitable for course work, class assignments or general-use training sessions. Users interested in using computing resources in such contexts are encouraged to investigate FarmShare , Stanford\u2019s community computing environment, which is primarily intended for supporting coursework. It is open to the Stanford community as a computing resource to support departmental or sponsored research, thus a faculty member's sponsorship is required for all user accounts. Usage policy Please note that your use of this system falls under the \"Computer and Network Usage Policy\", as described in the Stanford Administrative Guide . In particular, sharing authentication credentials is strictly prohibited. Violation of this policy will result in termination of access to Sherlock. Sherlock has been designed, deployed, and is maintained and operated by the Stanford Research Computing Center ( SRCC ) staff. The SRCC is a joint effort of the Dean of Research and IT Services to build and support a comprehensive program to advance computational research at Stanford. Sherlock has been initially purchased and supported with seed funding from Stanford's Provost . It comprises a set of freely available compute nodes, a few specific resources such as large-memory machines and GPU servers, as well as the associated networking equipment and storage. These resources can be used to run computational codes and programs, and are managed through a job scheduler using a fair-share algorithm . Data risk classification # Low and Moderate Risk data Sherlock is approved for computing with Low and Moderate Risk data only. High Risk data Sherlock is NOT approved to store or process HIPAA , PHI , PII nor any kind of High Risk data. The system is approved for computing with Low and Moderate Risk data only, and is not suitable to process High Risk data . Users are responsible for ensuring the compliance of their own data. For more information about data risk classifications, see the Information Security Risk Classification page . Investing in Sherlock # For users who need more than casual access to a shared computing environment, Sherlock also offers Faculty members the possibility to invest in additional, dedicated computing resources. Unlike traditional clusters, Sherlock is a collaborative system where the majority of nodes are purchased and shared by the cluster users. When a user (typically a PI ) purchases one or more nodes, they become an owner . Owners choose from a standard set of server configurations supported by SRCC staff (known as the Sherlock catalog ) to add to the cluster. When they're not in use, PI -purchased compute nodes can be used by other owners. This model also allows Sherlock owners to benefit from the scale of the cluster by giving them access to more compute nodes than their individual purchase, which gives them much greater flexibility than owning a standalone cluster. The majority of Sherlock nodes are owners nodes The vast majority of Sherlock's compute nodes have been purchased by individual PIs and groups, and PI purchases are the main driver behind the rapid expansion of the cluster, which went from 120 nodes to more than 1,000 nodes in less than 3 years. The resource scheduler configuration works like this: owners and their research teams get immediate and exclusive access to the resources they purchased, when those nodes are idle, other owners can use them, when the purchasing owners want to use their resources, jobs from other owners that may be running on them are preempted ( ie. killed and re-queued). This provides a way to get more resources to run less important jobs in the background, while making sure that an owner always gets immediate access to his/her own nodes. Participating owners also have shared access to the public, shared Sherlock nodes, along with everyone else. Benefits # Benefits to owners include: no wait time in queue with immediate and exclusive access to the purchased nodes access to more resources with the possibility to submit jobs to the other owners' nodes when they're not in use Compared to hosting and managing computing resources on your own, purchasing nodes on Sherlock provides: data center hosting, including backup power and cooling system configuration, maintenance and administration hardware diagnostics and repairs Those benefits come in addition to the other Sherlock advantages: access to high-performance, large parallel scratch storage space access to snapshot'ed, replicated, enterprise-class storage space optimized software stack, especially tailored for a range of research needs tools to build and install additional software applications as needed user support Limitations # Being an owner on Sherlock is different from traditional server hosting. In particular, purchasing your own compute nodes on Sherlock will NOT provide: root access : owner nodes on Sherlock are still managed by SRCC in accordance with Stanford's Minimum Security Standards . Although users are welcome to install (or request) any software they may need, purchasing compute nodes on Sherlock does not allow root access to the nodes. running permanent services : permanent processes such as web servers or databases can only run on owner nodes through the scheduler, using recurring or persistent . Purchasing compute nodes on Sherlock does not provide a way to run anything that couldn't run on publicly-available nodes. direct network connectivity from the outside world: owners' nodes are connected to the Sherlock's internal network and are not directly accessible from the outside, which means that they can't host public services like web or application servers. scheduler bypass : jobs running on owners' nodes still need to be submitted to the scheduler. Direct shell access to the nodes is not possible outside of scheduled interactive sessions. persistent local storage : local storage space provided on the compute nodes is only usable for the duration of a job and cannot be used to store long-term data. additional storage space : purchasing compute nodes on Sherlock does not provide additional storage space. Please note that SRCC does offer the possibility for PIs to purchase their own storage space on Oak , for their long-term research data needs. Purchasing nodes # If you are interested in becoming an owner, you can find the latest information about ordering Sherlock nodes on the ordering page . Feel free to contact us is you have any additional question. Cluster generations # The research computing landscape evolves very quickly, and to both accommodate growth and technological advances, it's necessary to adapt the Sherlock environment to these evolutions. Every year or so, a new generation of processors is released, which is why, over a span of several years, multiple generations of CPUs and GPUs make their way into Sherlock. This provides users with access to the latest features and performance enhancements, but it also adds some heterogeneity to the cluster, which is important to keep in mind when compiling software and requesting resources to run them. Another key component of Sherlock is the interconnect network that links all of Sherlock's compute nodes together and act as a backbone for the whole cluster. This network fabric is of finite capacity, and based on the individual networking switches characteristics and the typical research computing workflows, it can accommodate up to about 850 compute nodes. As nodes get added to Sherlock, the number of available ports decreases, and at some point, the fabric gets full and no more nodes can be added. Sherlock reached that stage for the first time in late 2016, which prompted the installation of a whole new fabric, to allow for further system expansion. This kind of evolution is the perfect opportunity to upgrade other components too: management software, ancillary services architecture and user applications. In January 2017, those components were completely overhauled and a new, completely separate cluster was kick-started, using using a different set of hardware and software, while conserving the same storage infrastructure, to ease the transition process. After a transition period, the older Sherlock hardware, compute and login nodes, have been be merged in the new cluster, and from a logical perspective (connection, job scheduling and computing resources), nodes attached to each of the fabrics have been reunited to form a single cluster again. As Sherlock continues to evolve and grow, the new fabric will also approach capacity again, and the same process will happen again to start the next generation of Sherlock. Maintenances and upgrades # The SRCC institutes a monthly scheduled maintenance window on Sherlock, to ensure optimal operation, avoid potential issues and prepare for future expansions. This window will be used to make hardware repairs, software and firmware updates, and perform general manufacturer recommended maintenance on our environment. As often as possible, maintenance tasks are performed in a rolling, non-disruptive fashion, but downtimes are sometimes an unfortunate necessity to allow disruptive operations that can't be conducted while users are working on the system. Maintenance schedule As often as possible, maintenances will take place on the first Tuesday of every month, from 08:00 to 12:00 Pacific time (noon), and will be announced 2 weeks in advance, through the usual communication channels. In case an exceptional amount of work is required, the maintenance window could be extended to 10 hours (from 08:00 to 18:00). During these times, access to Sherlock will be unavailable, login will be disabled and jobs won't run. A reservation will be placed in the scheduler so running jobs can finish before the maintenance, and jobs that wouldn't finish by the maintenance window would be pushed after it. Common questions # Q: Why doing maintenances at all? A : Due to the scale of our computing environment and the increasing complexity of the systems we deploy, it is prudent to arrange for a regular time when we can comfortably and without pressure fix problems or update facilities with minimal impact to our customers. Most, if not all, major HPC centers have regular maintenance schedules. We also need to enforce the Minimum Security rules instituted by the Stanford Information Security Office, which mandate deployment of security patches in a timely manner. Q: Why Tuesdays 08:00-12:00? Why not do this late at night? A: We have observed that the least busy time for our services is at the beginning of the week in the morning hours. Using this time period should not interrupt most of our users. If the remote possibility of a problem that extends past the scheduled downtime occurs, we would have our full staff fresh and available to assist in repairs and quickly restore service. Q: I have jobs running, what will happen to them? A: For long-running jobs, we strongly recommend checkpointing your results on a periodic basis. Besides, we will place a reservation in the scheduler for each maintenance that would prevent jobs to run past it. This means that the scheduler will only allow jobs to run if they can finish by the time the maintenance starts. If you submit a long job soon before the maintenance, it will be delayed until after the maintenance. That will ensure that no work is lost when the maintenance starts.","title":"Concepts"},{"location":"docs/overview/concepts/#sherlock-a-shared-resource","text":"Sherlock is a shared compute cluster available for use by all Stanford faculty members and their research teams to support sponsored research. Sherlock is a resource for research Sherlock is not suitable for course work, class assignments or general-use training sessions. Users interested in using computing resources in such contexts are encouraged to investigate FarmShare , Stanford\u2019s community computing environment, which is primarily intended for supporting coursework. It is open to the Stanford community as a computing resource to support departmental or sponsored research, thus a faculty member's sponsorship is required for all user accounts. Usage policy Please note that your use of this system falls under the \"Computer and Network Usage Policy\", as described in the Stanford Administrative Guide . In particular, sharing authentication credentials is strictly prohibited. Violation of this policy will result in termination of access to Sherlock. Sherlock has been designed, deployed, and is maintained and operated by the Stanford Research Computing Center ( SRCC ) staff. The SRCC is a joint effort of the Dean of Research and IT Services to build and support a comprehensive program to advance computational research at Stanford. Sherlock has been initially purchased and supported with seed funding from Stanford's Provost . It comprises a set of freely available compute nodes, a few specific resources such as large-memory machines and GPU servers, as well as the associated networking equipment and storage. These resources can be used to run computational codes and programs, and are managed through a job scheduler using a fair-share algorithm .","title":"Sherlock, a shared resource"},{"location":"docs/overview/concepts/#data-risk-classification","text":"Low and Moderate Risk data Sherlock is approved for computing with Low and Moderate Risk data only. High Risk data Sherlock is NOT approved to store or process HIPAA , PHI , PII nor any kind of High Risk data. The system is approved for computing with Low and Moderate Risk data only, and is not suitable to process High Risk data . Users are responsible for ensuring the compliance of their own data. For more information about data risk classifications, see the Information Security Risk Classification page .","title":"Data risk classification"},{"location":"docs/overview/concepts/#investing-in-sherlock","text":"For users who need more than casual access to a shared computing environment, Sherlock also offers Faculty members the possibility to invest in additional, dedicated computing resources. Unlike traditional clusters, Sherlock is a collaborative system where the majority of nodes are purchased and shared by the cluster users. When a user (typically a PI ) purchases one or more nodes, they become an owner . Owners choose from a standard set of server configurations supported by SRCC staff (known as the Sherlock catalog ) to add to the cluster. When they're not in use, PI -purchased compute nodes can be used by other owners. This model also allows Sherlock owners to benefit from the scale of the cluster by giving them access to more compute nodes than their individual purchase, which gives them much greater flexibility than owning a standalone cluster. The majority of Sherlock nodes are owners nodes The vast majority of Sherlock's compute nodes have been purchased by individual PIs and groups, and PI purchases are the main driver behind the rapid expansion of the cluster, which went from 120 nodes to more than 1,000 nodes in less than 3 years. The resource scheduler configuration works like this: owners and their research teams get immediate and exclusive access to the resources they purchased, when those nodes are idle, other owners can use them, when the purchasing owners want to use their resources, jobs from other owners that may be running on them are preempted ( ie. killed and re-queued). This provides a way to get more resources to run less important jobs in the background, while making sure that an owner always gets immediate access to his/her own nodes. Participating owners also have shared access to the public, shared Sherlock nodes, along with everyone else.","title":"Investing in Sherlock"},{"location":"docs/overview/concepts/#benefits","text":"Benefits to owners include: no wait time in queue with immediate and exclusive access to the purchased nodes access to more resources with the possibility to submit jobs to the other owners' nodes when they're not in use Compared to hosting and managing computing resources on your own, purchasing nodes on Sherlock provides: data center hosting, including backup power and cooling system configuration, maintenance and administration hardware diagnostics and repairs Those benefits come in addition to the other Sherlock advantages: access to high-performance, large parallel scratch storage space access to snapshot'ed, replicated, enterprise-class storage space optimized software stack, especially tailored for a range of research needs tools to build and install additional software applications as needed user support","title":"Benefits"},{"location":"docs/overview/concepts/#limitations","text":"Being an owner on Sherlock is different from traditional server hosting. In particular, purchasing your own compute nodes on Sherlock will NOT provide: root access : owner nodes on Sherlock are still managed by SRCC in accordance with Stanford's Minimum Security Standards . Although users are welcome to install (or request) any software they may need, purchasing compute nodes on Sherlock does not allow root access to the nodes. running permanent services : permanent processes such as web servers or databases can only run on owner nodes through the scheduler, using recurring or persistent . Purchasing compute nodes on Sherlock does not provide a way to run anything that couldn't run on publicly-available nodes. direct network connectivity from the outside world: owners' nodes are connected to the Sherlock's internal network and are not directly accessible from the outside, which means that they can't host public services like web or application servers. scheduler bypass : jobs running on owners' nodes still need to be submitted to the scheduler. Direct shell access to the nodes is not possible outside of scheduled interactive sessions. persistent local storage : local storage space provided on the compute nodes is only usable for the duration of a job and cannot be used to store long-term data. additional storage space : purchasing compute nodes on Sherlock does not provide additional storage space. Please note that SRCC does offer the possibility for PIs to purchase their own storage space on Oak , for their long-term research data needs.","title":"Limitations"},{"location":"docs/overview/concepts/#purchasing-nodes","text":"If you are interested in becoming an owner, you can find the latest information about ordering Sherlock nodes on the ordering page . Feel free to contact us is you have any additional question.","title":"Purchasing nodes"},{"location":"docs/overview/concepts/#cluster-generations","text":"The research computing landscape evolves very quickly, and to both accommodate growth and technological advances, it's necessary to adapt the Sherlock environment to these evolutions. Every year or so, a new generation of processors is released, which is why, over a span of several years, multiple generations of CPUs and GPUs make their way into Sherlock. This provides users with access to the latest features and performance enhancements, but it also adds some heterogeneity to the cluster, which is important to keep in mind when compiling software and requesting resources to run them. Another key component of Sherlock is the interconnect network that links all of Sherlock's compute nodes together and act as a backbone for the whole cluster. This network fabric is of finite capacity, and based on the individual networking switches characteristics and the typical research computing workflows, it can accommodate up to about 850 compute nodes. As nodes get added to Sherlock, the number of available ports decreases, and at some point, the fabric gets full and no more nodes can be added. Sherlock reached that stage for the first time in late 2016, which prompted the installation of a whole new fabric, to allow for further system expansion. This kind of evolution is the perfect opportunity to upgrade other components too: management software, ancillary services architecture and user applications. In January 2017, those components were completely overhauled and a new, completely separate cluster was kick-started, using using a different set of hardware and software, while conserving the same storage infrastructure, to ease the transition process. After a transition period, the older Sherlock hardware, compute and login nodes, have been be merged in the new cluster, and from a logical perspective (connection, job scheduling and computing resources), nodes attached to each of the fabrics have been reunited to form a single cluster again. As Sherlock continues to evolve and grow, the new fabric will also approach capacity again, and the same process will happen again to start the next generation of Sherlock.","title":"Cluster generations"},{"location":"docs/overview/concepts/#maintenances-and-upgrades","text":"The SRCC institutes a monthly scheduled maintenance window on Sherlock, to ensure optimal operation, avoid potential issues and prepare for future expansions. This window will be used to make hardware repairs, software and firmware updates, and perform general manufacturer recommended maintenance on our environment. As often as possible, maintenance tasks are performed in a rolling, non-disruptive fashion, but downtimes are sometimes an unfortunate necessity to allow disruptive operations that can't be conducted while users are working on the system. Maintenance schedule As often as possible, maintenances will take place on the first Tuesday of every month, from 08:00 to 12:00 Pacific time (noon), and will be announced 2 weeks in advance, through the usual communication channels. In case an exceptional amount of work is required, the maintenance window could be extended to 10 hours (from 08:00 to 18:00). During these times, access to Sherlock will be unavailable, login will be disabled and jobs won't run. A reservation will be placed in the scheduler so running jobs can finish before the maintenance, and jobs that wouldn't finish by the maintenance window would be pushed after it.","title":"Maintenances and upgrades"},{"location":"docs/overview/concepts/#common-questions","text":"Q: Why doing maintenances at all? A : Due to the scale of our computing environment and the increasing complexity of the systems we deploy, it is prudent to arrange for a regular time when we can comfortably and without pressure fix problems or update facilities with minimal impact to our customers. Most, if not all, major HPC centers have regular maintenance schedules. We also need to enforce the Minimum Security rules instituted by the Stanford Information Security Office, which mandate deployment of security patches in a timely manner. Q: Why Tuesdays 08:00-12:00? Why not do this late at night? A: We have observed that the least busy time for our services is at the beginning of the week in the morning hours. Using this time period should not interrupt most of our users. If the remote possibility of a problem that extends past the scheduled downtime occurs, we would have our full staff fresh and available to assist in repairs and quickly restore service. Q: I have jobs running, what will happen to them? A: For long-running jobs, we strongly recommend checkpointing your results on a periodic basis. Besides, we will place a reservation in the scheduler for each maintenance that would prevent jobs to run past it. This means that the scheduler will only allow jobs to run if they can finish by the time the maintenance starts. If you submit a long job soon before the maintenance, it will be delayed until after the maintenance. That will ensure that no work is lost when the maintenance starts.","title":"Common questions"},{"location":"docs/overview/introduction/","text":"Sherlock documentation # @media only screen and (max-width: 720px) { #logo_head { display: none; } } # logo_head { margin-top: -50px; } Warning This guide is a work in progress and is not complete yet. We are actively working on adding more content and information. Welcome to Sherlock! # Sherlock is a High-Performance Computing ( HPC ) cluster, operated by the Stanford Research Computing Center to provide computing resources to the Stanford community at large. You'll find all the documentation, tips, FAQs and information about Sherlock among these pages. Why use Sherlock? # Using Sherlock for your work provides many advantages over individual solutions: hosted in an on-premises, state-of-the-art datacenter, the Sherlock cluster is powered and cooled by installations that are optimized for scientific computing. On Sherlock, simulations and workloads benefit from performance levels that only large scale HPC systems can offer: high-performance I/O infrastructure, petabytes of storage, large variety of hardware configurations, GPU accelerators, centralized system administration and management provided by the Stanford Research Computing Center ( SRCC ). Such features are not easily accessible at the departmental level, and often require both significant initial investments and recurring costs. Joining Sherlock allows researchers and faculty members to avoid those costs and benefit from economies of scale, as well as to access larger, professionally managed computing resources that what would not be available on an individual or even departmental basis. How much does it cost? # Sherlock is free to use for anyone doing sponsored research at Stanford. Any faculty member can request access for research purposes, and get an account with a base storage allocation and unlimited compute time on the global, shared pool of resources. No CPU .hour charge Unlike all Cloud Service Providers and many HPC systems, there is no usage charge on Sherlock. When you submit your work on Sherlock, you don't need to keep an eye on the clock and worry about how much that run will cost you. There is no limit on the total amount of computing you can run on the cluster, as long as resources are available, and there's no charge to use them, no matter how large or small your computations are. In case those free resources are not sufficient, Stanford Research Computing offers Faculty members the opportunity to invest into the cluster, and get access to additional computing resources for their research teams. Using a traditional compute cluster condominium model, participating faculty and their teams get priority access to the resources they purchase. When they're idle, those resources are available to use by other owners on the cluster, giving them access to virtually unlimited resources. Information sources # Searching the docs If you're looking for information on a specific topic, the Search feature of this site will allow you to quickly find the page you're looking for. Just press S or F to open the Search bar and start typing. To help users take their first steps on Sherlock, we provide documentation and information through various channels: Channel URL Purpose Documentation You are here www.sherlock.stanford.edu/docs information to help new users start on Sherlock, and more in-depth documentation for users already familiar with the environment. Changelog news.sherlock.stanford.edu announces, news and updates about Sherlock. Dashboard status.sherlock.stanford.edu status of Sherlock's main components and services, outages, maintenances. To get started, you can take a look at the concepts and glossary pages to get familiar with the terminology used throughout the documentation pages. Then, we recommend going through the following sections: Prerequisites Connecting to the cluster Submitting jobs Acknowledgment / citation # It is important and expected that publications resulting from computations performed on Sherlock acknowledge this. The following wording is suggested: Acknowledgment Some of the computing for this project was performed on the Sherlock cluster. We would like to thank Stanford University and the Stanford Research Computing Center for providing computational resources and support that contributed to these research results. Support # Email (recommended) # Research Computing support can be reached by sending an email to srcc-support@stanford.edu and mentioning Sherlock . How to submit effective support requests To ensure a timely and relevant response, please make sure to include some additional details, such as job ids, commands executed and error messages received, so we can help you better. For more details, see the Troubleshooting page. As a member of the Sherlock community, you're also automatically subscribed to the sherlock-announce mailing-list, which is only used by the SRCC team to send important announcements about Sherlock, Office hours # COVID-19 update We'll be holding remote office hours via Zoom , for the time being. Sending a question to srcc-support@stanford.edu is always the best first option for questions. That way you can include detailed descriptions of the problem or question, valuable output and error messages and any steps you took when you encountered your error. Also, everyone on our team will see your ticket, enabling the most appropriate group member to respond. Office hours are a good place for more generalized questions about Sherlock, Slurm, Linux usage, data storage, queue structures/scheduling, job optimization and general capabilities of Sherlock. It's also useful for more technically nuanced questions that may not be easily answered with our ticketing system. In office hours some problems can indeed be solved quickly or progress can be made so that you can then work self-sufficiently towards a solution on your own. Office hours times Click here to join the Sherlock Office Hours Zoom Tuesday 10-11am Thursday 3-4pm You can also make an appointment with Sherlock's support team if you'd like. What to expect from office hours We can't accomodate walk-ins: we're unfortunately not staffed to accommodate walk-ins, so please make sure that you're planning to stop by during office hours. We will not be able to help you otherwise. We can rarely help with application-specific or algorithm problems. You should plan your projects sufficiently in advance and not come to office hours at the last minute before a deadline. Sherlock is a busy resource with several thousand users and you should not expect your jobs to complete before a given date. Not all questions and problems can be solved or answered during office hours, especially ones involving hardware, filesystem or network issues. Sherlock features several thousand computing, networking and storage components, that are constantly being monitored by our team. You can be sure that when Sherlock has an issue, we are aware of it and working on it. User community # Sherlock is present on the Stanford Slack Grid , and you're more than welcome to join the following channels: #sherlock-announce , for announcements related to Sherlock and its surrounding services, #sherlock-users , as a place for Sherlock users to connect directly with each other. If you have a general question about software used on Sherlock, want to reach out to other Sherlock users to share tips, good practices, tutorials or other info, please feel free to do so there. For more details about the SRCC Slack Workspace, and instructions on how to join this workspace and its channels, please see https://srcc.stanford.edu/support . Slack is not an official support channel Please note that while SRCC staff will monitor these channels, the official way to get support is still to email us at srcc-support@stanford.edu . Quick Start # If you're in a rush 1 , here's a 3-step ultra-quick start: connect to Sherlock $ ssh login.sherlock.stanford.edu get an interactive session on a compute node [ kilian@sh-ln01 login! ~ ] $ sdev run a command [ kilian@sh02-01n58 ~ ] $ module load python [ kilian@sh02-01n58 ~ ] $ python -c \"print('Hello Sherlock')\" Hello Sherlock Congrats! You ran your first job on Sherlock! Replay # Here's what it looks like in motion: even in a rush, you'll still need an account on the cluster. See the Prerequisites page for details. \u21a9","title":"Introduction"},{"location":"docs/overview/introduction/#sherlock-documentation","text":"@media only screen and (max-width: 720px) { #logo_head { display: none; } } # logo_head { margin-top: -50px; } Warning This guide is a work in progress and is not complete yet. We are actively working on adding more content and information.","title":"Sherlock documentation"},{"location":"docs/overview/introduction/#welcome-to-sherlock","text":"Sherlock is a High-Performance Computing ( HPC ) cluster, operated by the Stanford Research Computing Center to provide computing resources to the Stanford community at large. You'll find all the documentation, tips, FAQs and information about Sherlock among these pages.","title":"Welcome to Sherlock!"},{"location":"docs/overview/introduction/#why-use-sherlock","text":"Using Sherlock for your work provides many advantages over individual solutions: hosted in an on-premises, state-of-the-art datacenter, the Sherlock cluster is powered and cooled by installations that are optimized for scientific computing. On Sherlock, simulations and workloads benefit from performance levels that only large scale HPC systems can offer: high-performance I/O infrastructure, petabytes of storage, large variety of hardware configurations, GPU accelerators, centralized system administration and management provided by the Stanford Research Computing Center ( SRCC ). Such features are not easily accessible at the departmental level, and often require both significant initial investments and recurring costs. Joining Sherlock allows researchers and faculty members to avoid those costs and benefit from economies of scale, as well as to access larger, professionally managed computing resources that what would not be available on an individual or even departmental basis.","title":"Why use Sherlock?"},{"location":"docs/overview/introduction/#how-much-does-it-cost","text":"Sherlock is free to use for anyone doing sponsored research at Stanford. Any faculty member can request access for research purposes, and get an account with a base storage allocation and unlimited compute time on the global, shared pool of resources. No CPU .hour charge Unlike all Cloud Service Providers and many HPC systems, there is no usage charge on Sherlock. When you submit your work on Sherlock, you don't need to keep an eye on the clock and worry about how much that run will cost you. There is no limit on the total amount of computing you can run on the cluster, as long as resources are available, and there's no charge to use them, no matter how large or small your computations are. In case those free resources are not sufficient, Stanford Research Computing offers Faculty members the opportunity to invest into the cluster, and get access to additional computing resources for their research teams. Using a traditional compute cluster condominium model, participating faculty and their teams get priority access to the resources they purchase. When they're idle, those resources are available to use by other owners on the cluster, giving them access to virtually unlimited resources.","title":"How much does it cost?"},{"location":"docs/overview/introduction/#information-sources","text":"Searching the docs If you're looking for information on a specific topic, the Search feature of this site will allow you to quickly find the page you're looking for. Just press S or F to open the Search bar and start typing. To help users take their first steps on Sherlock, we provide documentation and information through various channels: Channel URL Purpose Documentation You are here www.sherlock.stanford.edu/docs information to help new users start on Sherlock, and more in-depth documentation for users already familiar with the environment. Changelog news.sherlock.stanford.edu announces, news and updates about Sherlock. Dashboard status.sherlock.stanford.edu status of Sherlock's main components and services, outages, maintenances. To get started, you can take a look at the concepts and glossary pages to get familiar with the terminology used throughout the documentation pages. Then, we recommend going through the following sections: Prerequisites Connecting to the cluster Submitting jobs","title":"Information sources"},{"location":"docs/overview/introduction/#acknowledgment-citation","text":"It is important and expected that publications resulting from computations performed on Sherlock acknowledge this. The following wording is suggested: Acknowledgment Some of the computing for this project was performed on the Sherlock cluster. We would like to thank Stanford University and the Stanford Research Computing Center for providing computational resources and support that contributed to these research results.","title":"Acknowledgment / citation"},{"location":"docs/overview/introduction/#support","text":"","title":"Support"},{"location":"docs/overview/introduction/#email-recommended","text":"Research Computing support can be reached by sending an email to srcc-support@stanford.edu and mentioning Sherlock . How to submit effective support requests To ensure a timely and relevant response, please make sure to include some additional details, such as job ids, commands executed and error messages received, so we can help you better. For more details, see the Troubleshooting page. As a member of the Sherlock community, you're also automatically subscribed to the sherlock-announce mailing-list, which is only used by the SRCC team to send important announcements about Sherlock,","title":"Email (recommended)"},{"location":"docs/overview/introduction/#office-hours","text":"COVID-19 update We'll be holding remote office hours via Zoom , for the time being. Sending a question to srcc-support@stanford.edu is always the best first option for questions. That way you can include detailed descriptions of the problem or question, valuable output and error messages and any steps you took when you encountered your error. Also, everyone on our team will see your ticket, enabling the most appropriate group member to respond. Office hours are a good place for more generalized questions about Sherlock, Slurm, Linux usage, data storage, queue structures/scheduling, job optimization and general capabilities of Sherlock. It's also useful for more technically nuanced questions that may not be easily answered with our ticketing system. In office hours some problems can indeed be solved quickly or progress can be made so that you can then work self-sufficiently towards a solution on your own. Office hours times Click here to join the Sherlock Office Hours Zoom Tuesday 10-11am Thursday 3-4pm You can also make an appointment with Sherlock's support team if you'd like. What to expect from office hours We can't accomodate walk-ins: we're unfortunately not staffed to accommodate walk-ins, so please make sure that you're planning to stop by during office hours. We will not be able to help you otherwise. We can rarely help with application-specific or algorithm problems. You should plan your projects sufficiently in advance and not come to office hours at the last minute before a deadline. Sherlock is a busy resource with several thousand users and you should not expect your jobs to complete before a given date. Not all questions and problems can be solved or answered during office hours, especially ones involving hardware, filesystem or network issues. Sherlock features several thousand computing, networking and storage components, that are constantly being monitored by our team. You can be sure that when Sherlock has an issue, we are aware of it and working on it.","title":"Office hours"},{"location":"docs/overview/introduction/#user-community","text":"Sherlock is present on the Stanford Slack Grid , and you're more than welcome to join the following channels: #sherlock-announce , for announcements related to Sherlock and its surrounding services, #sherlock-users , as a place for Sherlock users to connect directly with each other. If you have a general question about software used on Sherlock, want to reach out to other Sherlock users to share tips, good practices, tutorials or other info, please feel free to do so there. For more details about the SRCC Slack Workspace, and instructions on how to join this workspace and its channels, please see https://srcc.stanford.edu/support . Slack is not an official support channel Please note that while SRCC staff will monitor these channels, the official way to get support is still to email us at srcc-support@stanford.edu .","title":"User community"},{"location":"docs/overview/introduction/#quick-start","text":"If you're in a rush 1 , here's a 3-step ultra-quick start: connect to Sherlock $ ssh login.sherlock.stanford.edu get an interactive session on a compute node [ kilian@sh-ln01 login! ~ ] $ sdev run a command [ kilian@sh02-01n58 ~ ] $ module load python [ kilian@sh02-01n58 ~ ] $ python -c \"print('Hello Sherlock')\" Hello Sherlock Congrats! You ran your first job on Sherlock!","title":"Quick Start"},{"location":"docs/overview/introduction/#replay","text":"Here's what it looks like in motion: even in a rush, you'll still need an account on the cluster. See the Prerequisites page for details. \u21a9","title":"Replay"},{"location":"docs/overview/orders/","text":"Ordering nodes on Sherlock # For research groups needing access to additional, dedicated computing resources on Sherlock, we offer the possibility for PIs to purchase their own compute nodes to add to the cluster. Operating costs for managing and housing PI-purchased compute nodes are waived in exchange for letting other users make use of any idle compute cycles on the PI-owned nodes. Owners have priority access to the computing resources they purchase, but can access more nodes for their research if they need to. This provides the PI with much greater flexibility than owning a standalone cluster. Conditions # Service term # Compute nodes are purchased for a duration of 4 years Compute nodes are purchased and maintained based on a 4-year lifecycle, which is the duration of the equipment warranty and vendor support. Owners will be notified during the 4 th year that their nodes' lifetime is about to reach its term, at which point they'll be welcome to either: renew their investment by purchasing new nodes, continue to use the public portion of Sherlock's resources. At the end of their service term, compute nodes are physically retired from the cluster, to make room for new equipment. Compute nodes may be kept running for an additional year at most after the end of their service term, while PIs plan for equipment refresh. Nodes failing during this period may not be repaired, and failed hardware will be disabled or removed from the system. Please note that outside of exceptional circumstances, nodes purchased in Sherlock cannot be removed from cluster before the end of their service term. Shared ownership # Minimum order of one node per PI The number of nodes in a shared order must be greater or equal to the number of purchasing PI groups. For operational, administrative as well as usability reasons, we do not support shared ownership of equipment. Meaning that multiple PI groups cannot purchase and share a single compute node. Shared orders have a minimum of one node per purchasing PI group. Compute nodes catalog # SRCC offers a select number of compute node configurations that have been tested and validated on Sherlock and that aim to cover most computing needs. Sherlock catalog Complete details are available in the Sherlock compute nodes catalog 3 Configurations # We try to provide hardware configurations that can cover the needs and requirements of a wide range of computing applications, in various scientific fields, and to propose a spectrum of pricing tiers, as shown in the table below: Type Description Recommended usage Price range CBASE Base configuration Best per-core performance for serial applications, multi-threaded (OpenMP) and distributed (MPI) applications. Most flexible and cost-effective configuration $ CPERF High-end configuration Multi-threaded applications requiring higher numbers of CPU cores $$ CBIGMEM Large-memory configuration Serial or multi-threaded applications requiring terabytes of memory (genome assembly, etc...) $$$$ G4FP32 Base GPU configuration Single-precision (FP32) GPU-accelerated applications (CryoEM, MD...) with low GPU memory requirements $$ G4FP64 HPC GPU configuration AI, ML/DL and GPU-accelerated HPC codes requiring double-precision (FP64) and larger amounts of GPU memory $$$ G4TF64 G8TF64 Best-in-class GPU configuration AI, ML/DL and GPU-accelerated HPC codes requiring double-precision (FP64), large amounts of GPU memory, and heavy multi-GPU scaling $$$$ Choosing the best node configuration for your needs Although some configurations may appear cheaper when looking at the dollar/core ratio, this is not the only point to consider when determining the best configuration for your workload. Performance per core There are other factors to take into account, notably the memory and I/O bandwidth per core, which could be lower on higher core-count configurations like CPERF . With multiple times more cores than CBASE , they still provide the same total amount of bandwidth to remote and local storage, as well as, to a lesser extend, to memory. Higher core-count CPUs also often offer lower core frequencies, which combined with less bandwidth per core, may result in lower performance for serial jobs. CPERF nodes are an excellent fit for multi-threaded applications that don't span multiple nodes. But for more diverse workloads, they don't offer the same level of flexibility than the CBASE nodes, which can run a mix of serial, multi-threaded and MPI applications equally well. Resources availability Another important factor to take into account is that less nodes for a given number of cores offers less resilience against potential hardware failures: if a 128-core node becomes unavailable for some reason, that's 128 cores that nobody can use while the node is being repaired. But with 128 cores in 4x 32-core nodes, if a node fails, there are still 96 cores that can be used. We'll be happy to help you determine the best configuration for your computing needs, feel free to reach out to schedule a consultation. Configuration details for the different compute node types are listed in the Sherlock compute nodes catalog 3 Prices # Prices for the different compute node types are listed in the Sherlock compute nodes catalog 3 . They include tax and shipping fees, and are subject to change when quoted: they tend to follow the market-wide variations induced by global political and economical events, which are way outside of our control. Prices are provided there as a guideline for expectations. There are two components in the cost of a compute node purchase: the cost of the hardware itself (capital purchase), a one-time, per-node infrastructure fee 1 that will be charged to cover the costs of connecting the nodes to the cluster infrastructure (racks, PDUs, networking switches, cables...) No recurring fees There is currently no recurring fee associated with purchasing compute nodes on Sherlock. In particular, there is no CPU.hour charge, purchased nodes are available to their owners 100% of the time, at no additional cost. Currently, there are no user, administrative or management fees associated with ongoing system administration of the Sherlock environment. However, PIs should anticipate the eventuality of modest system administration and support fees being levied within the 4 year lifetime of their compute nodes. Purchasing process # Purchasing nodes on Sherlock is usually a 5-step process: the PI use the order form to submit an order, SRCC requests a formal vendor quote to finalize pricing and communicate it back to the PI for approval, SRCC submits a Stanford PO to the vendor, SRCC takes delivery of the hardware and proceeds to its installation, SRCC notifies the PI that their nodes are ready to be used. The typical delay between a PO submission to the vendor and the availability of the compute nodes to the PIs is usually between 4 and 8 weeks (global pandemic-related supply-chain disruptions notwithstanding). Minimum purchase Please note that the minimum purchase is one physical server per PI group. We cannot accommodate multiple PIs pooling funds for a single node. Single-node orders may incur additional delays Some node configurations need to be ordered from the vendor by sets of 4 nodes (see the Sherlock catalog for details). So orders for quantities non-multiples of 4 need will to be grouped with other PI's orders, which may incur additional delays. Required information # To place an order, we'll need the following information: The SUNet ID of the PI making the purchase request A PTA 2 number to charge the hardware (capital) portion of the purchase A PTA 2 number to charge the per-node infrastructure fees (non-capital) It could be the same PTA used for the capital portion of the purchase, or a different one Placing an order # To start ordering compute nodes for Sherlock: .md-button { min-width: 8rem; text-align: center; } .steps { width: 50%; padding: 10px; } @media screen and (max-width: 992px) { .steps { width: 100%; float: none !important; } } check the Sherlock catalog 3 to review prices and select your configurations Choose fill in the order form 3 to submit your request and provide the required information Order And we'll be in touch shortly! infrastructure fees are considered non-capital for cost accounting purposes and may incur indirect cost burdens on cost-reimbursable contracts and grants. \u21a9 PTA is an acronym used for a Project-Task-Award combination representing an account in the Stanford Financial system. \u21a9 \u21a9 SUNet ID required , document restricted to @stanford.edu accounts. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9","title":"Process"},{"location":"docs/overview/orders/#ordering-nodes-on-sherlock","text":"For research groups needing access to additional, dedicated computing resources on Sherlock, we offer the possibility for PIs to purchase their own compute nodes to add to the cluster. Operating costs for managing and housing PI-purchased compute nodes are waived in exchange for letting other users make use of any idle compute cycles on the PI-owned nodes. Owners have priority access to the computing resources they purchase, but can access more nodes for their research if they need to. This provides the PI with much greater flexibility than owning a standalone cluster.","title":"Ordering nodes on Sherlock"},{"location":"docs/overview/orders/#conditions","text":"","title":"Conditions"},{"location":"docs/overview/orders/#service-term","text":"Compute nodes are purchased for a duration of 4 years Compute nodes are purchased and maintained based on a 4-year lifecycle, which is the duration of the equipment warranty and vendor support. Owners will be notified during the 4 th year that their nodes' lifetime is about to reach its term, at which point they'll be welcome to either: renew their investment by purchasing new nodes, continue to use the public portion of Sherlock's resources. At the end of their service term, compute nodes are physically retired from the cluster, to make room for new equipment. Compute nodes may be kept running for an additional year at most after the end of their service term, while PIs plan for equipment refresh. Nodes failing during this period may not be repaired, and failed hardware will be disabled or removed from the system. Please note that outside of exceptional circumstances, nodes purchased in Sherlock cannot be removed from cluster before the end of their service term.","title":"Service term"},{"location":"docs/overview/orders/#shared-ownership","text":"Minimum order of one node per PI The number of nodes in a shared order must be greater or equal to the number of purchasing PI groups. For operational, administrative as well as usability reasons, we do not support shared ownership of equipment. Meaning that multiple PI groups cannot purchase and share a single compute node. Shared orders have a minimum of one node per purchasing PI group.","title":"Shared ownership"},{"location":"docs/overview/orders/#compute-nodes-catalog","text":"SRCC offers a select number of compute node configurations that have been tested and validated on Sherlock and that aim to cover most computing needs. Sherlock catalog Complete details are available in the Sherlock compute nodes catalog 3","title":"Compute nodes catalog"},{"location":"docs/overview/orders/#configurations","text":"We try to provide hardware configurations that can cover the needs and requirements of a wide range of computing applications, in various scientific fields, and to propose a spectrum of pricing tiers, as shown in the table below: Type Description Recommended usage Price range CBASE Base configuration Best per-core performance for serial applications, multi-threaded (OpenMP) and distributed (MPI) applications. Most flexible and cost-effective configuration $ CPERF High-end configuration Multi-threaded applications requiring higher numbers of CPU cores $$ CBIGMEM Large-memory configuration Serial or multi-threaded applications requiring terabytes of memory (genome assembly, etc...) $$$$ G4FP32 Base GPU configuration Single-precision (FP32) GPU-accelerated applications (CryoEM, MD...) with low GPU memory requirements $$ G4FP64 HPC GPU configuration AI, ML/DL and GPU-accelerated HPC codes requiring double-precision (FP64) and larger amounts of GPU memory $$$ G4TF64 G8TF64 Best-in-class GPU configuration AI, ML/DL and GPU-accelerated HPC codes requiring double-precision (FP64), large amounts of GPU memory, and heavy multi-GPU scaling $$$$ Choosing the best node configuration for your needs Although some configurations may appear cheaper when looking at the dollar/core ratio, this is not the only point to consider when determining the best configuration for your workload. Performance per core There are other factors to take into account, notably the memory and I/O bandwidth per core, which could be lower on higher core-count configurations like CPERF . With multiple times more cores than CBASE , they still provide the same total amount of bandwidth to remote and local storage, as well as, to a lesser extend, to memory. Higher core-count CPUs also often offer lower core frequencies, which combined with less bandwidth per core, may result in lower performance for serial jobs. CPERF nodes are an excellent fit for multi-threaded applications that don't span multiple nodes. But for more diverse workloads, they don't offer the same level of flexibility than the CBASE nodes, which can run a mix of serial, multi-threaded and MPI applications equally well. Resources availability Another important factor to take into account is that less nodes for a given number of cores offers less resilience against potential hardware failures: if a 128-core node becomes unavailable for some reason, that's 128 cores that nobody can use while the node is being repaired. But with 128 cores in 4x 32-core nodes, if a node fails, there are still 96 cores that can be used. We'll be happy to help you determine the best configuration for your computing needs, feel free to reach out to schedule a consultation. Configuration details for the different compute node types are listed in the Sherlock compute nodes catalog 3","title":"Configurations"},{"location":"docs/overview/orders/#prices","text":"Prices for the different compute node types are listed in the Sherlock compute nodes catalog 3 . They include tax and shipping fees, and are subject to change when quoted: they tend to follow the market-wide variations induced by global political and economical events, which are way outside of our control. Prices are provided there as a guideline for expectations. There are two components in the cost of a compute node purchase: the cost of the hardware itself (capital purchase), a one-time, per-node infrastructure fee 1 that will be charged to cover the costs of connecting the nodes to the cluster infrastructure (racks, PDUs, networking switches, cables...) No recurring fees There is currently no recurring fee associated with purchasing compute nodes on Sherlock. In particular, there is no CPU.hour charge, purchased nodes are available to their owners 100% of the time, at no additional cost. Currently, there are no user, administrative or management fees associated with ongoing system administration of the Sherlock environment. However, PIs should anticipate the eventuality of modest system administration and support fees being levied within the 4 year lifetime of their compute nodes.","title":"Prices"},{"location":"docs/overview/orders/#purchasing-process","text":"Purchasing nodes on Sherlock is usually a 5-step process: the PI use the order form to submit an order, SRCC requests a formal vendor quote to finalize pricing and communicate it back to the PI for approval, SRCC submits a Stanford PO to the vendor, SRCC takes delivery of the hardware and proceeds to its installation, SRCC notifies the PI that their nodes are ready to be used. The typical delay between a PO submission to the vendor and the availability of the compute nodes to the PIs is usually between 4 and 8 weeks (global pandemic-related supply-chain disruptions notwithstanding). Minimum purchase Please note that the minimum purchase is one physical server per PI group. We cannot accommodate multiple PIs pooling funds for a single node. Single-node orders may incur additional delays Some node configurations need to be ordered from the vendor by sets of 4 nodes (see the Sherlock catalog for details). So orders for quantities non-multiples of 4 need will to be grouped with other PI's orders, which may incur additional delays.","title":"Purchasing process"},{"location":"docs/overview/orders/#required-information","text":"To place an order, we'll need the following information: The SUNet ID of the PI making the purchase request A PTA 2 number to charge the hardware (capital) portion of the purchase A PTA 2 number to charge the per-node infrastructure fees (non-capital) It could be the same PTA used for the capital portion of the purchase, or a different one","title":"Required information"},{"location":"docs/overview/orders/#placing-an-order","text":"To start ordering compute nodes for Sherlock: .md-button { min-width: 8rem; text-align: center; } .steps { width: 50%; padding: 10px; } @media screen and (max-width: 992px) { .steps { width: 100%; float: none !important; } } check the Sherlock catalog 3 to review prices and select your configurations Choose fill in the order form 3 to submit your request and provide the required information Order And we'll be in touch shortly! infrastructure fees are considered non-capital for cost accounting purposes and may incur indirect cost burdens on cost-reimbursable contracts and grants. \u21a9 PTA is an acronym used for a Project-Task-Award combination representing an account in the Stanford Financial system. \u21a9 \u21a9 SUNet ID required , document restricted to @stanford.edu accounts. \u21a9 \u21a9 \u21a9 \u21a9 \u21a9","title":"Placing an order"},{"location":"docs/overview/tech/facts/","text":"Sherlock facts # as of May 2021 .facts { width: 50%; padding-right: 4em; } @media screen and (max-width: 992px) { .facts { width: 100%; padding-right: 2em; float: none !important; } } Users # 5,483 user accounts 888 PI groups from all Stanford's seven Schools, SLAC, Stanford Institutes, etc. 173 owner groups Interfaces # 14 login nodes 3 data transfer nodes (DTNs) Computing # 3.36 PFLOPs FP64 1,666 compute nodes 20 server models (from 3 different manufacturers) 44,032 CPU cores 4 CPU generations ( 14 CPU models) 712 GPUs 6 GPU generations ( 12 GPU models) 44 racks 59 PDUs ( 425.82 kW of average power) Storage # 6.1 PB $SCRATCH parallel, distributed filesystem, delivering over 200 GB/s of I/O bandwidth 26.3 PB $OAK long term research data storage Networking # 121 Infiniband switches across 4 Infiniband fabrics (EDR, FDR, HDR) 5,749 Infiniband cables spanning about 30.45 km 58 Ethernet switches Scheduler # 142 Slurm partitions 133,228,305 CPU.hours used in the last 6 months, that's over 15,208 years of computing!","title":"Facts"},{"location":"docs/overview/tech/facts/#sherlock-facts","text":"as of May 2021 .facts { width: 50%; padding-right: 4em; } @media screen and (max-width: 992px) { .facts { width: 100%; padding-right: 2em; float: none !important; } }","title":"Sherlock facts"},{"location":"docs/overview/tech/facts/#users","text":"5,483 user accounts 888 PI groups from all Stanford's seven Schools, SLAC, Stanford Institutes, etc. 173 owner groups","title":" Users"},{"location":"docs/overview/tech/facts/#interfaces","text":"14 login nodes 3 data transfer nodes (DTNs)","title":" Interfaces"},{"location":"docs/overview/tech/facts/#computing","text":"3.36 PFLOPs FP64 1,666 compute nodes 20 server models (from 3 different manufacturers) 44,032 CPU cores 4 CPU generations ( 14 CPU models) 712 GPUs 6 GPU generations ( 12 GPU models) 44 racks 59 PDUs ( 425.82 kW of average power)","title":" Computing"},{"location":"docs/overview/tech/facts/#storage","text":"6.1 PB $SCRATCH parallel, distributed filesystem, delivering over 200 GB/s of I/O bandwidth 26.3 PB $OAK long term research data storage","title":" Storage"},{"location":"docs/overview/tech/facts/#networking","text":"121 Infiniband switches across 4 Infiniband fabrics (EDR, FDR, HDR) 5,749 Infiniband cables spanning about 30.45 km 58 Ethernet switches","title":" Networking"},{"location":"docs/overview/tech/facts/#scheduler","text":"142 Slurm partitions 133,228,305 CPU.hours used in the last 6 months, that's over 15,208 years of computing!","title":" Scheduler"},{"location":"docs/overview/tech/glossary/","text":"What's a cluster? # A computing cluster is a federation of multiple compute nodes (independent computers), most commonly linked together through a high-performance interconnect network. What makes it a \"super-computer\" is the ability for a program to address resources (such as memory, CPU cores) located in different compute nodes, through the high-performance interconnect network. On a computing cluster, users typically connect to login nodes , using a secure remote login protocol such as SSH . Unlike in traditional interactive environments, users then need to prepare compute jobs to submit to a resource scheduler . Based on a set of rules and limits, the scheduler will then try to match the jobs' resource requirements with available resources such as CPUs , memory or computing accelerators such as GPUs . It will then execute the user defined tasks on the selected resources, and generate output files in one of the different storage locations available on the cluster, for the user to review and analyze. Cluster components # The terms that are typically used to describe cluster components could be confusing, so in an effort to clarify things, here's a schema of the most important ones, and their definition. CPU # A Central Processing Unit ( CPU ), or core, or CPU core, is the smallest unit in a microprocessor that can carry out computational tasks, that is, run programs. Modern processors typically have multiple cores. Socket # A socket is the connector that houses the microprocessor. By extension, it represents the physical package of a processor, that typically contains multiple cores. Node # A node is a physical, stand-alone computer, that can handle computing tasks and run jobs. It's connected to other compute nodes via a fast network interconnect, and contains CPUs, memory and devices managed by an operating system. Cluster # A cluster is the complete collection of nodes with networking and file storage facilities. It's usually a group of independent computers connected via a fast network interconnect, managed by a resource manager, which acts as a large parallel computer. Other commonly used terms # To make this documentation more accessible, we try to explain key terms in a non-technical way. When reading these pages, please keep in mind the following definitions, presented in alphabetical order: Application # An application is a computer program designed to perform a group of coordinated functions, tasks, or activities for the benefit of the user. In the context of scientific computing, an application typically performs computations related to a scientific goal (molecular dynamics simulations, genome assembly, compuational fluid dynamics simulations, etc). Backfill # Backfill scheduling is a method that a scheduler can use in order to maximize utilization. It allows smaller (both in terms of size and time requirements), lower priority jobs to start before larger, higher priority ones, as long as doing so doesn't push back the higher-priority jobs expected start time. Executable # A binary (or executable) program refers to the machine-code compiled version of an application. This is which is a binary file that a computer can execute directly. As opposed to the application source code, which is the human-readable version of the application internal instructions, and which needs to be compiled by a compiler to produce the executable binary. Fairshare # A resource scheduler ranks jobs by priority for execution. Each job's priority in queue is determined by multiple factors, among which one being the user's fairshare score. A user's fairshare score is computed based on a target (the given portion of the resources that this user should be able to use) and the user's effetive usage, ie the amount of resources (s)he effectively used in the past. As a result, the more resources past jobs have used, the lower the priority of the next jobs will be. Past usage is computed based on a sliding window and progressively forgotten over time. This enables all users on a shared resource to get a fair portion of it for their own use, by giving higher priorty to users who have been underserved in the past. FLOPS # Floating-point Operations Per Second (FLOPS) are a measure of computing performance, and represent the number of floating-point operations that a CPU can perform each second. Modern CPUs and GPUs are capable of doing TeraFLOPS (10^12 floating-point operations per second), depending on the precision of those operations (half-precision: 16 bits, single-precision: 32 bits, double-precision: 64 bits). GPU # A Graphical Processing Unit ( GPU ) is a specialized device initially designed to generate graphical output. On modern computing architecture, they are used to accelerate certain types of computation, which they are much faster than CPUs at. GPUs have their own memory, and are attached to CPUs, within a node. Each compute node can host one or more GPUs. HPC # High Performance Computing ( HPC ) refers to the practice of aggregating computing power to achieve higher performance that would be possible by using a typical computer. Infiniband # Infiniband is a networking standard that features high bandwidth and low latency. The current Infiniband devices are capable of transferring data at up to 200 Gbits/sec with less than a microsecond latency. As of this writing, the popular Infiniband versions are HDR (High Data Rate) with 200 Gbits/sec and EDR (Enhanced Data Rate) with 100 Gbits/sec. IOPS # Input/output operations per second (IOPS, pronounced eye-ops) is an input/output performance measurement used to characterize computer storage system performance. Job # A job, or batch job, is the scheduler\u2019s base unit of computing by which resources are allocated to a user for a specified amount of time. Users create job submission scripts to ask the scheduler for resources such as cores, memory, runtime, etc. The scheduler puts the requests in a queue and allocates requested resources based on jobs\u2019 priority. Job step # Job steps are sets of (possibly parallel) tasks within a job Login nodes # Login nodes are points of access to a compute cluster. Users usually connect to login nodes via SSH to compile and debug their code, review their results, do some simple tests, and submit their batch jobs to the parallel computer. Login nodes are not for computing Login nodes are usually shared among many users and therefore must not be used to run computationally intensive tasks. Those should be submitted to the scheduler which will dispatch them on compute nodes. Modules # Environment modules, or software modules, are a type of software management tool used on in most HPC environments. Using modules enable users to selectively pick the software that they want to use and add them to their environment. This allows to switch between different versions or flavors of the same software, pick compilers, libraries and software components and avoid conflicts between them. MPI # Message Passing Interface ( MPI ) is a standardized and portable message-passing system designed to exchange information between processes running on different nodes. There are several implementations of the MPI standard, which is the most common way used to scale parallel applications beyond a single compute node. OpenMP # Open Multi Processing (OpenMP) is a parallel programming model designed for shared memory architecture. It's based on pragmas that can be added in applications to let the compiler generate a code that can run on multiple cores, within the same node. Partition # A partition is a set of compute nodes within a cluster with a common feature. For example, compute nodes with GPU , or compute nodes belonging to same owner, could form a partition. On Sherlock, you can see detailed partition information with the sh_part or sinfo commands. QOS # A Quality Of Service (QOS) is the set of rules and limitations that apply to a categories of job. The combination of a partition (set of machines where a job can run) and QOS (set of rules that applies to that job) makes what is often referred to as a scheduler queue . Run time # The run time, or walltime, of a job is the time required to finish its execution. Scheduler # The goal of a job scheduler is to find the appropriate resources to run a set of computational tasks in the most efficient manner. Based on resource requirements and job descriptions, it will prioritize those jobs, allocate resources (nodes, CPUs, memory) and schedule their execution. Slurm # Simple Linux Utility for Resource Management (SLURM) is a software that manages computing resources and schedule tasks on them. Slurm coordinates running of many programs on a shared facility and makes sure that resources are used in an optimal manner. SSH # Secure Shell ( SSH ) is a protocol to securely access remote computers. Based on the client-server model, multiple users with an SSH client can access a remote computer. Some operating systems such as Linux and Mac OS have a built-in SSH client and others can use one of many publicly available clients. Thread # A process, in the simplest terms, is an executing program. One or more threads run in the context of the process. A thread is the basic unit to which the operating system allocates processor time. A thread can execute any part of the process code, including parts currently being executed by another thread. Threads are co-located on the same node. Task # In the Slurm context, a task is to be understood as a process. A multi-process program is made of several tasks. A task is typically used to schedule a MPI process, that in turn can use several CPUs. By contrast, a multi-threaded program is composed of only one task, which uses several CPUs.","title":"Glossary"},{"location":"docs/overview/tech/glossary/#whats-a-cluster","text":"A computing cluster is a federation of multiple compute nodes (independent computers), most commonly linked together through a high-performance interconnect network. What makes it a \"super-computer\" is the ability for a program to address resources (such as memory, CPU cores) located in different compute nodes, through the high-performance interconnect network. On a computing cluster, users typically connect to login nodes , using a secure remote login protocol such as SSH . Unlike in traditional interactive environments, users then need to prepare compute jobs to submit to a resource scheduler . Based on a set of rules and limits, the scheduler will then try to match the jobs' resource requirements with available resources such as CPUs , memory or computing accelerators such as GPUs . It will then execute the user defined tasks on the selected resources, and generate output files in one of the different storage locations available on the cluster, for the user to review and analyze.","title":"What's a cluster?"},{"location":"docs/overview/tech/glossary/#cluster-components","text":"The terms that are typically used to describe cluster components could be confusing, so in an effort to clarify things, here's a schema of the most important ones, and their definition.","title":"Cluster components"},{"location":"docs/overview/tech/glossary/#cpu","text":"A Central Processing Unit ( CPU ), or core, or CPU core, is the smallest unit in a microprocessor that can carry out computational tasks, that is, run programs. Modern processors typically have multiple cores.","title":"CPU"},{"location":"docs/overview/tech/glossary/#socket","text":"A socket is the connector that houses the microprocessor. By extension, it represents the physical package of a processor, that typically contains multiple cores.","title":"Socket"},{"location":"docs/overview/tech/glossary/#node","text":"A node is a physical, stand-alone computer, that can handle computing tasks and run jobs. It's connected to other compute nodes via a fast network interconnect, and contains CPUs, memory and devices managed by an operating system.","title":"Node"},{"location":"docs/overview/tech/glossary/#cluster","text":"A cluster is the complete collection of nodes with networking and file storage facilities. It's usually a group of independent computers connected via a fast network interconnect, managed by a resource manager, which acts as a large parallel computer.","title":"Cluster"},{"location":"docs/overview/tech/glossary/#other-commonly-used-terms","text":"To make this documentation more accessible, we try to explain key terms in a non-technical way. When reading these pages, please keep in mind the following definitions, presented in alphabetical order:","title":"Other commonly used terms"},{"location":"docs/overview/tech/glossary/#application","text":"An application is a computer program designed to perform a group of coordinated functions, tasks, or activities for the benefit of the user. In the context of scientific computing, an application typically performs computations related to a scientific goal (molecular dynamics simulations, genome assembly, compuational fluid dynamics simulations, etc).","title":"Application"},{"location":"docs/overview/tech/glossary/#backfill","text":"Backfill scheduling is a method that a scheduler can use in order to maximize utilization. It allows smaller (both in terms of size and time requirements), lower priority jobs to start before larger, higher priority ones, as long as doing so doesn't push back the higher-priority jobs expected start time.","title":"Backfill"},{"location":"docs/overview/tech/glossary/#executable","text":"A binary (or executable) program refers to the machine-code compiled version of an application. This is which is a binary file that a computer can execute directly. As opposed to the application source code, which is the human-readable version of the application internal instructions, and which needs to be compiled by a compiler to produce the executable binary.","title":"Executable"},{"location":"docs/overview/tech/glossary/#fairshare","text":"A resource scheduler ranks jobs by priority for execution. Each job's priority in queue is determined by multiple factors, among which one being the user's fairshare score. A user's fairshare score is computed based on a target (the given portion of the resources that this user should be able to use) and the user's effetive usage, ie the amount of resources (s)he effectively used in the past. As a result, the more resources past jobs have used, the lower the priority of the next jobs will be. Past usage is computed based on a sliding window and progressively forgotten over time. This enables all users on a shared resource to get a fair portion of it for their own use, by giving higher priorty to users who have been underserved in the past.","title":"Fairshare"},{"location":"docs/overview/tech/glossary/#flops","text":"Floating-point Operations Per Second (FLOPS) are a measure of computing performance, and represent the number of floating-point operations that a CPU can perform each second. Modern CPUs and GPUs are capable of doing TeraFLOPS (10^12 floating-point operations per second), depending on the precision of those operations (half-precision: 16 bits, single-precision: 32 bits, double-precision: 64 bits).","title":"FLOPS"},{"location":"docs/overview/tech/glossary/#gpu","text":"A Graphical Processing Unit ( GPU ) is a specialized device initially designed to generate graphical output. On modern computing architecture, they are used to accelerate certain types of computation, which they are much faster than CPUs at. GPUs have their own memory, and are attached to CPUs, within a node. Each compute node can host one or more GPUs.","title":"GPU"},{"location":"docs/overview/tech/glossary/#hpc","text":"High Performance Computing ( HPC ) refers to the practice of aggregating computing power to achieve higher performance that would be possible by using a typical computer.","title":"HPC"},{"location":"docs/overview/tech/glossary/#infiniband","text":"Infiniband is a networking standard that features high bandwidth and low latency. The current Infiniband devices are capable of transferring data at up to 200 Gbits/sec with less than a microsecond latency. As of this writing, the popular Infiniband versions are HDR (High Data Rate) with 200 Gbits/sec and EDR (Enhanced Data Rate) with 100 Gbits/sec.","title":"Infiniband"},{"location":"docs/overview/tech/glossary/#iops","text":"Input/output operations per second (IOPS, pronounced eye-ops) is an input/output performance measurement used to characterize computer storage system performance.","title":"IOPS"},{"location":"docs/overview/tech/glossary/#job","text":"A job, or batch job, is the scheduler\u2019s base unit of computing by which resources are allocated to a user for a specified amount of time. Users create job submission scripts to ask the scheduler for resources such as cores, memory, runtime, etc. The scheduler puts the requests in a queue and allocates requested resources based on jobs\u2019 priority.","title":"Job"},{"location":"docs/overview/tech/glossary/#job-step","text":"Job steps are sets of (possibly parallel) tasks within a job","title":"Job step"},{"location":"docs/overview/tech/glossary/#login-nodes","text":"Login nodes are points of access to a compute cluster. Users usually connect to login nodes via SSH to compile and debug their code, review their results, do some simple tests, and submit their batch jobs to the parallel computer. Login nodes are not for computing Login nodes are usually shared among many users and therefore must not be used to run computationally intensive tasks. Those should be submitted to the scheduler which will dispatch them on compute nodes.","title":"Login nodes"},{"location":"docs/overview/tech/glossary/#modules","text":"Environment modules, or software modules, are a type of software management tool used on in most HPC environments. Using modules enable users to selectively pick the software that they want to use and add them to their environment. This allows to switch between different versions or flavors of the same software, pick compilers, libraries and software components and avoid conflicts between them.","title":"Modules"},{"location":"docs/overview/tech/glossary/#mpi","text":"Message Passing Interface ( MPI ) is a standardized and portable message-passing system designed to exchange information between processes running on different nodes. There are several implementations of the MPI standard, which is the most common way used to scale parallel applications beyond a single compute node.","title":"MPI"},{"location":"docs/overview/tech/glossary/#openmp","text":"Open Multi Processing (OpenMP) is a parallel programming model designed for shared memory architecture. It's based on pragmas that can be added in applications to let the compiler generate a code that can run on multiple cores, within the same node.","title":"OpenMP"},{"location":"docs/overview/tech/glossary/#partition","text":"A partition is a set of compute nodes within a cluster with a common feature. For example, compute nodes with GPU , or compute nodes belonging to same owner, could form a partition. On Sherlock, you can see detailed partition information with the sh_part or sinfo commands.","title":"Partition"},{"location":"docs/overview/tech/glossary/#qos","text":"A Quality Of Service (QOS) is the set of rules and limitations that apply to a categories of job. The combination of a partition (set of machines where a job can run) and QOS (set of rules that applies to that job) makes what is often referred to as a scheduler queue .","title":"QOS"},{"location":"docs/overview/tech/glossary/#run-time","text":"The run time, or walltime, of a job is the time required to finish its execution.","title":"Run time"},{"location":"docs/overview/tech/glossary/#scheduler","text":"The goal of a job scheduler is to find the appropriate resources to run a set of computational tasks in the most efficient manner. Based on resource requirements and job descriptions, it will prioritize those jobs, allocate resources (nodes, CPUs, memory) and schedule their execution.","title":"Scheduler"},{"location":"docs/overview/tech/glossary/#slurm","text":"Simple Linux Utility for Resource Management (SLURM) is a software that manages computing resources and schedule tasks on them. Slurm coordinates running of many programs on a shared facility and makes sure that resources are used in an optimal manner.","title":"Slurm"},{"location":"docs/overview/tech/glossary/#ssh","text":"Secure Shell ( SSH ) is a protocol to securely access remote computers. Based on the client-server model, multiple users with an SSH client can access a remote computer. Some operating systems such as Linux and Mac OS have a built-in SSH client and others can use one of many publicly available clients.","title":"SSH"},{"location":"docs/overview/tech/glossary/#thread","text":"A process, in the simplest terms, is an executing program. One or more threads run in the context of the process. A thread is the basic unit to which the operating system allocates processor time. A thread can execute any part of the process code, including parts currently being executed by another thread. Threads are co-located on the same node.","title":"Thread"},{"location":"docs/overview/tech/glossary/#task","text":"In the Slurm context, a task is to be understood as a process. A multi-process program is made of several tasks. A task is typically used to schedule a MPI process, that in turn can use several CPUs. By contrast, a multi-threaded program is composed of only one task, which uses several CPUs.","title":"Task"},{"location":"docs/overview/tech/specs/","text":"Technical specifications # In a nutshell # Sherlock features over 1,600 compute nodes, 44,000+ CPU cores and 700+ GPUs, for a total computing power of more than 3.3 Petaflops. That would rank it in the Top500 list of the most powerful supercomputers in the world. The cluster currently extends across 4 Infiniband fabrics ( EDR , FDR , HDR ). A 6.1 PB parallel, distributed filesystem, delivering over 200 GB/s of I/O bandwidth, provides scratch storage for more than 5,400 users, and 800 PI groups. Resources # The Sherlock cluster has been initiated in January 2014 with a base of freely available computing resources (about 2,000 CPU cores) and the accompanying networking and storage infrastructure (about 1 PB of shared storage). Since then, it's been constantly expanding, spawning multiple cluster generations, with numerous contributions from many research groups on campus. Cluster generations For more information about Sherlock's ongoing evolution and expansion, please see Cluster generations . Interface # Type Qty Details login nodes 14 sherlock.stanford.edu (load-balanced) data transfer nodes 3 dedicated bandwidth for large data transfers Computing # Access to computing resources Computing resources marked with below are freely available to every Sherlock user. Resources marked with are only accessible to Sherlock owners and their research teams. th:nth-child(2) { min-width: 0 !important; Type Access Nodes CPU cores Details compute nodes normal partition 154 4,032 - 56x 20 (Intel E5-2640v4), 128 GB RAM , EDR IB - 28x 24 (Intel 5118), 191 GB RAM , EDR IB - 70x 32 (AMD 7502), 256 GB RAM , HDR IB development nodes dev partition 2 40 - 2x 20 (Intel E5-2640v4), 128 GB RAM , EDR IB large memory nodes bigmem partition 5 408 - 1x 32 (Intel E5-2697Av4), 512 GB RAM , EDR IB - 1x 56 (Intel E5-4650v4), 3072 GB RAM , EDR IB - 1x 64 (AMD 7502), 4096 GB RAM , HDR IB - 2x 128 (AMD 7742), 1024 GB RAM , HDR IB GPU nodes gpu partition 26 748 - 1x 20 (Intel E5-2640v4), 256 GB RAM , EDR IB - 4x Tesla P100 PCIe - 1x 20 (Intel E5-2640v4), 256 GB RAM , EDR IB - 4x Tesla P40 - 3x 20 (Intel E5-2640v4), 256 GB RAM , EDR IB - 4x Tesla V100_SXM2 - 1x 24 (Intel 5118), 191 GB RAM , EDR IB - 4x Tesla V100_SXM2 - 2x 24 (Intel 5118), 191 GB RAM , EDR IB - 4x Tesla V100 PCIe - 16x 32 (AMD 7502P), 256 GB RAM , HDR IB - 4x Geforce RTX_2080Ti - 2x 32 (AMD 7502P), 256 GB RAM , HDR IB - 4x Tesla V100S PCIe privately-owned nodes owners partition 1,475 37,788 43 different node configurations, including GPU and bigmem nodes Total 1,666 44,032 712 Storage # More information For more information about storage options on Sherlock, please refer to the Storage section of the documentation. Sherlock is architected around shared storage components, meaning that users can find the same files and directories from all of the Sherlock nodes. Highly-available NFS filesystem for user and group home directories (with hourly snapshots and off-site replication) High-performance Lustre scratch filesystem (6.1 PB parallel, distributed filesystem, delivering over 200 GB/s of I/O bandwidth) Direct access to SRCC 's Oak long-term research data storage system (26.3 PB)","title":"Specs"},{"location":"docs/overview/tech/specs/#technical-specifications","text":"","title":"Technical specifications"},{"location":"docs/overview/tech/specs/#in-a-nutshell","text":"Sherlock features over 1,600 compute nodes, 44,000+ CPU cores and 700+ GPUs, for a total computing power of more than 3.3 Petaflops. That would rank it in the Top500 list of the most powerful supercomputers in the world. The cluster currently extends across 4 Infiniband fabrics ( EDR , FDR , HDR ). A 6.1 PB parallel, distributed filesystem, delivering over 200 GB/s of I/O bandwidth, provides scratch storage for more than 5,400 users, and 800 PI groups.","title":"In a nutshell"},{"location":"docs/overview/tech/specs/#resources","text":"The Sherlock cluster has been initiated in January 2014 with a base of freely available computing resources (about 2,000 CPU cores) and the accompanying networking and storage infrastructure (about 1 PB of shared storage). Since then, it's been constantly expanding, spawning multiple cluster generations, with numerous contributions from many research groups on campus. Cluster generations For more information about Sherlock's ongoing evolution and expansion, please see Cluster generations .","title":"Resources"},{"location":"docs/overview/tech/specs/#interface","text":"Type Qty Details login nodes 14 sherlock.stanford.edu (load-balanced) data transfer nodes 3 dedicated bandwidth for large data transfers","title":"Interface"},{"location":"docs/overview/tech/specs/#computing","text":"Access to computing resources Computing resources marked with below are freely available to every Sherlock user. Resources marked with are only accessible to Sherlock owners and their research teams. th:nth-child(2) { min-width: 0 !important; Type Access Nodes CPU cores Details compute nodes normal partition 154 4,032 - 56x 20 (Intel E5-2640v4), 128 GB RAM , EDR IB - 28x 24 (Intel 5118), 191 GB RAM , EDR IB - 70x 32 (AMD 7502), 256 GB RAM , HDR IB development nodes dev partition 2 40 - 2x 20 (Intel E5-2640v4), 128 GB RAM , EDR IB large memory nodes bigmem partition 5 408 - 1x 32 (Intel E5-2697Av4), 512 GB RAM , EDR IB - 1x 56 (Intel E5-4650v4), 3072 GB RAM , EDR IB - 1x 64 (AMD 7502), 4096 GB RAM , HDR IB - 2x 128 (AMD 7742), 1024 GB RAM , HDR IB GPU nodes gpu partition 26 748 - 1x 20 (Intel E5-2640v4), 256 GB RAM , EDR IB - 4x Tesla P100 PCIe - 1x 20 (Intel E5-2640v4), 256 GB RAM , EDR IB - 4x Tesla P40 - 3x 20 (Intel E5-2640v4), 256 GB RAM , EDR IB - 4x Tesla V100_SXM2 - 1x 24 (Intel 5118), 191 GB RAM , EDR IB - 4x Tesla V100_SXM2 - 2x 24 (Intel 5118), 191 GB RAM , EDR IB - 4x Tesla V100 PCIe - 16x 32 (AMD 7502P), 256 GB RAM , HDR IB - 4x Geforce RTX_2080Ti - 2x 32 (AMD 7502P), 256 GB RAM , HDR IB - 4x Tesla V100S PCIe privately-owned nodes owners partition 1,475 37,788 43 different node configurations, including GPU and bigmem nodes Total 1,666 44,032 712","title":"Computing"},{"location":"docs/overview/tech/specs/#storage","text":"More information For more information about storage options on Sherlock, please refer to the Storage section of the documentation. Sherlock is architected around shared storage components, meaning that users can find the same files and directories from all of the Sherlock nodes. Highly-available NFS filesystem for user and group home directories (with hourly snapshots and off-site replication) High-performance Lustre scratch filesystem (6.1 PB parallel, distributed filesystem, delivering over 200 GB/s of I/O bandwidth) Direct access to SRCC 's Oak long-term research data storage system (26.3 PB)","title":"Storage"},{"location":"docs/overview/tech/status/","text":"var statusWidget = new Status.Widget({ hostname: \"status.sherlock.stanford.edu\", selector: \"#sh_status\", display: { ledPosition: \"left\", } }); .status-widget__state { font-size: 1em; font-weight: bold; } .status-widget__led { height: 12px; width: 11px; margin-left: 5px; } .status-widget__issue { line-height: normal; } .status-widget__issue__title, .status-widget__issue__body { padding: 5px 0; } Scheduled maintenances Maintenance operations and upgrades are scheduled on Sherlock on a regular basis. Per the University's Minimum Security policies , we deploy security patches on Sherlock as required for compliance. Components and services # Sherlock status is For more details about Sherlock components and services, see the status dashboard . Current usage #","title":"Status"},{"location":"docs/overview/tech/status/#components-and-services","text":"Sherlock status is For more details about Sherlock components and services, see the status dashboard .","title":"Components and services"},{"location":"docs/overview/tech/status/#current-usage","text":"","title":"Current usage"},{"location":"docs/software/install/","text":"Software installation requests For more information about software installation requests, please see the Software Overview page If the software package or version you need is not available in the list of provided software , you may compile and install it yourself. The recommended location for user-installed software is the $GROUP_HOME group shared directory , which is snapshotted and replicated off-site, and can easily be shared with members of a research group. Work in progress This page is a work in progress and is not complete yet. We are actively working on adding more content and information.","title":"Installation"},{"location":"docs/software/list/","text":"Software list # The full list of software centrally installed and managed on Sherlock is in the tables below. Work in progress Software installations on Sherlock are an ever ongoing process. We're continuously adding new software to the list. If you're looking for something that is not in the list, please take a look here for options. Categories # Software modules on Sherlock are organized in categories , by scientific field or functional class. It means that you will have to first load a category module before getting access to individual modules. The math and devel categories are loaded by default. See the Modules page for further details and examples. We currently provide 416 software modules, in 7 categories, covering 75 fields of science: biology clinical science, computational biology, cryo-em, genomics, neurology, pathology, phylogenetics, population genetics chemistry cheminformatics, computational chemistry, crystallography, electrostatics, molecular dynamics, quantum chemistry devel build, compiler, data, data analytics, debug, engine, framework, language, lib, mpi, networking, parser, profiling, runtime, sdk math computational geometry, deep learning, linear algebra, machine learning, numerical analysis, numerical library, optimization, scientific computing, statistics, symbolic physics astronomy, CFD, climate modeling, geophysics, geoscience, materials science, micromagnetics, particle, photonics, quantum mechanics system backup, benchmark, checkpointing, compression, containers, database, devel, scm, document management, document processing, file management, file transfer, framework, language, libs, media, performance, resource monitoring, scm, tools viz data, gis, graphs, imaging, molecular visualization, plotting, remote display Licensed software Access to software modules marked with in the tables below is restricted to properly licensed user groups. SRCC is not funded to provide commercial software on Sherlock and researchers are responsible for the costs of purchasing and renewing commercial software licenses. For more information, please feel free to contact us and see the Stanford Software Licensing page for purchasing information. Additional flags and features Some of the modules listed below have been built to support specific architectures or parallel execution modes: versions marked with support GPU acceleration versions marked with support MPI parallel execution versions marked with are the default version for the module biology # Field Module name Version(s) URL Description clinical science simvascular 20180704 Website Simvascular is a blood flow simulation and analysis toolkit. This module provides the svFSI (Fluid Solid Interaction) solver. computational biology py-biopython 1.70_py27 Website Biopython is a set of freely available tools for biological computation written in Python. computational biology rosetta 3.8 Website Rosetta is the premier software suite for modeling macromolecular structures. As a flexible, multi-purpose application, it includes tools for structure prediction, design, and remodeling of proteins and nucleic acids. cryo-em ctffind 4.1.13 Website ctffind is a program for finding CTFs of electron micrographs. cryo-em eman2 2.2 Website EMAN2 is a broadly based greyscale scientific image processing suite with a primary focus on processing data from transmission electron microscopes. cryo-em imod 4.9.12 4.11.5 Website IMOD is a set of image processing, modeling and display programs used for tomographic reconstruction and for 3D reconstruction of EM serial sections and optical sections. cryo-em motioncor2 1.3.1 Website MotionCor2 is a multi- GPU accelerated program which corrects anisotropic image motion at the single pixel level. cryo-em relion 2.0.3 2.1 Website RELION (for REgularised LIkelihood OptimisatioN, pronounce rely-on) is a stand-alone computer program that employs an empirical Bayesian approach to refinement of (multiple) 3D reconstructions or 2D class averages in electron cryo-microscopy (cryo-EM). genomics angsd 0.919 0.931 Website ANGSD is a software for analyzing next generation sequencing data. genomics augustus 3.3.2 Website AUGUSTUS is a program that predicts genes in eukaryotic genomic sequences. genomics bamtools 2.5.1 Website BamTools is a project that provides both a C++ API and a command-line toolkit for reading, writing, and manipulating BAM (genome alignment) files. genomics bcftools 1.6 1.8 Website BCFtools is a program for variant calling and manipulating files in the Variant Call Format (VCF) and its binary counterpart BCF. genomics bcl2fastq 2.20 Website The bcl2fastq2 conversion software can be used to convert BCL files from MiniSeq, MiSeq, NextSeq, HiSeq, iSeq and NovaSeq sequening systems. genomics bedtools 2.27.1 Website The bedtools utilities are a swiss-army knife of tools for a wide-range of genomics analysis tasks. genomics bgen 1.1.4 Website bgen is the reference implementation of the BGEN format, a binary file format for imputed genotype and haplotype data. genomics bowtie 1.2.2 Website Bowtie is an ultrafast, memory-efficient short read aligner. genomics bowtie2 2.3.4.1 Website Bowtie 2 is an ultrafast and memory-efficient tool for aligning sequencing reads to long reference sequences. genomics bwa 0.7.17 Website BWA (Burrows-Wheeler Aligner) is a software package for mapping low-divergent sequences against a large reference genome, such as the human genome. genomics canu 1.8 Website A single molecule sequence assembler for genomes large and small. genomics cufflinks 2.2.1 Website Cufflinks assembles transcripts, estimates their abundances, and tests for differential expression and regulation in RNA-Seq samples. genomics fastqc 0.11.8 Website FastQC aims to provide a simple way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines. genomics fastx_toolkit 0.0.14 Website The FASTX-Toolkit is a collection of command line tools for Short-Reads FASTA/FASTQ files preprocessing. genomics freebayes 1.2.0 Website FreeBayes is a Bayesian genetic variant detector designed to find small polymorphisms. genomics gatk 4.1.0.0 4.1.4.1 Website GATK (Genome Analysis Toolkit) offers a wide variety of tools with a primary focus on variant discovery and genotyping. genomics hic-pro 2.10.0 Website HiC-Pro: An optimized and flexible pipeline for Hi-C data processing. genomics hisat2 2.1.0 Website HISAT2 is a fast and sensitive alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes (as well as to a single reference genome). genomics htslib 1.6 1.8 1.10.2 Website C library for high-throughput sequencing data formats. genomics jellyfish 2.2.10 Website A fast multi-threaded k-mer counter. genomics kallisto 0.44.0 Website kallisto is a program for quantifying abundances of transcripts from RNA-Seq data using high-throughput sequencing reads. genomics metal 20110325 Website The METAL software is designed to facilitate meta-analysis of large datasets (such as several whole genome scans) in a convenient, rapid and memory efficient manner. genomics mixcr 2.1.12 Website MiXCR is a universal framework that processes big immunome data from raw sequences to quantitated clonotypes. genomics ncbi-blast+ 2.6.0 2.7.1 2.11.0 Website NCBI BLAST+ is a suite of command-line tools to run BLAST (Basic Local Alignment Search Tool), an algorithm for comparing primary biological sequence information. genomics plink 1.07 1.90b5.3 2.0a1 2.0a2 Website PLINK is a free, open-source whole genome association analysis toolset, designed to perform a range of basic, large-scale analyses in a computationally efficient manner. genomics py-busco 3.0.2_py27 Website Assessing genome assembly and annotation completeness with Benchmarking Universal Single-Copy Orthologs (BUSCO). genomics py-bx-python 0.8.1_py27 Website Tools for manipulating biological data, particularly multiple sequence alignments. genomics py-cutadapt 1.18_py27 1.18_py36 Website Cutadapt finds and removes adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads. genomics py-deeptools 3.3.1_py36 Website Tools to process and analyze deep sequencing data. genomics py-fithic 1.1.3_py27 Website Fit-Hi-C is a tool for assigning statistical confidence estimates to chromosomal contact maps produced by genome architecture assays. genomics py-macs2 2.1.1_py27 Website MACS (Model-based Analysis of ChIP-Seq) implements a novel ChIP-Seq analysis method. genomics py-mapdamage 2.2.1_py36 Website mapDamage2 is a computational framework which tracks and quantifies DNA damage patterns among ancient DNA sequencing reads generated by Next-Generation Sequencing platforms. genomics py-multiqc 1.6_py27 1.6_py36 Website MultiQC is a reporting tool that parses summary statistics from results and log files generated by other bioinformatics tools. genomics py-obitools 1.2.13_py27 Website OBITools is a set of programs designed for analyzing NGS data in a DNA metabarcoding context. genomics py-pybedtools 0.8.0_py27 0.8.2_py36 Website Pybedtools wraps and extends BEDTools and offers feature-level manipulations from within Python. genomics py-pysam 0.14.1_py27 0.15.3_py36 Website Pysam is a python module for reading, manipulating and writing genomic data sets. genomics rsem 1.3.3 Website RSEM is a software package for estimating gene and isoform expression levels from RNA-Seq data. genomics salmon 0.12.0 Website Highly-accurate & wicked fast transcript-level quantification from RNA-seq reads using lightweight alignments. genomics samtools 1.6 1.8 Website Tools (written in C using htslib) for manipulating next-generation sequencing data. genomics sentieon 201808.01 Website Sentieon Genomics software is a set of software tools that perform analysis of genomic data obtained from DNA sequencing. genomics shapeit 4.0.0 Website SHAPEIT4 is a fast and accurate method for estimation of haplotypes (aka phasing) for SNP array and high coverage sequencing data. genomics star 2.5.4b Website STAR: ultrafast universal RNA-seq aligner. genomics tophat 2.1.1 Website TopHat is a fast splice junction mapper for RNA-Seq reads. genomics trim_galore 0.5.0 Website Trim Galore! is a wrapper script to automate quality and adapter trimming as well as quality control, with some added functionality to remove biased methylation positions for RRBS sequence files. genomics trinity 2.8.4 Website Trinity RNA-Seq de novo transcriptome assembly. genomics vcflib 1.0.0 Website A C++ library for parsing and manipulating VCF files. genomics vcftools 0.1.15 Website VCFtools is a program package designed for working with VCF files, such as those generated by the 1000 Genomes Project. neurology afni 17.2.07 18.2.04 Website AFNI (Analysis of Functional NeuroImages) is a set of C programs for processing, analyzing, and displaying functional MRI (FMRI) data - a technique for mapping human brain activity. neurology ants 2.1.0 2.3.1 Website ANTs computes high-dimensional mappings to capture the statistics of brain structure and function. neurology dcm2niix 1.0.20171215 Website dcm2niix is a program esigned to convert neuroimaging data from the DICOM format to the NIfTI format. neurology freesurfer 6.0.0 7.1.1 Website An open source software suite for processing and analyzing (human) brain MRI images. neurology fsl 5.0.10 Website FSL is a comprehensive library of analysis tools for FMRI, MRI and DTI brain imaging data. neurology mricron 20160502 Website MRIcron is a cross-platform NIfTI format image viewer. neurology mrtrix 0.3.16 Website MRtrix3 provides a set of tools to perform various types of diffusion MRI analyses, from various forms of tractography through to next-generation group-level analyses. neurology py-mdt 0.10.9_py36 Website The Maastricht Diffusion Toolbox, MDT, is a framework and library for parallelized ( GPU and multi-core CPU ) diffusion Magnetic Resonance Imaging (MRI) modeling. neurology py-nipype 1.1.3_py27 1.1.3_py36 Website Nipype is a Python project that provides a uniform interface to existing neuroimaging software and facilitates interaction between these packages within a single workflow. neurology spm 12 Website The SPM software package has been designed for the analysis of brain imaging data sequences. The sequences can be a series of images from different cohorts, or time-series from the same subject. neurology workbench 1.3.1 Website Connectome Workbench is an open source, freely available visualization and discovery tool used to map neuroimaging data, especially data generated by the Human Connectome Project. pathology openslide 3.4.1 Website OpenSlide is a C library that provides a simple interface to read whole-slide images (also known as virtual slides). pathology py-openslide-python 1.1.1_py27 1.1.1_py36 Website OpenSlide Python is a Python interface to the OpenSlide library. phylogenetics py-ete 3.0.0_py27 Website A Python framework for the analysis and visualization of trees. population genetics py-admixfrog 0.6.1_py36 Website Admixfrog is a HMM to infer ancestry frogments (fragments) from low-coverage, contaminated data. chemistry # Field Module name Version(s) URL Description cheminformatics py-rdkit 2018.09.1_py27 2018.09.1_py36 Website RDKit is a collection of cheminformatics and machine-learning software written in C++ and Python. computational chemistry gaussian g16.A03 g16.B01 Website Gaussian is a general purpose computational chemistry software package. computational chemistry libint 1.1.4 2.0.3 Website Libint computes molecular integrals. computational chemistry libxc 3.0.0 Website Libxc is a library of exchange-correlation functionals for density-functional theory. computational chemistry nwchem 6.8 Website NWChem is an ab initio computational chemistry software package which also includes quantum chemical and molecular dynamics functionality. computational chemistry py-ase 3.14.1_py27 Website The Atomic Simulation Environment (ASE) is a set of tools and Python modules for setting up, manipulating, running, visualizing and analyzing atomistic simulations. computational chemistry schrodinger 2017-3 2018-1 2018-2 2019-2 2020-2 2021-1 Website Schr\u00f6dinger Suites (Small-molecule Drug Discovery Suite, Material Science Suite, Biologics Suite) provide a set of molecular modelling software. computational chemistry vasp 5.4.1 6.6.1 Website The Vienna Ab initio Simulation Package (VASP) is a computer program for atomic scale materials modelling, e.g. electronic structure calculations and quantum-mechanical molecular dynamics, from first principles. crystallography vesta 3.4.4 Website VESTA is a 3D visualization program for structural models, volumetric data such as electron/nuclear densities, and crystal morphologies. electrostatics apbs 1.5 Website APBS solves the equations of continuum electrostatics for large biomolecular assemblages. molecular dynamics gromacs 2016.3 2018 Website GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. molecular dynamics lammps 20180316 20200303 Website LAMMPS is a classical molecular dynamics code that models an ensemble of particles in a liquid, solid, or gaseous state. molecular dynamics openmm 7.1.1 Website A high performance toolkit for molecular simulation. molecular dynamics plumed 2.3.2 Website PLUMED is an open source library for free energy calculations in molecular systems. molecular dynamics py-raspa2 2.0.3_py27 Website RASPA2 is a general purpose classical simulation package that can be used for the simulation of molecules in gases, fluids, zeolites, aluminosilicates, metal-organic frameworks, carbon nanotubes and external fields. molecular dynamics qbox 1.65.0 Website Qbox is a First-Principles Molecular Dynamics code. molecular dynamics quip 20170901 Website The QUIP package is a collection of software tools to carry out molecular dynamics simulations. quantum chemistry cp2k 4.1 Website CP2K is a quantum chemistry and solid state physics software package that can perform atomistic simulations of solid state, liquid, molecular, periodic, material, crystal, and biological systems. quantum chemistry orca 4.2.1 Website ORCA is a flexible, efficient and easy-to-use general purpose tool for quantum chemistry. quantum chemistry quantum-espresso 6.2.1 6.6 Website Quantum ESPRESSO is an integrated suite of Open-Source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials. quantum chemistry quantum-espresso_gpu 1.1 Website GPU -accelerated Quantum ESPRESSO using CUDA FORTRAN devel # Field Module name Version(s) URL Description build bazel 0.16.1 0.26.1 0.29.1 Website Bazel is a fast, scalable, multi-language and extensible build system. build bazelisk 1.3.0 1.8.0 Website Bazelisk is a wrapper for Bazel written in Go. build cmake 3.8.1 3.11.1 3.13.1 Website CMake is an extensible, open-source system that manages the build process in an operating system and in a compiler-independent manner. build kerl 1.8.5 Website Kerl is a tool to easily build and install Erlang/OTP instances. build ninja 1.9.0 Website Ninja is a small build system with a focus on speed. build py-meson 0.51.1_py36 Website Meson is an open source build system meant to be both extremely fast, and, even more importantly, as user friendly as possible. build py-scons 3.0.5_py27 3.0.5_py36 Website SCons is an Open Source software construction tool. compiler aocc 2.1.0 2.2.0 Website AMD Optimizing C/C++ Compiler - AOCC is a highly optimized C, C++ and Fortran compiler for x86 targets especially for Zen based AMD processors. compiler gcc 6.3.0 7.1.0 7.3.0 8.1.0 9.1.0 10.1.0 Website The GNU Compiler Collection includes front ends for C, C++, Fortran, Java, and Go, as well as libraries for these languages (libstdc++, libgcj,...). compiler icc 2017.u2 2018.u1 2018 2019 Website Intel C++ Compiler, also known as icc or icl, is a group of C and C++ compilers from Intel compiler ifort 2017.u2 2018.u1 2018 2019 Website Intel Fortran Compiler, also known as ifort, is a group of Fortran compilers from Intel compiler llvm 3.8.1 4.0.0 5.0.0 7.0.0 Website The LLVM Project is a collection of modular and reusable compiler and toolchain technologies. Clang is an LLVM native C/C++/Objective-C compiler, compiler nagfor npl6a61na Website The NAG Fortran Compiler is a full standard implementation of the ISO Fortran 95 language with the addition of all of Fortran 2003, most of Fortran 2008 and OpenMP 3.0 and 3.1. compiler pgi 19.10 Website PGI compilers and tools, including Open MPI (Community Edition). compiler smlnj 110.81 Website Standard ML of New Jersey (abbreviated SML/NJ) is a compiler for the Standard ML '97 programming language. data h5utils 1.12.1 Website h5utils is a set of utilities for visualization and conversion of scientific data in the free, portable HDF5 format. data hdf5 1.10.6 1.10.0p1 1.10.2 Website HDF5 is a data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data. data hiredis 0.13.3 Website Hiredis is a minimalistic C client library for the Redis database. data ncl 6.4.0 6.6.2 Website NCL is a free interpreted language designed specifically for scientific data processing and visualization. data nco 4.8.0 Website The NCO toolkit manipulates and analyzes data stored in netCDF-accessible formats. data netcdf 4.4.1.1 Website NetCDF is a set of software libraries and self-describing, machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data. data pnetcdf 1.8.1 Website Parallel netCDF (PnetCDF) is a parallel I/O library for accessing NetCDF files in CDF-1, 2, and 5 formats. data protobuf 3.4.0 Website Protocol Buffers (a.k.a., protobuf) are Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data. data py-pandas 0.23.0_py27 0.23.0_py36 1.0.3_py36 Website pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language. data py-protobuf 3.4.0_py27 3.4.0_py36 3.6.1_py27 3.6.1_py36 3.15.8_py36 Website Python bindings for Google's Protocol Buffers data interchange format. data redis 4.0.1 Website Redis is an open source, in-memory data structure store, used as a database, cache and message broker. data analytics hadoop 3.1.0 Website The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. data analytics py-sparkhpc 0.3 Website Launching and controlling spark on HPC clusters data analytics spark 2.3.0 Website Apache Spark\u2122 is a unified analytics engine for large-scale data processing. debug gdb 8.2.1 Website GDB is the GNU Project debugger. debug valgrind 3.14.0 Website Valgrind is an instrumentation framework for building dynamic analysis tools. engine v8 8.4.371.22 Website V8 is Google\u2019s open source high-performance JavaScript and WebAssembly engine, written in C++. framework dotnet 2.1.500 Website .NET is a free, cross-platform, open source developer platform for building many different types of applications. language cuda 9.0.176 8.0.61 9.1.85 9.2.88 9.2.148 10.0.130 10.1.105 10.1.168 10.2.89 11.0.3 11.1.1 11.2.0 Website CUDA is a parallel computing platform and application programming interface (API) model created by Nvidia. It allows software developers and software engineers to use a CUDA-enabled graphics processing unit ( GPU ) for general purpose processing. language erlang 21.3 Website Erlang is a programming language used to build massively scalable soft real-time systems with requirements on high availability. language go 1.9 1.14 Website Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. language guile 2.0.11 2.2.2 Website GNU Guile is the preferred extension system for the GNU Project, which features an implementation of the Scheme programming language. language haskell 8.6.5 Website Haskell is a statically typed, purely functional programming language with type inference and lazy evaluation. language java 1.8.0_131 Website Java is a general-purpose computer programming language that is concurrent, class-based, object-oriented,[14] and specifically designed to have as few implementation dependencies as possible. language julia 1.0.0 1.1.0 1.2.0 1.3.1 1.4.0 1.5.1 Website Julia is a high-level, high-performance dynamic programming language for numerical computing. language lua 5.3.4 Website Lua is a powerful, efficient, lightweight, embeddable scripting language. It supports procedural programming, object-oriented programming, functional programming, data-driven programming, and data description. language luarocks 2.4.3 Website LuaRocks is the package manager for Lua modules. language manticore 20180301 Website Manticore is a high-level parallel programming language aimed at general-purpose applications running on multi-core processors. language nodejs 8.9.4 9.5.0 Website Node.js is a JavaScript runtime built on Chrome's V8 JavaScript engine. It provides the npm package manager. language perl 5.26.0 Website Perl 5 is a highly capable, feature-rich programming language with over 29 years of development. language php 7.3.0 Website PHP (recursive acronym for PHP: Hypertext Preprocessor) is an open source general-purpose scripting language that is especially suited for web development. language py-cython 0.27.3_py27 0.27.3_py36 0.29.21_py36 Website Cython is an optimising static compiler for both the Python programming language and the extended Cython programming language (based on Pyrex). language py-ipython 5.4.1_py27 6.1.0_py36 Website IPython is a command shell for interactive computing in multiple programming languages, originally developed for the Python programming language. language py-jupyter 1.0.0_py27 1.0.0_py36 Website Jupyter is a browser-based interactive notebook for programming, mathematics, and data science. It supports a number of languages via plugins. language python 2.7.13 3.6.1 3.9.0 Website Python is an interpreted, interactive, object-oriented programming language. language ruby 2.4.1 2.7.1 Website A dynamic, open source programming language with a focus on simplicity and productivity. It has an elegant syntax that is natural to read and easy to write. language rust 1.35.0 Website A language empowering everyone to build reliable and efficient software. language scala 2.12.6 Website Scala combines object-oriented and functional programming in one concise, high-level language. lib ant 1.10.1 Website Apache Ant is a Java library and command-line tool whose mission is to drive processes described in build files as targets and extension points dependent upon each other. lib boost 1.64.0 1.69.0 1.75.0 1.76.0 Website Boost is a set of libraries for the C++ programming language that provide support for tasks and structures such as linear algebra, pseudorandom number generation, multithreading, image processing, regular expressions, and unit testing. lib cnmem 1.0.0 Website CNMeM is a simple library to help the Deep Learning frameworks manage CUDA memory. lib cub 1.7.3 1.10.0 Website CUB is a flexible library of cooperative threadblock primitives and other utilities for CUDA kernel programming. lib cutlass 0.1.0 Website CUTLASS is a collection of CUDA C++ template abstractions for implementing high-performance matrix-multiplication (GEMM) at all levels and scales within CUDA. lib eigen 3.3.3 Website Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms. lib libctl 3.2.2 4.0.1 Website libctl is a library for supporting flexible control files in scientific simulations. lib libgpuarray 0.7.5 Website Library to manipulate tensors on the GPU . lib nccl 1.3.4 2.0.4 2.1.15 2.2.13 2.3.7 2.4.8 2.5.6 2.8.4 Website NCCL (pronounced 'Nickel') is a stand-alone library of standard collective communication routines, such as all-gather, reduce, broadcast, etc., that have been optimized to achieve high bandwidth over PCIe. lib opencv 3.3.0 4.5.2 Website OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. lib petsc 3.10.3 Website PETSc is a suite of data structures and routines for the scalable (parallel) solution of scientific applications modeled by partial differential equations. lib py-h5py 2.7.1_py27 2.8.0_py36 2.10.0_py36 Website The h5py package is a Pythonic interface to the HDF5 binary data format. lib py-netcdf4 1.3.1_py27 1.3.1_py36 Website netcdf4-python is a Python interface to the netCDF C library. lib py-numba 0.35.0_py27 0.35.0_py36 0.53.1_py36 Website Numba is a compiler for Python array and numerical functions that gives you the power to speed up your applications with high performance functions written directly in Python.. lib py-pycuda 2017.1.1_py27 Website PyCUDA lets you access Nvidia\u2018s CUDA parallel computation API from Python. lib py-schwimmbad 0.3.1_py36 Website schwimmbad provides a uniform interface to parallel processing pools and enables switching easily between local development (e.g., serial processing or with multiprocessing) and deployment on a cluster or supercomputer (via, e.g., MPI or JobLib). lib py-scikit-image 0.13.0_py27 0.14.0_py27 0.15.0_py27 0.15.0_py36 0.17.2_py36 Website scikit-image is a collection of algorithms for image processing. lib rabbitmq 3.7.13 Website RabbitMQ is an open-source message broker. lib swig 3.0.12 Website SWIG is an interface compiler that connects programs written in C and C++ with scripting languages such as Perl, Python, Ruby, and Tcl. lib tbb 2017.u2 2018.u1 2018 2019 Website Intel\u00ae Threading Building Blocks (Intel\u00ae TBB) is a widely used C++ library for shared-memory parallel programming and heterogeneous computing (intra-node distributed memory programming). lib trilinos 12.12.1 Website Trilinos is a collection of open-source software libraries, called packages, intended to be used as building blocks for the development of scientific applications. lib zeromq 4.2.2 Website ZeroMQ (also spelled \u00d8MQ, 0MQ or ZMQ) is a high-performance asynchronous messaging library, aimed at use in distributed or concurrent applications. mpi hpcx 2.6.0 2.7.0 2.8.1 Website Mellanox HPC -X toolkit is a comprehensive software package that includes MPI and SHMEM/PGAS communications libraries. mpi impi 2017.u2 2018.u1 2018 2019 Website Intel\u00ae MPI Library is a multi-fabric message passing library that implements the Message Passing Interface, version 3.1 ( MPI -3.1) specification. mpi openmpi 2.0.2 2.1.1 3.1.2 4.0.3 4.0.5 4.1.0 Website The Open MPI Project is an open source Message Passing Interface implementation that is developed and maintained by a consortium of academic, research, and industry partners. mpi py-mpi4py 3.0.0_py27 3.0.3_py36 Website MPI for Python provides Python bindings for the Message Passing Interface ( MPI ) standard. It is implemented on top of the MPI -\u00bd/3 specification and exposes an API which grounds on the standard MPI -2 C++ bindings. networking gasnet 1.30.0 Website GASNet is a language-independent, low-level networking layer that provides network-independent, high-performance communication primitives tailored for implementing parallel global address space SPMD languages and libraries. networking libfabric 1.6.0 1.6.2 1.7.1 1.9.1 1.10.1 1.11.1 Website The Open Fabrics Interfaces (OFI) is a framework focused on exporting fabric communication services to applications. Libfabric is the library that defines and exports the user-space API of OFI. networking ucx 1.3.1 1.8.1 1.9.0 1.10.0 Website UCX is a communication library implementing high-performance messaging for MPI /PGAS frameworks. parser xerces-c 3.2.1 Website Xerces-C++ is a validating XML parser written in a portable subset of C++. profiling amd-uprof 3.3.462 Website AMD uProf is a performance analysis tool for applications. runtime starpu 1.3.2 Website StarPU is a unified runtime system that offers support for heterogeneous multicore architectures sdk google-cloud-sdk 240.0.0 338.0.0 Website Command-line interface for Google Cloud Platform products and services. math # Field Module name Version(s) URL Description computational geometry cgal 4.10 Website The Computational Geometry Algorithms Library (CGAL) is a C++ library that aims to provide easy access to efficient and reliable algorithms in computational geometry. computational geometry qhull 2015.2 Website Qhull computes the convex hull, Delaunay triangulation, Voronoi diagram, halfspace intersection about a point, furthest-site Delaunay triangulation, and furthest-site Voronoi diagram. deep learning caffe2 0.8.1 Website Caffe2 is a deep learning framework that provides an easy and straightforward way to experiment with deep learning and leverage community contributions of new models and algorithms. deep learning cudnn 6.0 7.0.1 7.0.4 7.0.5 7.1.4 7.4.1.5 7.6.4 7.6.5 8.1.1.33 Website NVIDIA cuDNN is a GPU -accelerated library of primitives for deep neural networks. deep learning cutensor 1.2.0 Website GPU -accelerated tensor linear algebra library. deep learning py-horovod 0.12.1_py27 0.12.1_py36 Website Horovod is a distributed training framework for TensorFlow. The goal of Horovod is to make distributed Deep Learning fast and easy to use. deep learning py-keras 2.1.5_py27 2.0.8_py27 2.1.5_py36 2.2.4_py27 2.2.4_py36 2.3.1_py36 Website Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. deep learning py-onnx 1.0.1_py27 1.8.1_py36 Website ONNX is a open format to represent deep learning models. deep learning py-pytorch 0.3.0_py27 0.2.0_py27 0.2.0_py36 0.3.0_py36 1.0.0_py27 1.0.0_py36 1.4.0_py36 1.8.1_py39 Website PyTorch is a deep learning framework that puts Python first. deep learning py-tensorboardx 1.8_py27 Website TensorboardX is TensorBoard\u2122 for PyTorch (and Chainer, MXNet, NumPy...) deep learning py-tensorflow 1.12.0_py27 1.4.0_py27 1.5.0_py27 1.5.0_py36 1.6.0_py27 1.6.0_py36 1.7.0_py27 1.8.0_py27 1.9.0_py27 1.9.0_py36 1.12.0_py36 2.0.0_py36 2.1.0_py36 2.4.1_py36 Website TensorFlow\u2122 is an open source software library for numerical computation using data flow graphs. deep learning py-tensorlayer 1.6.3_py27 Website TensorLayer is a Deep Learning (DL) and Reinforcement Learning (RL) library extended from Google TensorFlow. deep learning py-theano 1.0.1_py27 Website Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. deep learning tensorrt 3.0.1 3.0.4 4.0.1.6 5.0.2.6 6.0.1.8 7.0.0.11 7.2.3.4 Website NVIDIA TensorRT\u2122 is a high-performance deep learning inference optimizer and runtime that delivers low latency, high-throughput inference for deep learning applications. deep learning torch 20180202 Website Torch is a scientific computing framework with wide support for machine learning algorithms that puts GPUs first. linear algebra armadillo 8.200.1 Website Armadillo is a high quality linear algebra library (matrix maths) for the C++ language, aiming towards a good balance between speed and ease of use. machine learning py-scikit-learn 0.19.1_py27 0.19.1_py36 0.24.2_py36 Website Scikit-learn is a free software machine learning library for the Python programming language. numerical analysis matlab R2017a R2017b R2018a R2019a R2020a Website MATLAB is a multi-paradigm numerical computing environment and proprietary programming language developed by MathWorks. numerical analysis octave 4.2.1 Website GNU Octave is a high-level language primarily intended for numerical computations. numerical library arpack 3.5.0 3.7.0 Website Collection of Fortran77 subroutines designed to solve large scale eigenvalue problems. numerical library blis 2.1 2.2.4 Website BLIS is a portable software framework for instantiating high-performance BLAS-like dense linear algebra libraries. numerical library fftw 3.3.6 3.3.8 Website The Fastest Fourier Transform in the West (FFTW) is a software library for computing discrete Fourier transforms (DFTs). numerical library glpk 4.63 Website The GLPK (GNU Linear Programming Kit) package is intended for solving large-scale linear programming (LP), mixed integer programming (MIP), and other related problems. numerical library gmp 6.1.2 Website GMP is a free library for arbitrary precision arithmetic, operating on signed integers, rational numbers, and floating-point numbers. numerical library gsl 1.16 2.3 Website The GNU Scientific Library (GSL) is a numerical library for C and C++ programmers. The library provides a wide range of mathematical routines such as random number generators, special functions and least-squares fitting. numerical library harminv 1.4.1 Website harminv is a program designed to solve the problem of harmonic inversion: given a time series consisting of a sum of sinusoids (modes), extract their frequencies and amplitudes. numerical library hypre 2.20.0 Website HYPRE is a library of high performance preconditioners and solvers featuring multigrid methods for the solution of large, sparse linear systems of equations on massively parallel computers. numerical library imkl 2017.u2 2018.u1 2018 2019 Website Intel Math Kernel Library (Intel MKL) is a library of optimized math routines for science, engineering, and financial applications. Core math functions include BLAS, LAPACK, ScaLAPACK, sparse solvers, fast Fourier transforms, and vector math.[3] The routines in MKL are hand-optimized specifically for Intel processors numerical library libflame 2.1 2.2.4 Website libflame is a portable library for dense matrix computations, providing much of the functionality present in LAPACK numerical library libxsmm 1.8.1 Website LIBXSMM is a library for small dense and small sparse matrix-matrix multiplications as well as for deep learning primitives such as small convolutions numerical library metis 5.1.0 Website METIS is a set of serial programs for partitioning graphs, partitioning finite element meshes, and producing fill reducing orderings for sparse matrices. numerical library mpc 1.2.1 Website GNU MPC is a C library for the arithmetic of complex numbers with arbitrarily high precision and correct rounding of the result. numerical library mpfr 3.1.5 4.1.0 Website The MPFR library is a C library for multiple-precision floating-point computations with correct rounding. numerical library mumps 5.1.2 Website A parallel sparse direct solver. numerical library nagcl cll6i26dcl Website The NAG C Library is the largest and most comprehensive collection of mathematical and statistical algorithms for C and C++. numerical library nagfl fll6i26dcl Website The NAG Fortran Library is the largest and most comprehensive collection of numerical and statistical algorithms in Fortran. numerical library nagfs fsl6i26dcl Website The NAG Library for SMP & Multicore is based on, and includes, the full functionality of the NAG Fortran Library. numerical library nagmb MBL6I25DNL Website The NAG C Library is the largest and most comprehensive collection of mathematical and statistical algorithms for C and C++. numerical library openblas 0.3.4 0.2.19 0.3.9 0.3.10 Website OpenBLAS is an optimized BLAS library numerical library parmetis 4.0.3 Website ParMETIS is an MPI -based parallel library that implements a variety of algorithms for partitioning unstructured graphs, meshes, and for computing fill-reducing orderings of sparse matrices. numerical library py-cupy 7.8.0_py36 Website CuPy is an implementation of NumPy-compatible multi-dimensional array on CUDA. numerical library py-gmpy2 2.0.8_py36 Website gmpy2 is a C-coded Python extension module that supports multiple-precision arithmetic. numerical library py-numpy 1.14.3_py27 1.14.3_py36 1.17.2_py36 1.18.1_py36 1.19.2_py36 1.20.3_py39 Website NumPy is the fundamental package for scientific computing with Python. numerical library py-pyublas 2017.1_py27 Website PyUblas provides a seamless glue layer between Numpy and Boost.Ublas for use with Boost.Python. numerical library py-scipy 1.1.0_py27 1.1.0_py36 1.4.1_py36 1.6.3_py39 Website The SciPy library provides many user-friendly and efficient numerical routines such as routines for numerical integration and optimization. numerical library qrupdate 1.1.2 Website qrupdate is a Fortran library for fast updates of QR and Cholesky decompositions. numerical library scalapack 2.0.2 2.1 Website ScaLAPACK is a library of high-performance linear algebra routines for parallel distributed memory machines. numerical library scotch 6.0.4 Website Software package and libraries for sequential and parallel graph partitioning, static mapping and clustering, sequential mesh and hypergraph partitioning, and sequential and parallel sparse matrix block ordering. numerical library superlu 5.2.1 Website SuperLU is a general purpose library for the direct solution of large, sparse, nonsymmetric systems of linear equations. numerical library xblas 1.0.248 Website Extra precise basic linear algebra subroutines. optimization gurobi 7.5.1 8.0.1_py27 8.0.1_py36 9.0.3_py36 Website The Gurobi Optimizer is a commercial optimization solver for mathematical programming. optimization knitro 10.3.0 Website Artelys Knitro is an optimization solver for difficult large-scale nonlinear problems. optimization nlopt 2.6.2 Website NLopt is a free/open-source library for nonlinear optimization. scientific computing py-scipystack 1.0_py27 1.0_py36 Website The SciPy Stack is a collection of open source software for scientific computing in Python. It provides the following packages: numpy, scipy, matplotlib, ipython, jupyter, pandas, sympy and nose. statistics datamash 1.3 Website GNU datamash is a command-line program which performs basic numeric, textual and statistical operations on input textual data files. statistics jags 4.3.0 Website Just another Gibbs sampler (JAGS) is a program for simulation from Bayesian hierarchical models using Markov chain Monte Carlo (MCMC). statistics py-rpy2 2.8.6_py27 2.9.2_py36 Website rpy2 is an interface to R running embedded in a Python process. statistics R 3.5.1 3.4.0 3.6.1 4.0.2 Website R is a free software environment for statistical computing and graphics. statistics rstudio 1.1.423 Website RStudio is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management. statistics sas 9.4 Website SAS is a software suite developed by SAS Institute for advanced analytics, multivariate analyses, business intelligence, data management, and predictive analytics. statistics stata 15 14 16 17 Website Stata is a complete, integrated statistical software package that provides everything you need for data analysis, data management, and graphics. symbolic libmatheval 1.1.11 Website GNU libmatheval is a library (callable from C and Fortran) to parse and evaluate symbolic expressions input as text. symbolic py-sympy 1.1.1_py27 1.1.1_py36 Website SymPy is a Python library for symbolic mathematics. physics # Field Module name Version(s) URL Description astronomy heasoft 6.22.1 6.26.1 Website HEAsoft is a Unified Release of the FTOOLS (General and mission-specific tools to manipulate FITS files) and XANADU (High-level, multi-mission tasks for X-ray astronomical spectral, timing, and imaging data analysis) software packages. astronomy py-astropy 4.0.1_py36 Website The Astropy Project is a community effort to develop a common core package for Astronomy in Python and foster an ecosystem of interoperable astronomy packages. astronomy py-lenstools 1.0_py36 Website This python package collects together a suite of widely used analysis tools in Weak Gravitational Lensing. CFD su2 7.0.3 Website SU2: An Open-Source Suite for Multiphysics Simulation and Design climate modeling cdo 1.9.7.1 Website CDO is a collection of command line Operators to manipulate and analyse Climate and NWP model Data. geophysics opensees 2.5.0 Website OpenSees is a software framework for developing applications to simulate the performance of structural and geotechnical systems subjected to earthquakes. geoscience gdal 2.2.1 Website GDAL is a translator library for raster and vector geospatial data formats. geoscience geos 3.6.2 Website GEOS (Geometry Engine - Open Source) is a C++ port of Java Topology Suite (JTS). geoscience proj 4.9.3 Website proj.4 is a standard UNIX filter function which converts geographic longitude and latitude coordinates into cartesian coordinates (and vice versa. geoscience py-opendrift 1.0.3_py27 Website OpenDrift is a software for modeling the trajectories and fate of objects or substances drifting in the ocean, or even in the atmosphere. geoscience py-pyproj 1.9.5.1_py27 1.9.5.1_py36 Website Python interface to PROJ4 library for cartographic transformations. geoscience udunits 2.2.26 Website The UDUNITS package from Unidata is a C-based package for the programatic handling of units of physical quantities. materials science atat 3.36 Website Alloy Theoretic Automated Toolkit: a software toolkit for modeling coupled configurational and vibrational disorder in alloy systems. micromagnetics oommf 1.2b4 Website OOMMF is a set of portable, extensible public domain micromagnetic program and associated tools. particle openmc 0.10.0 Website OpenMC is a Monte Carlo particle transport simulation code focused on neutron criticality calculations. photonics meep 1.3 1.4.3 Website Meep is a free finite-difference time-domain (FDTD) simulation software package to model electromagnetic systems. photonics mpb 1.5 1.6.2 Website MPB is a free software package for computing the band structures, or dispersion relations, and electromagnetic modes of periodic dielectric structures, on both serial and parallel computers. quantum mechanics py-quspin 0.3.5_py36 Website QuSpin is an open-source Python package for exact diagonalization and quantum dynamics of arbitrary boson, fermion and spin many-body systems. quantum mechanics py-qutip 4.5.2_py36 Website QuTiP is open-source software for simulating the dynamics of closed and open quantum systems. system # Field Module name Version(s) URL Description scm gh 1.9.1 Website gh is GitHub on the command line. It brings pull requests, issues, and other GitHub concepts to the terminal next to where you are already working with git and your code. backup restic 0.9.5 0.12.0 Website Fast, secure, efficient backup program. benchmark hp2p 3.2 Website Heavy Peer To Peer: a MPI based benchmark for network diagnostic. benchmark mpibench 20190729 Website Times MPI collectives over a series of message sizes. benchmark mprime 29.4 Website mprime is used by GIMPS, a distributed computing project dedicated to finding new Mersenne prime numbers, and which is commonly used as a stability testing utility. benchmark osu-micro-benchmarks 5.6.1 5.6.3 5.7 Website The OSU MicroBenchmarks carry out a variety of message passing performance tests using MPI . checkpointing dmtcp 2.6.0 Website DMTCP (Distributed MultiThreaded Checkpointing) transparently checkpoints a single-host or distributed computation in user-space -- with no modifications to user code or to the O/S. compression libarchive 3.3.2 3.4.2 Website The libarchive project develops a portable, efficient C library that can read and write streaming archives in a variety of formats. compression libzip 1.5.1 Website libzip is a C library for reading, creating, and modifying zip archives. compression lz4 1.8.0 Website LZ4 is lossless compression algorithm. compression lzo 2.10 Website LZO is a portable lossless data compression library written in ANSI C. compression mpibzip2 0.6 Website MPIBZIP2 is a parallel implementation of the bzip2 block-sorting file compressor that uses MPI and achieves significant speedup on cluster machines. compression p7zip 16.02 Website p7zip is a Linux port of 7zip, a file archiver with high compression ratio. compression pbzip2 1.1.12 Website PBZIP2 is a parallel implementation of the bzip2 block-sorting file compressor that uses pthreads and achieves near-linear speedup on SMP machines. compression pigz 2.4 Website A parallel implementation of gzip for modern multi-processor, multi-core machines. compression szip 2.1.1 Website Szip compression software, providing lossless compression of scientific data, is an implementation of the extended-Rice lossless compression algorithm. compression xz 5.2.3 Website XZ Utils is free general-purpose data compression software with a high compression ratio. compression zlib 1.2.11 Website zlib is designed to be a free, general-purpose, legally unencumbered -- that is, not covered by any patents -- lossless data-compression library for use on virtually any computer hardware and operating system. containers libnvidia-container 1.0.0rc2 Website libnvidia-container is a library and a simple CLI utility to automatically configure GNU/Linux containers leveraging NVIDIA hardware. containers proot 5.1.0 Website PRoot is a user-space implementation of chroot, mount --bind, and binfmt_misc. database bdb 6.2.32 Website Berkeley DB (BDB) is a software library intended to provide a high-performance embedded database for key/value data. database mariadb 10.2.11 Website MariaDB is a community-developed fork of the MySQL relational database management system intended to remain free under the GNU GPL. database postgresql 10.5 Website PostgreSQL is a powerful, open source object-relational database system with a strong focus on reliability, feature robustness, and performance. database sqlite 3.18.0 Website SQLite is a self-contained, high-reliability, embedded, full-featured, public-domain, SQL database engine. document management pandoc 2.7.3 Website Pandoc is a universal document converter. document processing ghostscript 9.53.2 Website Ghostscript is an interpreter for the PostScript language and PDF files. document processing lyx 2.3.2 Website LyX is a document processor. document processing poppler 0.47.0 Website Poppler is a PDF rendering library. document processing texinfo 6.6 Website Texinfo is the official documentation format of the GNU project. document processing texlive 2019 Website TeX Live is an easy way to get up and running with the TeX document production system. file management duc 1.4.4 Website Duc is a collection of tools for indexing, inspecting and visualizing disk usage. file management exa 0.8.0 Website exa is a replacement for ls written in Rust. file management fpart 0.9.3 Website fpart sorts files and packs them into partitions. file management ncdu 1.15.1 Website Ncdu is a disk usage analyzer with an ncurses interface. file management py-pcircle 0.17_py27 Website pcircle contains a suite of file system tools developed at OLCF to take advantage of highly scalable parallel file system such as Lustre. file management rmlint 2.8.0 Website rmlint finds space waste and other broken things on your filesystem and offers to remove it. file transfer aria2 1.35.0 Website aria2 is a lightweight multi-protocol & multi-source command-line download utility. file transfer aspera-cli 3.9.6 Website The IBM Aspera Command-Line Interface (the Aspera CLI) is a collection of Aspera tools for performing high-speed, secure data transfers from the command line. file transfer aws-cli 2.0.50 Website This package provides a unified command line interface to Amazon Web Services. file transfer gsutil 4.31 Website gsutil is a Python application that lets you access Cloud Storage from the command line. file transfer lftp 4.8.1 Website LFTP is a sophisticated file transfer program supporting a number of network protocols (ftp, http, sftp, fish, torrent). file transfer mpifileutils 0.10.1 Website mpiFileUtils is a suite of MPI -based tools to manage large datasets, which may vary from large directory trees to large files. file transfer py-globus-cli 1.2.0 1.9.0_py27 1.9.0_py36 Website A command line wrapper over the Globus SDK for Python. file transfer rclone 1.39 1.43.1 1.49.5 1.55.1 Website Rclone is a command line program to sync files and directories to and from: Google Drive, Amazon S3, Dropbox, Google Cloud Storage, Amazon Drive, Microsoft One Drive, Hubic, Backblaze B2, Yandex Disk, or the local filesystem. framework mono 5.12.0.301 5.20.1.19 Website Mono is an open source implementation of Microsoft's .NET Framework based on the ECMA standards for C# and the Common Language Runtime. language tcltk 8.6.6 Website Tcl (Tool Command Language) is a dynamic programming language, suitable for web and desktop applications, networking, administration, testing. Tk is a graphical user interface toolkit. libs apr 1.6.3 Website The Apache Portable Runtime is a supporting library for the Apache web server. It provides a set of APIs that map to the underlying operating system. libs apr-util 1.6.1 Website The Apache Portable Runtime is a supporting library for the Apache web server. It provides a set of APIs that map to the underlying operating system. libs atk 2.24.0 Website ATK is the Accessibility Toolkit. It provides a set of generic interfaces allowing accessibility technologies such as screen readers to interact with a graphical user interface. libs benchmark 1.2.0 Website A microbenchmark support library libs cairo 1.14.10 Website Cairo is a 2D graphics library with support for multiple output devices. libs cups 2.2.4 Website CUPS is the standards-based, open source printing system. libs dbus 1.10.22 Website D-Bus is a message bus system, a simple way for applications to talk to one another. libs enchant 1.6.1 2.2.3 Website Enchant is a library (and command-line program) that wraps a number of different spelling libraries and programs with a consistent interface. libs fltk 1.3.4 Website FLTK (pronounced 'fulltick') is a cross-platform C++ GUI toolkit. libs fontconfig 2.12.4 Website Fontconfig is a library for configuring and customizing font access. libs freeglut 3.0.0 Website FreeGLUT is a free-software/open-source alternative to the OpenGL Utility Toolkit (GLUT) library. libs freetype 2.8 2.9.1 Website FreeType is a software font engine that is designed to be small, efficient, highly customizable, and portable while capable of producing high-quality output (glyph images). libs gc 7.6.0 Website The Boehm-Demers-Weiser conservative garbage collector can be used as a garbage collecting replacement for C malloc or C++ new. libs gconf 2.9.91 Website GConf is a system for storing application preferences. libs gdk-pixbuf 2.36.8 Website The GdkPixbuf library provides facilities for loading images in a variety of file formats. libs gflags 2.2.1 Website The gflags package contains a C++ library that implements commandline flags processing. libs giflib 5.1.4 Website GIFLIB is a package of portable tools and library routines for working with GIF images. libs glib 2.52.3 Website The GLib library provides core non-graphical functionality such as high level data types, Unicode manipulation, and an object and type system to C programs. libs glog 0.3.5 Website C++ implementation of the Google logging module. libs gnutls 3.5.9 Website GnuTLS is a secure communications library implementing the SSL, TLS and DTLS protocols and technologies around them. libs gobject-introspection 1.52.1 Website GObject introspection is a middleware layer between C libraries (using GObject) and language bindings. libs googletest 1.8.0 Website Google Test is Google's C++ test framework. libs gtk+ 2.24.30 3.22.18 Website GTK+, or the GIMP Toolkit, is a multi-platform toolkit for creating graphical user interfaces. libs harfbuzz 1.4.8 Website HarfBuzz is an OpenType text shaping engine. libs hunspell 1.6.2 Website Hunspell is a spell checker. libs hyphen 2.8.8 Website Hyphen is a hyphenation library to use converted TeX hyphenation patterns. libs icu 59.1 Website ICU is a set of C/C++ and Java libraries providing Unicode and Globalization support for software applications. libs json-glib 1.4.4 Website JSON-GLib is a library providing serialization and deserialization support for the JavaScript Object Notation (JSON) format described by RFC 4627. libs libaio 0.3.111 Website libaio provides the Linux-native API for async I/O . libs libepoxy 1.4.1 Website Epoxy is a library for handling OpenGL function pointer management for you. libs libexif 0.6.21 Website A library for parsing, editing, and saving EXIF data. libs libffi 3.2.1 Website libffi is a portable Foreign Function Interface library. libs libgcrypt 1.8.2 Website Libgcrypt is a general purpose cryptographic library originally based on code from GnuPG. libs libgd 2.2.5 Website GD is an open source code library for the dynamic creation of images by programmers. libs libgdiplus 5.6 Website C-based implementation of the GDI+ API libs libgpg-error 1.27 Website Libgpg-error is a small library that originally defined common error values for all GnuPG components. libs libidl 0.8.14 Website The libIDL package contains libraries for Interface Definition Language files. This is a specification for defining portable interfaces. libs libjpeg-turbo 1.5.1 Website libjpeg-turbo is a JPEG image codec that uses SIMD instructions (MMX, SSE2, AVX2, NEON, AltiVec) to accelerate baseline JPEG compression and decompression on x86, x86-64, ARM, and PowerPC systems libs libmng 2.0.3 Website THE reference library for reading, displaying, writing and examining Multiple-Image Network Graphics. MNG is the animation extension to the popular PNG image-format. libs libpng 1.2.57 1.6.29 Website libpng is the official PNG reference library. It supports almost all PNG features, is extensible, and has been extensively tested for over 20 years. libs libproxy 0.4.15 Website libproxy is a library that provides automatic proxy configuration management. libs libressl 2.5.3 3.2.1 Website LibreSSL is a version of the TLS/crypto stack forked from OpenSSL in 2014, with goals of modernizing the codebase, improving security, and applying best practice development processes. libs libseccomp 2.3.3 Website The libseccomp library provides an easy to use, platform independent, interface to the Linux Kernel's syscall filtering mechanism.. libs libsodium 1.0.18 Website Sodium is a modern, easy-to-use software library for encryption, decryption, signatures, password hashing and more. libs libsoup 2.61.2 Website libsoup is an HTTP client/server library for GNOME. libs libtasn1 4.13 Website Libtasn1 is the ASN.1 library used by GnuTLS, p11-kit and some other packages. libs libtiff 4.0.8 Website libtiff provides support for the Tag Image File Format (TIFF), a widely used format for storing image data. libs libunistring 0.9.7 Website Libunistring provides functions for manipulating Unicode strings and for manipulating C strings according to the Unicode standard. libs libuuid 1.0.3 Website Portable uuid C library. libs libuv 1.38.1 Website libuv is a multi-platform support library with a focus on asynchronous I/O . libs libwebp 0.6.1 Website WebP is a modern image format that provides superior lossless and lossy compression for images on the web. libs libxkbcommon 0.9.1 Website libxkbcommon is a keyboard keymap compiler and support library which processes a reduced subset of keymaps as defined by the XKB (X Keyboard Extension) specification. libs libxml2 2.9.4 Website Libxml2 is a XML C parser and toolkit. libs libxslt 1.1.32 Website Libxslt is the XSLT C library developed for the GNOME project. XSLT itself is a an XML language to define transformation for XML. libs mesa 17.1.6 Website Mesa is an open-source implementation of the OpenGL, Vulkan and other specifications. libs ncurses 6.0 Website The ncurses (new curses) library is a free software emulation of curses in System V Release 4.0 (SVr4), and more. libs nettle 3.3 Website Nettle is a cryptographic library that is designed to fit easily in more or less any context. libs openjpeg 2.3.1 Website OpenJPEG is an open-source JPEG 2000 codec written in C language. libs orbit 2.14.19 Website ORBit2 is a CORBA 2.4-compliant Object Request Broker (ORB) featuring mature C, C++ and Python bindings. libs pango 1.40.10 Website Pango is a library for laying out and rendering of text, with an emphasis on internationalization. libs pcre 8.40 Website The PCRE library is a set of functions that implement regular expression pattern matching using the same syntax and semantics as Perl 5. libs pcre2 10.35 Website The PCRE22 library is a set of functions that implement regular expression pattern matching using the same syntax and semantics as Perl 5. libs popt 1.16 Website Library for parsing command line options. libs py-lmdb 0.93 Website Universal Python binding for the LMDB 'Lightning' Database. libs py-mako 1.0.7_py27 1.0.7_py36 Website Mako is a template library written in Python. It provides a familiar, non-XML syntax which compiles into Python modules for maximum performance. libs py-pygobject 3.32.2_py36 Website PyGObject is a Python package which provides bindings for GObject based libraries such as GTK, GStreamer, WebKitGTK, GLib, GIO and many more. libs py-pyopengl 3.1.5_py39 Website Standard OpenGL bindings for Python. libs py-pyqt5 5.9.1_py36 Website PyQt5 is a comprehensive set of Python bindings for Qt v5. libs readline 7.0 Website The GNU Readline library provides a set of functions for use by applications that allow users to edit command lines as they are typed in. libs serf 1.3.9 Website The serf library is a high performance C-based HTTP client library built upon the Apache Portable Runtime (APR) library. libs snappy 1.1.7 Website A fast compressor/decompressor. libs talloc 2.1.14 Website talloc is a hierarchical, reference counted memory pool system with destructors. libs utf8proc 2.4.0 Website iutf8proc is a small, clean C library that provides Unicode normalization, case-folding, and other operations for data in the UTF-8 encoding. libs wxwidgets 3.0.4 Website wxWidgets is a C++ library that lets developers create applications for Windows, macOS, Linux and other platforms with a single code base. media ffmpeg 4.0 4.2.1 Website FFmpeg is the leading multimedia framework, able to decode, encode, transcode, mux, demux, stream, filter and play pretty much anything that humans and machines have created. media libsndfile 1.0.28 Website Libsndfile is a C library for reading and writing files containing sampled sound (such as MS Windows WAV and the Apple/SGI AIFF format) through one standard library interface. performance likwid 4.3.2 Website Likwid is a simple toolsuite of command line applications for performance oriented programmers. resource monitoring nvtop 1.1.0 Website Nvtop stands for NVidia TOP, a (h)top like task monitor for NVIDIA GPUs. scm git 2.12.2 Website Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. scm git-lfs 2.4.0 Website Git Large File Storage (LFS) replaces large files such as audio samples, videos, datasets, and graphics with text pointers inside Git, while storing the file contents on a remote server. scm libgit2 1.1.0 Website libgit2 is a portable, pure C implementation of the Git core methods provided as a re-entrant linkable library with a solid API scm mercurial 4.5.3 Website Mercurial is a free, distributed source control management tool. scm py-dvc 0.91.1_py36 Website Data Version Control or DVC is an open-source tool for data science and machine learning projects. scm subversion 1.9.7 1.12.2 Website Subversion is an open source version control system. tools clinfo 2.2.18.04.06 Website clinfo is a simple command-line application that enumerates all possible (known) properties of the OpenCL platform and devices available on the system. tools curl 7.54.0 Website curl is an open source command line tool and library for transferring data with URL syntax. tools depot_tools 20200731 Website Tools for working with Chromium development. tools expat 2.2.3 Website Expat is a stream-oriented XML parser library written in C. tools graphicsmagick 1.3.26 Website GraphicsMagick is the swiss army knife of image processing. tools imagemagick 7.0.7-2 Website ImageMagick is a free and open-source software suite for displaying, converting, and editing raster image and vector image files. tools leveldb 1.20 Website Symas LMDB is an extraordinarily fast, memory-efficient database we developed for the Symas OpenLDAP Project. tools lmdb 0.9.21 Website Symas LMDB is an extraordinarily fast, memory-efficient database we developed for the Symas OpenLDAP Project. tools motif 2.3.7 Website Motif is the toolkit for the Common Desktop Environment. tools parallel 20180122 20200822 Website GNU parallel is a shell tool for executing jobs in parallel using one or more computers. tools qt 5.9.1 Website QT is a cross-platform application framework that is used for developing application software that can be run on various software and hardware platforms. tools ripgrep 11.0.1 Website ripgrep recursively searches directories for a regex pattern. tools rocksdb 5.7.3 Website A library that provides an embeddable, persistent key-value store for fast storage. tools x11 7.7 Website The X.Org project provides an open source implementation of the X Window System. tools xkeyboard-config 2.21 Website The non-arch keyboard configuration database for X Window. viz # Field Module name Version(s) URL Description data ncview 2.1.7 Website Ncview is a visual browser for netCDF format files. gis panoply 4.10.8 Website Panoply plots geo-referenced and other arrays from netCDF, HDF, GRIB, and other datasets. graphs graphviz 2.40.1 2.44.1 Website Graphviz is open source graph visualization software. imaging py-pillow 5.1.0_py27 5.1.0_py36 7.0.0_py36 8.2.0_py39 Website Pillow is a friendly PIL (Python Imaging Library) fork. imaging py-pillow-simd 7.0.0.post3_py36 Website Pillow-SIMD is an optimized version of Pillow molecular visualization pymol 1.8.6.2 Website PyMOL is a Python-enhanced molecular graphics tool. plotting gnuplot 5.2.0 Website Gnuplot is a portable command-line driven graphing utility for Linux, OS /2, MS Windows, OSX, VMS, and many other platforms. plotting grace 5.1.25 Website Grace is a WYSIWYG tool to make two-dimensional plots of numerical data. plotting py-basemap 1.1.0_py27 1.1.0_py36 Website The matplotlib basemap toolkit is a library for plotting 2D data on maps in Python. plotting py-matplotlib 2.2.2_py27 2.1.2_py27 2.1.2_py36 2.2.2_py36 3.1.1_py36 3.2.1_py36 3.4.2_py39 Website Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. plotting py-plotly 2.4.1_py27 Website Plotly's Python graphing library makes interactive, publication-quality graphs online. remote display virtualgl 2.5.2 Website VirtualGL is an open source toolkit that gives any Unix or Linux remote display software the ability to run OpenGL applications with full 3D hardware acceleration.","title":"List"},{"location":"docs/software/list/#software-list","text":"The full list of software centrally installed and managed on Sherlock is in the tables below. Work in progress Software installations on Sherlock are an ever ongoing process. We're continuously adding new software to the list. If you're looking for something that is not in the list, please take a look here for options.","title":"Software list"},{"location":"docs/software/list/#categories","text":"Software modules on Sherlock are organized in categories , by scientific field or functional class. It means that you will have to first load a category module before getting access to individual modules. The math and devel categories are loaded by default. See the Modules page for further details and examples. We currently provide 416 software modules, in 7 categories, covering 75 fields of science: biology clinical science, computational biology, cryo-em, genomics, neurology, pathology, phylogenetics, population genetics chemistry cheminformatics, computational chemistry, crystallography, electrostatics, molecular dynamics, quantum chemistry devel build, compiler, data, data analytics, debug, engine, framework, language, lib, mpi, networking, parser, profiling, runtime, sdk math computational geometry, deep learning, linear algebra, machine learning, numerical analysis, numerical library, optimization, scientific computing, statistics, symbolic physics astronomy, CFD, climate modeling, geophysics, geoscience, materials science, micromagnetics, particle, photonics, quantum mechanics system backup, benchmark, checkpointing, compression, containers, database, devel, scm, document management, document processing, file management, file transfer, framework, language, libs, media, performance, resource monitoring, scm, tools viz data, gis, graphs, imaging, molecular visualization, plotting, remote display Licensed software Access to software modules marked with in the tables below is restricted to properly licensed user groups. SRCC is not funded to provide commercial software on Sherlock and researchers are responsible for the costs of purchasing and renewing commercial software licenses. For more information, please feel free to contact us and see the Stanford Software Licensing page for purchasing information. Additional flags and features Some of the modules listed below have been built to support specific architectures or parallel execution modes: versions marked with support GPU acceleration versions marked with support MPI parallel execution versions marked with are the default version for the module","title":"Categories"},{"location":"docs/software/list/#biology","text":"Field Module name Version(s) URL Description clinical science simvascular 20180704 Website Simvascular is a blood flow simulation and analysis toolkit. This module provides the svFSI (Fluid Solid Interaction) solver. computational biology py-biopython 1.70_py27 Website Biopython is a set of freely available tools for biological computation written in Python. computational biology rosetta 3.8 Website Rosetta is the premier software suite for modeling macromolecular structures. As a flexible, multi-purpose application, it includes tools for structure prediction, design, and remodeling of proteins and nucleic acids. cryo-em ctffind 4.1.13 Website ctffind is a program for finding CTFs of electron micrographs. cryo-em eman2 2.2 Website EMAN2 is a broadly based greyscale scientific image processing suite with a primary focus on processing data from transmission electron microscopes. cryo-em imod 4.9.12 4.11.5 Website IMOD is a set of image processing, modeling and display programs used for tomographic reconstruction and for 3D reconstruction of EM serial sections and optical sections. cryo-em motioncor2 1.3.1 Website MotionCor2 is a multi- GPU accelerated program which corrects anisotropic image motion at the single pixel level. cryo-em relion 2.0.3 2.1 Website RELION (for REgularised LIkelihood OptimisatioN, pronounce rely-on) is a stand-alone computer program that employs an empirical Bayesian approach to refinement of (multiple) 3D reconstructions or 2D class averages in electron cryo-microscopy (cryo-EM). genomics angsd 0.919 0.931 Website ANGSD is a software for analyzing next generation sequencing data. genomics augustus 3.3.2 Website AUGUSTUS is a program that predicts genes in eukaryotic genomic sequences. genomics bamtools 2.5.1 Website BamTools is a project that provides both a C++ API and a command-line toolkit for reading, writing, and manipulating BAM (genome alignment) files. genomics bcftools 1.6 1.8 Website BCFtools is a program for variant calling and manipulating files in the Variant Call Format (VCF) and its binary counterpart BCF. genomics bcl2fastq 2.20 Website The bcl2fastq2 conversion software can be used to convert BCL files from MiniSeq, MiSeq, NextSeq, HiSeq, iSeq and NovaSeq sequening systems. genomics bedtools 2.27.1 Website The bedtools utilities are a swiss-army knife of tools for a wide-range of genomics analysis tasks. genomics bgen 1.1.4 Website bgen is the reference implementation of the BGEN format, a binary file format for imputed genotype and haplotype data. genomics bowtie 1.2.2 Website Bowtie is an ultrafast, memory-efficient short read aligner. genomics bowtie2 2.3.4.1 Website Bowtie 2 is an ultrafast and memory-efficient tool for aligning sequencing reads to long reference sequences. genomics bwa 0.7.17 Website BWA (Burrows-Wheeler Aligner) is a software package for mapping low-divergent sequences against a large reference genome, such as the human genome. genomics canu 1.8 Website A single molecule sequence assembler for genomes large and small. genomics cufflinks 2.2.1 Website Cufflinks assembles transcripts, estimates their abundances, and tests for differential expression and regulation in RNA-Seq samples. genomics fastqc 0.11.8 Website FastQC aims to provide a simple way to do some quality control checks on raw sequence data coming from high throughput sequencing pipelines. genomics fastx_toolkit 0.0.14 Website The FASTX-Toolkit is a collection of command line tools for Short-Reads FASTA/FASTQ files preprocessing. genomics freebayes 1.2.0 Website FreeBayes is a Bayesian genetic variant detector designed to find small polymorphisms. genomics gatk 4.1.0.0 4.1.4.1 Website GATK (Genome Analysis Toolkit) offers a wide variety of tools with a primary focus on variant discovery and genotyping. genomics hic-pro 2.10.0 Website HiC-Pro: An optimized and flexible pipeline for Hi-C data processing. genomics hisat2 2.1.0 Website HISAT2 is a fast and sensitive alignment program for mapping next-generation sequencing reads (both DNA and RNA) to a population of human genomes (as well as to a single reference genome). genomics htslib 1.6 1.8 1.10.2 Website C library for high-throughput sequencing data formats. genomics jellyfish 2.2.10 Website A fast multi-threaded k-mer counter. genomics kallisto 0.44.0 Website kallisto is a program for quantifying abundances of transcripts from RNA-Seq data using high-throughput sequencing reads. genomics metal 20110325 Website The METAL software is designed to facilitate meta-analysis of large datasets (such as several whole genome scans) in a convenient, rapid and memory efficient manner. genomics mixcr 2.1.12 Website MiXCR is a universal framework that processes big immunome data from raw sequences to quantitated clonotypes. genomics ncbi-blast+ 2.6.0 2.7.1 2.11.0 Website NCBI BLAST+ is a suite of command-line tools to run BLAST (Basic Local Alignment Search Tool), an algorithm for comparing primary biological sequence information. genomics plink 1.07 1.90b5.3 2.0a1 2.0a2 Website PLINK is a free, open-source whole genome association analysis toolset, designed to perform a range of basic, large-scale analyses in a computationally efficient manner. genomics py-busco 3.0.2_py27 Website Assessing genome assembly and annotation completeness with Benchmarking Universal Single-Copy Orthologs (BUSCO). genomics py-bx-python 0.8.1_py27 Website Tools for manipulating biological data, particularly multiple sequence alignments. genomics py-cutadapt 1.18_py27 1.18_py36 Website Cutadapt finds and removes adapter sequences, primers, poly-A tails and other types of unwanted sequence from your high-throughput sequencing reads. genomics py-deeptools 3.3.1_py36 Website Tools to process and analyze deep sequencing data. genomics py-fithic 1.1.3_py27 Website Fit-Hi-C is a tool for assigning statistical confidence estimates to chromosomal contact maps produced by genome architecture assays. genomics py-macs2 2.1.1_py27 Website MACS (Model-based Analysis of ChIP-Seq) implements a novel ChIP-Seq analysis method. genomics py-mapdamage 2.2.1_py36 Website mapDamage2 is a computational framework which tracks and quantifies DNA damage patterns among ancient DNA sequencing reads generated by Next-Generation Sequencing platforms. genomics py-multiqc 1.6_py27 1.6_py36 Website MultiQC is a reporting tool that parses summary statistics from results and log files generated by other bioinformatics tools. genomics py-obitools 1.2.13_py27 Website OBITools is a set of programs designed for analyzing NGS data in a DNA metabarcoding context. genomics py-pybedtools 0.8.0_py27 0.8.2_py36 Website Pybedtools wraps and extends BEDTools and offers feature-level manipulations from within Python. genomics py-pysam 0.14.1_py27 0.15.3_py36 Website Pysam is a python module for reading, manipulating and writing genomic data sets. genomics rsem 1.3.3 Website RSEM is a software package for estimating gene and isoform expression levels from RNA-Seq data. genomics salmon 0.12.0 Website Highly-accurate & wicked fast transcript-level quantification from RNA-seq reads using lightweight alignments. genomics samtools 1.6 1.8 Website Tools (written in C using htslib) for manipulating next-generation sequencing data. genomics sentieon 201808.01 Website Sentieon Genomics software is a set of software tools that perform analysis of genomic data obtained from DNA sequencing. genomics shapeit 4.0.0 Website SHAPEIT4 is a fast and accurate method for estimation of haplotypes (aka phasing) for SNP array and high coverage sequencing data. genomics star 2.5.4b Website STAR: ultrafast universal RNA-seq aligner. genomics tophat 2.1.1 Website TopHat is a fast splice junction mapper for RNA-Seq reads. genomics trim_galore 0.5.0 Website Trim Galore! is a wrapper script to automate quality and adapter trimming as well as quality control, with some added functionality to remove biased methylation positions for RRBS sequence files. genomics trinity 2.8.4 Website Trinity RNA-Seq de novo transcriptome assembly. genomics vcflib 1.0.0 Website A C++ library for parsing and manipulating VCF files. genomics vcftools 0.1.15 Website VCFtools is a program package designed for working with VCF files, such as those generated by the 1000 Genomes Project. neurology afni 17.2.07 18.2.04 Website AFNI (Analysis of Functional NeuroImages) is a set of C programs for processing, analyzing, and displaying functional MRI (FMRI) data - a technique for mapping human brain activity. neurology ants 2.1.0 2.3.1 Website ANTs computes high-dimensional mappings to capture the statistics of brain structure and function. neurology dcm2niix 1.0.20171215 Website dcm2niix is a program esigned to convert neuroimaging data from the DICOM format to the NIfTI format. neurology freesurfer 6.0.0 7.1.1 Website An open source software suite for processing and analyzing (human) brain MRI images. neurology fsl 5.0.10 Website FSL is a comprehensive library of analysis tools for FMRI, MRI and DTI brain imaging data. neurology mricron 20160502 Website MRIcron is a cross-platform NIfTI format image viewer. neurology mrtrix 0.3.16 Website MRtrix3 provides a set of tools to perform various types of diffusion MRI analyses, from various forms of tractography through to next-generation group-level analyses. neurology py-mdt 0.10.9_py36 Website The Maastricht Diffusion Toolbox, MDT, is a framework and library for parallelized ( GPU and multi-core CPU ) diffusion Magnetic Resonance Imaging (MRI) modeling. neurology py-nipype 1.1.3_py27 1.1.3_py36 Website Nipype is a Python project that provides a uniform interface to existing neuroimaging software and facilitates interaction between these packages within a single workflow. neurology spm 12 Website The SPM software package has been designed for the analysis of brain imaging data sequences. The sequences can be a series of images from different cohorts, or time-series from the same subject. neurology workbench 1.3.1 Website Connectome Workbench is an open source, freely available visualization and discovery tool used to map neuroimaging data, especially data generated by the Human Connectome Project. pathology openslide 3.4.1 Website OpenSlide is a C library that provides a simple interface to read whole-slide images (also known as virtual slides). pathology py-openslide-python 1.1.1_py27 1.1.1_py36 Website OpenSlide Python is a Python interface to the OpenSlide library. phylogenetics py-ete 3.0.0_py27 Website A Python framework for the analysis and visualization of trees. population genetics py-admixfrog 0.6.1_py36 Website Admixfrog is a HMM to infer ancestry frogments (fragments) from low-coverage, contaminated data.","title":"biology"},{"location":"docs/software/list/#chemistry","text":"Field Module name Version(s) URL Description cheminformatics py-rdkit 2018.09.1_py27 2018.09.1_py36 Website RDKit is a collection of cheminformatics and machine-learning software written in C++ and Python. computational chemistry gaussian g16.A03 g16.B01 Website Gaussian is a general purpose computational chemistry software package. computational chemistry libint 1.1.4 2.0.3 Website Libint computes molecular integrals. computational chemistry libxc 3.0.0 Website Libxc is a library of exchange-correlation functionals for density-functional theory. computational chemistry nwchem 6.8 Website NWChem is an ab initio computational chemistry software package which also includes quantum chemical and molecular dynamics functionality. computational chemistry py-ase 3.14.1_py27 Website The Atomic Simulation Environment (ASE) is a set of tools and Python modules for setting up, manipulating, running, visualizing and analyzing atomistic simulations. computational chemistry schrodinger 2017-3 2018-1 2018-2 2019-2 2020-2 2021-1 Website Schr\u00f6dinger Suites (Small-molecule Drug Discovery Suite, Material Science Suite, Biologics Suite) provide a set of molecular modelling software. computational chemistry vasp 5.4.1 6.6.1 Website The Vienna Ab initio Simulation Package (VASP) is a computer program for atomic scale materials modelling, e.g. electronic structure calculations and quantum-mechanical molecular dynamics, from first principles. crystallography vesta 3.4.4 Website VESTA is a 3D visualization program for structural models, volumetric data such as electron/nuclear densities, and crystal morphologies. electrostatics apbs 1.5 Website APBS solves the equations of continuum electrostatics for large biomolecular assemblages. molecular dynamics gromacs 2016.3 2018 Website GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. molecular dynamics lammps 20180316 20200303 Website LAMMPS is a classical molecular dynamics code that models an ensemble of particles in a liquid, solid, or gaseous state. molecular dynamics openmm 7.1.1 Website A high performance toolkit for molecular simulation. molecular dynamics plumed 2.3.2 Website PLUMED is an open source library for free energy calculations in molecular systems. molecular dynamics py-raspa2 2.0.3_py27 Website RASPA2 is a general purpose classical simulation package that can be used for the simulation of molecules in gases, fluids, zeolites, aluminosilicates, metal-organic frameworks, carbon nanotubes and external fields. molecular dynamics qbox 1.65.0 Website Qbox is a First-Principles Molecular Dynamics code. molecular dynamics quip 20170901 Website The QUIP package is a collection of software tools to carry out molecular dynamics simulations. quantum chemistry cp2k 4.1 Website CP2K is a quantum chemistry and solid state physics software package that can perform atomistic simulations of solid state, liquid, molecular, periodic, material, crystal, and biological systems. quantum chemistry orca 4.2.1 Website ORCA is a flexible, efficient and easy-to-use general purpose tool for quantum chemistry. quantum chemistry quantum-espresso 6.2.1 6.6 Website Quantum ESPRESSO is an integrated suite of Open-Source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials. quantum chemistry quantum-espresso_gpu 1.1 Website GPU -accelerated Quantum ESPRESSO using CUDA FORTRAN","title":"chemistry"},{"location":"docs/software/list/#devel","text":"Field Module name Version(s) URL Description build bazel 0.16.1 0.26.1 0.29.1 Website Bazel is a fast, scalable, multi-language and extensible build system. build bazelisk 1.3.0 1.8.0 Website Bazelisk is a wrapper for Bazel written in Go. build cmake 3.8.1 3.11.1 3.13.1 Website CMake is an extensible, open-source system that manages the build process in an operating system and in a compiler-independent manner. build kerl 1.8.5 Website Kerl is a tool to easily build and install Erlang/OTP instances. build ninja 1.9.0 Website Ninja is a small build system with a focus on speed. build py-meson 0.51.1_py36 Website Meson is an open source build system meant to be both extremely fast, and, even more importantly, as user friendly as possible. build py-scons 3.0.5_py27 3.0.5_py36 Website SCons is an Open Source software construction tool. compiler aocc 2.1.0 2.2.0 Website AMD Optimizing C/C++ Compiler - AOCC is a highly optimized C, C++ and Fortran compiler for x86 targets especially for Zen based AMD processors. compiler gcc 6.3.0 7.1.0 7.3.0 8.1.0 9.1.0 10.1.0 Website The GNU Compiler Collection includes front ends for C, C++, Fortran, Java, and Go, as well as libraries for these languages (libstdc++, libgcj,...). compiler icc 2017.u2 2018.u1 2018 2019 Website Intel C++ Compiler, also known as icc or icl, is a group of C and C++ compilers from Intel compiler ifort 2017.u2 2018.u1 2018 2019 Website Intel Fortran Compiler, also known as ifort, is a group of Fortran compilers from Intel compiler llvm 3.8.1 4.0.0 5.0.0 7.0.0 Website The LLVM Project is a collection of modular and reusable compiler and toolchain technologies. Clang is an LLVM native C/C++/Objective-C compiler, compiler nagfor npl6a61na Website The NAG Fortran Compiler is a full standard implementation of the ISO Fortran 95 language with the addition of all of Fortran 2003, most of Fortran 2008 and OpenMP 3.0 and 3.1. compiler pgi 19.10 Website PGI compilers and tools, including Open MPI (Community Edition). compiler smlnj 110.81 Website Standard ML of New Jersey (abbreviated SML/NJ) is a compiler for the Standard ML '97 programming language. data h5utils 1.12.1 Website h5utils is a set of utilities for visualization and conversion of scientific data in the free, portable HDF5 format. data hdf5 1.10.6 1.10.0p1 1.10.2 Website HDF5 is a data model, library, and file format for storing and managing data. It supports an unlimited variety of datatypes, and is designed for flexible and efficient I/O and for high volume and complex data. data hiredis 0.13.3 Website Hiredis is a minimalistic C client library for the Redis database. data ncl 6.4.0 6.6.2 Website NCL is a free interpreted language designed specifically for scientific data processing and visualization. data nco 4.8.0 Website The NCO toolkit manipulates and analyzes data stored in netCDF-accessible formats. data netcdf 4.4.1.1 Website NetCDF is a set of software libraries and self-describing, machine-independent data formats that support the creation, access, and sharing of array-oriented scientific data. data pnetcdf 1.8.1 Website Parallel netCDF (PnetCDF) is a parallel I/O library for accessing NetCDF files in CDF-1, 2, and 5 formats. data protobuf 3.4.0 Website Protocol Buffers (a.k.a., protobuf) are Google's language-neutral, platform-neutral, extensible mechanism for serializing structured data. data py-pandas 0.23.0_py27 0.23.0_py36 1.0.3_py36 Website pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language. data py-protobuf 3.4.0_py27 3.4.0_py36 3.6.1_py27 3.6.1_py36 3.15.8_py36 Website Python bindings for Google's Protocol Buffers data interchange format. data redis 4.0.1 Website Redis is an open source, in-memory data structure store, used as a database, cache and message broker. data analytics hadoop 3.1.0 Website The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. data analytics py-sparkhpc 0.3 Website Launching and controlling spark on HPC clusters data analytics spark 2.3.0 Website Apache Spark\u2122 is a unified analytics engine for large-scale data processing. debug gdb 8.2.1 Website GDB is the GNU Project debugger. debug valgrind 3.14.0 Website Valgrind is an instrumentation framework for building dynamic analysis tools. engine v8 8.4.371.22 Website V8 is Google\u2019s open source high-performance JavaScript and WebAssembly engine, written in C++. framework dotnet 2.1.500 Website .NET is a free, cross-platform, open source developer platform for building many different types of applications. language cuda 9.0.176 8.0.61 9.1.85 9.2.88 9.2.148 10.0.130 10.1.105 10.1.168 10.2.89 11.0.3 11.1.1 11.2.0 Website CUDA is a parallel computing platform and application programming interface (API) model created by Nvidia. It allows software developers and software engineers to use a CUDA-enabled graphics processing unit ( GPU ) for general purpose processing. language erlang 21.3 Website Erlang is a programming language used to build massively scalable soft real-time systems with requirements on high availability. language go 1.9 1.14 Website Go is an open source programming language that makes it easy to build simple, reliable, and efficient software. language guile 2.0.11 2.2.2 Website GNU Guile is the preferred extension system for the GNU Project, which features an implementation of the Scheme programming language. language haskell 8.6.5 Website Haskell is a statically typed, purely functional programming language with type inference and lazy evaluation. language java 1.8.0_131 Website Java is a general-purpose computer programming language that is concurrent, class-based, object-oriented,[14] and specifically designed to have as few implementation dependencies as possible. language julia 1.0.0 1.1.0 1.2.0 1.3.1 1.4.0 1.5.1 Website Julia is a high-level, high-performance dynamic programming language for numerical computing. language lua 5.3.4 Website Lua is a powerful, efficient, lightweight, embeddable scripting language. It supports procedural programming, object-oriented programming, functional programming, data-driven programming, and data description. language luarocks 2.4.3 Website LuaRocks is the package manager for Lua modules. language manticore 20180301 Website Manticore is a high-level parallel programming language aimed at general-purpose applications running on multi-core processors. language nodejs 8.9.4 9.5.0 Website Node.js is a JavaScript runtime built on Chrome's V8 JavaScript engine. It provides the npm package manager. language perl 5.26.0 Website Perl 5 is a highly capable, feature-rich programming language with over 29 years of development. language php 7.3.0 Website PHP (recursive acronym for PHP: Hypertext Preprocessor) is an open source general-purpose scripting language that is especially suited for web development. language py-cython 0.27.3_py27 0.27.3_py36 0.29.21_py36 Website Cython is an optimising static compiler for both the Python programming language and the extended Cython programming language (based on Pyrex). language py-ipython 5.4.1_py27 6.1.0_py36 Website IPython is a command shell for interactive computing in multiple programming languages, originally developed for the Python programming language. language py-jupyter 1.0.0_py27 1.0.0_py36 Website Jupyter is a browser-based interactive notebook for programming, mathematics, and data science. It supports a number of languages via plugins. language python 2.7.13 3.6.1 3.9.0 Website Python is an interpreted, interactive, object-oriented programming language. language ruby 2.4.1 2.7.1 Website A dynamic, open source programming language with a focus on simplicity and productivity. It has an elegant syntax that is natural to read and easy to write. language rust 1.35.0 Website A language empowering everyone to build reliable and efficient software. language scala 2.12.6 Website Scala combines object-oriented and functional programming in one concise, high-level language. lib ant 1.10.1 Website Apache Ant is a Java library and command-line tool whose mission is to drive processes described in build files as targets and extension points dependent upon each other. lib boost 1.64.0 1.69.0 1.75.0 1.76.0 Website Boost is a set of libraries for the C++ programming language that provide support for tasks and structures such as linear algebra, pseudorandom number generation, multithreading, image processing, regular expressions, and unit testing. lib cnmem 1.0.0 Website CNMeM is a simple library to help the Deep Learning frameworks manage CUDA memory. lib cub 1.7.3 1.10.0 Website CUB is a flexible library of cooperative threadblock primitives and other utilities for CUDA kernel programming. lib cutlass 0.1.0 Website CUTLASS is a collection of CUDA C++ template abstractions for implementing high-performance matrix-multiplication (GEMM) at all levels and scales within CUDA. lib eigen 3.3.3 Website Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms. lib libctl 3.2.2 4.0.1 Website libctl is a library for supporting flexible control files in scientific simulations. lib libgpuarray 0.7.5 Website Library to manipulate tensors on the GPU . lib nccl 1.3.4 2.0.4 2.1.15 2.2.13 2.3.7 2.4.8 2.5.6 2.8.4 Website NCCL (pronounced 'Nickel') is a stand-alone library of standard collective communication routines, such as all-gather, reduce, broadcast, etc., that have been optimized to achieve high bandwidth over PCIe. lib opencv 3.3.0 4.5.2 Website OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library. lib petsc 3.10.3 Website PETSc is a suite of data structures and routines for the scalable (parallel) solution of scientific applications modeled by partial differential equations. lib py-h5py 2.7.1_py27 2.8.0_py36 2.10.0_py36 Website The h5py package is a Pythonic interface to the HDF5 binary data format. lib py-netcdf4 1.3.1_py27 1.3.1_py36 Website netcdf4-python is a Python interface to the netCDF C library. lib py-numba 0.35.0_py27 0.35.0_py36 0.53.1_py36 Website Numba is a compiler for Python array and numerical functions that gives you the power to speed up your applications with high performance functions written directly in Python.. lib py-pycuda 2017.1.1_py27 Website PyCUDA lets you access Nvidia\u2018s CUDA parallel computation API from Python. lib py-schwimmbad 0.3.1_py36 Website schwimmbad provides a uniform interface to parallel processing pools and enables switching easily between local development (e.g., serial processing or with multiprocessing) and deployment on a cluster or supercomputer (via, e.g., MPI or JobLib). lib py-scikit-image 0.13.0_py27 0.14.0_py27 0.15.0_py27 0.15.0_py36 0.17.2_py36 Website scikit-image is a collection of algorithms for image processing. lib rabbitmq 3.7.13 Website RabbitMQ is an open-source message broker. lib swig 3.0.12 Website SWIG is an interface compiler that connects programs written in C and C++ with scripting languages such as Perl, Python, Ruby, and Tcl. lib tbb 2017.u2 2018.u1 2018 2019 Website Intel\u00ae Threading Building Blocks (Intel\u00ae TBB) is a widely used C++ library for shared-memory parallel programming and heterogeneous computing (intra-node distributed memory programming). lib trilinos 12.12.1 Website Trilinos is a collection of open-source software libraries, called packages, intended to be used as building blocks for the development of scientific applications. lib zeromq 4.2.2 Website ZeroMQ (also spelled \u00d8MQ, 0MQ or ZMQ) is a high-performance asynchronous messaging library, aimed at use in distributed or concurrent applications. mpi hpcx 2.6.0 2.7.0 2.8.1 Website Mellanox HPC -X toolkit is a comprehensive software package that includes MPI and SHMEM/PGAS communications libraries. mpi impi 2017.u2 2018.u1 2018 2019 Website Intel\u00ae MPI Library is a multi-fabric message passing library that implements the Message Passing Interface, version 3.1 ( MPI -3.1) specification. mpi openmpi 2.0.2 2.1.1 3.1.2 4.0.3 4.0.5 4.1.0 Website The Open MPI Project is an open source Message Passing Interface implementation that is developed and maintained by a consortium of academic, research, and industry partners. mpi py-mpi4py 3.0.0_py27 3.0.3_py36 Website MPI for Python provides Python bindings for the Message Passing Interface ( MPI ) standard. It is implemented on top of the MPI -\u00bd/3 specification and exposes an API which grounds on the standard MPI -2 C++ bindings. networking gasnet 1.30.0 Website GASNet is a language-independent, low-level networking layer that provides network-independent, high-performance communication primitives tailored for implementing parallel global address space SPMD languages and libraries. networking libfabric 1.6.0 1.6.2 1.7.1 1.9.1 1.10.1 1.11.1 Website The Open Fabrics Interfaces (OFI) is a framework focused on exporting fabric communication services to applications. Libfabric is the library that defines and exports the user-space API of OFI. networking ucx 1.3.1 1.8.1 1.9.0 1.10.0 Website UCX is a communication library implementing high-performance messaging for MPI /PGAS frameworks. parser xerces-c 3.2.1 Website Xerces-C++ is a validating XML parser written in a portable subset of C++. profiling amd-uprof 3.3.462 Website AMD uProf is a performance analysis tool for applications. runtime starpu 1.3.2 Website StarPU is a unified runtime system that offers support for heterogeneous multicore architectures sdk google-cloud-sdk 240.0.0 338.0.0 Website Command-line interface for Google Cloud Platform products and services.","title":"devel"},{"location":"docs/software/list/#math","text":"Field Module name Version(s) URL Description computational geometry cgal 4.10 Website The Computational Geometry Algorithms Library (CGAL) is a C++ library that aims to provide easy access to efficient and reliable algorithms in computational geometry. computational geometry qhull 2015.2 Website Qhull computes the convex hull, Delaunay triangulation, Voronoi diagram, halfspace intersection about a point, furthest-site Delaunay triangulation, and furthest-site Voronoi diagram. deep learning caffe2 0.8.1 Website Caffe2 is a deep learning framework that provides an easy and straightforward way to experiment with deep learning and leverage community contributions of new models and algorithms. deep learning cudnn 6.0 7.0.1 7.0.4 7.0.5 7.1.4 7.4.1.5 7.6.4 7.6.5 8.1.1.33 Website NVIDIA cuDNN is a GPU -accelerated library of primitives for deep neural networks. deep learning cutensor 1.2.0 Website GPU -accelerated tensor linear algebra library. deep learning py-horovod 0.12.1_py27 0.12.1_py36 Website Horovod is a distributed training framework for TensorFlow. The goal of Horovod is to make distributed Deep Learning fast and easy to use. deep learning py-keras 2.1.5_py27 2.0.8_py27 2.1.5_py36 2.2.4_py27 2.2.4_py36 2.3.1_py36 Website Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. deep learning py-onnx 1.0.1_py27 1.8.1_py36 Website ONNX is a open format to represent deep learning models. deep learning py-pytorch 0.3.0_py27 0.2.0_py27 0.2.0_py36 0.3.0_py36 1.0.0_py27 1.0.0_py36 1.4.0_py36 1.8.1_py39 Website PyTorch is a deep learning framework that puts Python first. deep learning py-tensorboardx 1.8_py27 Website TensorboardX is TensorBoard\u2122 for PyTorch (and Chainer, MXNet, NumPy...) deep learning py-tensorflow 1.12.0_py27 1.4.0_py27 1.5.0_py27 1.5.0_py36 1.6.0_py27 1.6.0_py36 1.7.0_py27 1.8.0_py27 1.9.0_py27 1.9.0_py36 1.12.0_py36 2.0.0_py36 2.1.0_py36 2.4.1_py36 Website TensorFlow\u2122 is an open source software library for numerical computation using data flow graphs. deep learning py-tensorlayer 1.6.3_py27 Website TensorLayer is a Deep Learning (DL) and Reinforcement Learning (RL) library extended from Google TensorFlow. deep learning py-theano 1.0.1_py27 Website Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. deep learning tensorrt 3.0.1 3.0.4 4.0.1.6 5.0.2.6 6.0.1.8 7.0.0.11 7.2.3.4 Website NVIDIA TensorRT\u2122 is a high-performance deep learning inference optimizer and runtime that delivers low latency, high-throughput inference for deep learning applications. deep learning torch 20180202 Website Torch is a scientific computing framework with wide support for machine learning algorithms that puts GPUs first. linear algebra armadillo 8.200.1 Website Armadillo is a high quality linear algebra library (matrix maths) for the C++ language, aiming towards a good balance between speed and ease of use. machine learning py-scikit-learn 0.19.1_py27 0.19.1_py36 0.24.2_py36 Website Scikit-learn is a free software machine learning library for the Python programming language. numerical analysis matlab R2017a R2017b R2018a R2019a R2020a Website MATLAB is a multi-paradigm numerical computing environment and proprietary programming language developed by MathWorks. numerical analysis octave 4.2.1 Website GNU Octave is a high-level language primarily intended for numerical computations. numerical library arpack 3.5.0 3.7.0 Website Collection of Fortran77 subroutines designed to solve large scale eigenvalue problems. numerical library blis 2.1 2.2.4 Website BLIS is a portable software framework for instantiating high-performance BLAS-like dense linear algebra libraries. numerical library fftw 3.3.6 3.3.8 Website The Fastest Fourier Transform in the West (FFTW) is a software library for computing discrete Fourier transforms (DFTs). numerical library glpk 4.63 Website The GLPK (GNU Linear Programming Kit) package is intended for solving large-scale linear programming (LP), mixed integer programming (MIP), and other related problems. numerical library gmp 6.1.2 Website GMP is a free library for arbitrary precision arithmetic, operating on signed integers, rational numbers, and floating-point numbers. numerical library gsl 1.16 2.3 Website The GNU Scientific Library (GSL) is a numerical library for C and C++ programmers. The library provides a wide range of mathematical routines such as random number generators, special functions and least-squares fitting. numerical library harminv 1.4.1 Website harminv is a program designed to solve the problem of harmonic inversion: given a time series consisting of a sum of sinusoids (modes), extract their frequencies and amplitudes. numerical library hypre 2.20.0 Website HYPRE is a library of high performance preconditioners and solvers featuring multigrid methods for the solution of large, sparse linear systems of equations on massively parallel computers. numerical library imkl 2017.u2 2018.u1 2018 2019 Website Intel Math Kernel Library (Intel MKL) is a library of optimized math routines for science, engineering, and financial applications. Core math functions include BLAS, LAPACK, ScaLAPACK, sparse solvers, fast Fourier transforms, and vector math.[3] The routines in MKL are hand-optimized specifically for Intel processors numerical library libflame 2.1 2.2.4 Website libflame is a portable library for dense matrix computations, providing much of the functionality present in LAPACK numerical library libxsmm 1.8.1 Website LIBXSMM is a library for small dense and small sparse matrix-matrix multiplications as well as for deep learning primitives such as small convolutions numerical library metis 5.1.0 Website METIS is a set of serial programs for partitioning graphs, partitioning finite element meshes, and producing fill reducing orderings for sparse matrices. numerical library mpc 1.2.1 Website GNU MPC is a C library for the arithmetic of complex numbers with arbitrarily high precision and correct rounding of the result. numerical library mpfr 3.1.5 4.1.0 Website The MPFR library is a C library for multiple-precision floating-point computations with correct rounding. numerical library mumps 5.1.2 Website A parallel sparse direct solver. numerical library nagcl cll6i26dcl Website The NAG C Library is the largest and most comprehensive collection of mathematical and statistical algorithms for C and C++. numerical library nagfl fll6i26dcl Website The NAG Fortran Library is the largest and most comprehensive collection of numerical and statistical algorithms in Fortran. numerical library nagfs fsl6i26dcl Website The NAG Library for SMP & Multicore is based on, and includes, the full functionality of the NAG Fortran Library. numerical library nagmb MBL6I25DNL Website The NAG C Library is the largest and most comprehensive collection of mathematical and statistical algorithms for C and C++. numerical library openblas 0.3.4 0.2.19 0.3.9 0.3.10 Website OpenBLAS is an optimized BLAS library numerical library parmetis 4.0.3 Website ParMETIS is an MPI -based parallel library that implements a variety of algorithms for partitioning unstructured graphs, meshes, and for computing fill-reducing orderings of sparse matrices. numerical library py-cupy 7.8.0_py36 Website CuPy is an implementation of NumPy-compatible multi-dimensional array on CUDA. numerical library py-gmpy2 2.0.8_py36 Website gmpy2 is a C-coded Python extension module that supports multiple-precision arithmetic. numerical library py-numpy 1.14.3_py27 1.14.3_py36 1.17.2_py36 1.18.1_py36 1.19.2_py36 1.20.3_py39 Website NumPy is the fundamental package for scientific computing with Python. numerical library py-pyublas 2017.1_py27 Website PyUblas provides a seamless glue layer between Numpy and Boost.Ublas for use with Boost.Python. numerical library py-scipy 1.1.0_py27 1.1.0_py36 1.4.1_py36 1.6.3_py39 Website The SciPy library provides many user-friendly and efficient numerical routines such as routines for numerical integration and optimization. numerical library qrupdate 1.1.2 Website qrupdate is a Fortran library for fast updates of QR and Cholesky decompositions. numerical library scalapack 2.0.2 2.1 Website ScaLAPACK is a library of high-performance linear algebra routines for parallel distributed memory machines. numerical library scotch 6.0.4 Website Software package and libraries for sequential and parallel graph partitioning, static mapping and clustering, sequential mesh and hypergraph partitioning, and sequential and parallel sparse matrix block ordering. numerical library superlu 5.2.1 Website SuperLU is a general purpose library for the direct solution of large, sparse, nonsymmetric systems of linear equations. numerical library xblas 1.0.248 Website Extra precise basic linear algebra subroutines. optimization gurobi 7.5.1 8.0.1_py27 8.0.1_py36 9.0.3_py36 Website The Gurobi Optimizer is a commercial optimization solver for mathematical programming. optimization knitro 10.3.0 Website Artelys Knitro is an optimization solver for difficult large-scale nonlinear problems. optimization nlopt 2.6.2 Website NLopt is a free/open-source library for nonlinear optimization. scientific computing py-scipystack 1.0_py27 1.0_py36 Website The SciPy Stack is a collection of open source software for scientific computing in Python. It provides the following packages: numpy, scipy, matplotlib, ipython, jupyter, pandas, sympy and nose. statistics datamash 1.3 Website GNU datamash is a command-line program which performs basic numeric, textual and statistical operations on input textual data files. statistics jags 4.3.0 Website Just another Gibbs sampler (JAGS) is a program for simulation from Bayesian hierarchical models using Markov chain Monte Carlo (MCMC). statistics py-rpy2 2.8.6_py27 2.9.2_py36 Website rpy2 is an interface to R running embedded in a Python process. statistics R 3.5.1 3.4.0 3.6.1 4.0.2 Website R is a free software environment for statistical computing and graphics. statistics rstudio 1.1.423 Website RStudio is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management. statistics sas 9.4 Website SAS is a software suite developed by SAS Institute for advanced analytics, multivariate analyses, business intelligence, data management, and predictive analytics. statistics stata 15 14 16 17 Website Stata is a complete, integrated statistical software package that provides everything you need for data analysis, data management, and graphics. symbolic libmatheval 1.1.11 Website GNU libmatheval is a library (callable from C and Fortran) to parse and evaluate symbolic expressions input as text. symbolic py-sympy 1.1.1_py27 1.1.1_py36 Website SymPy is a Python library for symbolic mathematics.","title":"math"},{"location":"docs/software/list/#physics","text":"Field Module name Version(s) URL Description astronomy heasoft 6.22.1 6.26.1 Website HEAsoft is a Unified Release of the FTOOLS (General and mission-specific tools to manipulate FITS files) and XANADU (High-level, multi-mission tasks for X-ray astronomical spectral, timing, and imaging data analysis) software packages. astronomy py-astropy 4.0.1_py36 Website The Astropy Project is a community effort to develop a common core package for Astronomy in Python and foster an ecosystem of interoperable astronomy packages. astronomy py-lenstools 1.0_py36 Website This python package collects together a suite of widely used analysis tools in Weak Gravitational Lensing. CFD su2 7.0.3 Website SU2: An Open-Source Suite for Multiphysics Simulation and Design climate modeling cdo 1.9.7.1 Website CDO is a collection of command line Operators to manipulate and analyse Climate and NWP model Data. geophysics opensees 2.5.0 Website OpenSees is a software framework for developing applications to simulate the performance of structural and geotechnical systems subjected to earthquakes. geoscience gdal 2.2.1 Website GDAL is a translator library for raster and vector geospatial data formats. geoscience geos 3.6.2 Website GEOS (Geometry Engine - Open Source) is a C++ port of Java Topology Suite (JTS). geoscience proj 4.9.3 Website proj.4 is a standard UNIX filter function which converts geographic longitude and latitude coordinates into cartesian coordinates (and vice versa. geoscience py-opendrift 1.0.3_py27 Website OpenDrift is a software for modeling the trajectories and fate of objects or substances drifting in the ocean, or even in the atmosphere. geoscience py-pyproj 1.9.5.1_py27 1.9.5.1_py36 Website Python interface to PROJ4 library for cartographic transformations. geoscience udunits 2.2.26 Website The UDUNITS package from Unidata is a C-based package for the programatic handling of units of physical quantities. materials science atat 3.36 Website Alloy Theoretic Automated Toolkit: a software toolkit for modeling coupled configurational and vibrational disorder in alloy systems. micromagnetics oommf 1.2b4 Website OOMMF is a set of portable, extensible public domain micromagnetic program and associated tools. particle openmc 0.10.0 Website OpenMC is a Monte Carlo particle transport simulation code focused on neutron criticality calculations. photonics meep 1.3 1.4.3 Website Meep is a free finite-difference time-domain (FDTD) simulation software package to model electromagnetic systems. photonics mpb 1.5 1.6.2 Website MPB is a free software package for computing the band structures, or dispersion relations, and electromagnetic modes of periodic dielectric structures, on both serial and parallel computers. quantum mechanics py-quspin 0.3.5_py36 Website QuSpin is an open-source Python package for exact diagonalization and quantum dynamics of arbitrary boson, fermion and spin many-body systems. quantum mechanics py-qutip 4.5.2_py36 Website QuTiP is open-source software for simulating the dynamics of closed and open quantum systems.","title":"physics"},{"location":"docs/software/list/#system","text":"Field Module name Version(s) URL Description scm gh 1.9.1 Website gh is GitHub on the command line. It brings pull requests, issues, and other GitHub concepts to the terminal next to where you are already working with git and your code. backup restic 0.9.5 0.12.0 Website Fast, secure, efficient backup program. benchmark hp2p 3.2 Website Heavy Peer To Peer: a MPI based benchmark for network diagnostic. benchmark mpibench 20190729 Website Times MPI collectives over a series of message sizes. benchmark mprime 29.4 Website mprime is used by GIMPS, a distributed computing project dedicated to finding new Mersenne prime numbers, and which is commonly used as a stability testing utility. benchmark osu-micro-benchmarks 5.6.1 5.6.3 5.7 Website The OSU MicroBenchmarks carry out a variety of message passing performance tests using MPI . checkpointing dmtcp 2.6.0 Website DMTCP (Distributed MultiThreaded Checkpointing) transparently checkpoints a single-host or distributed computation in user-space -- with no modifications to user code or to the O/S. compression libarchive 3.3.2 3.4.2 Website The libarchive project develops a portable, efficient C library that can read and write streaming archives in a variety of formats. compression libzip 1.5.1 Website libzip is a C library for reading, creating, and modifying zip archives. compression lz4 1.8.0 Website LZ4 is lossless compression algorithm. compression lzo 2.10 Website LZO is a portable lossless data compression library written in ANSI C. compression mpibzip2 0.6 Website MPIBZIP2 is a parallel implementation of the bzip2 block-sorting file compressor that uses MPI and achieves significant speedup on cluster machines. compression p7zip 16.02 Website p7zip is a Linux port of 7zip, a file archiver with high compression ratio. compression pbzip2 1.1.12 Website PBZIP2 is a parallel implementation of the bzip2 block-sorting file compressor that uses pthreads and achieves near-linear speedup on SMP machines. compression pigz 2.4 Website A parallel implementation of gzip for modern multi-processor, multi-core machines. compression szip 2.1.1 Website Szip compression software, providing lossless compression of scientific data, is an implementation of the extended-Rice lossless compression algorithm. compression xz 5.2.3 Website XZ Utils is free general-purpose data compression software with a high compression ratio. compression zlib 1.2.11 Website zlib is designed to be a free, general-purpose, legally unencumbered -- that is, not covered by any patents -- lossless data-compression library for use on virtually any computer hardware and operating system. containers libnvidia-container 1.0.0rc2 Website libnvidia-container is a library and a simple CLI utility to automatically configure GNU/Linux containers leveraging NVIDIA hardware. containers proot 5.1.0 Website PRoot is a user-space implementation of chroot, mount --bind, and binfmt_misc. database bdb 6.2.32 Website Berkeley DB (BDB) is a software library intended to provide a high-performance embedded database for key/value data. database mariadb 10.2.11 Website MariaDB is a community-developed fork of the MySQL relational database management system intended to remain free under the GNU GPL. database postgresql 10.5 Website PostgreSQL is a powerful, open source object-relational database system with a strong focus on reliability, feature robustness, and performance. database sqlite 3.18.0 Website SQLite is a self-contained, high-reliability, embedded, full-featured, public-domain, SQL database engine. document management pandoc 2.7.3 Website Pandoc is a universal document converter. document processing ghostscript 9.53.2 Website Ghostscript is an interpreter for the PostScript language and PDF files. document processing lyx 2.3.2 Website LyX is a document processor. document processing poppler 0.47.0 Website Poppler is a PDF rendering library. document processing texinfo 6.6 Website Texinfo is the official documentation format of the GNU project. document processing texlive 2019 Website TeX Live is an easy way to get up and running with the TeX document production system. file management duc 1.4.4 Website Duc is a collection of tools for indexing, inspecting and visualizing disk usage. file management exa 0.8.0 Website exa is a replacement for ls written in Rust. file management fpart 0.9.3 Website fpart sorts files and packs them into partitions. file management ncdu 1.15.1 Website Ncdu is a disk usage analyzer with an ncurses interface. file management py-pcircle 0.17_py27 Website pcircle contains a suite of file system tools developed at OLCF to take advantage of highly scalable parallel file system such as Lustre. file management rmlint 2.8.0 Website rmlint finds space waste and other broken things on your filesystem and offers to remove it. file transfer aria2 1.35.0 Website aria2 is a lightweight multi-protocol & multi-source command-line download utility. file transfer aspera-cli 3.9.6 Website The IBM Aspera Command-Line Interface (the Aspera CLI) is a collection of Aspera tools for performing high-speed, secure data transfers from the command line. file transfer aws-cli 2.0.50 Website This package provides a unified command line interface to Amazon Web Services. file transfer gsutil 4.31 Website gsutil is a Python application that lets you access Cloud Storage from the command line. file transfer lftp 4.8.1 Website LFTP is a sophisticated file transfer program supporting a number of network protocols (ftp, http, sftp, fish, torrent). file transfer mpifileutils 0.10.1 Website mpiFileUtils is a suite of MPI -based tools to manage large datasets, which may vary from large directory trees to large files. file transfer py-globus-cli 1.2.0 1.9.0_py27 1.9.0_py36 Website A command line wrapper over the Globus SDK for Python. file transfer rclone 1.39 1.43.1 1.49.5 1.55.1 Website Rclone is a command line program to sync files and directories to and from: Google Drive, Amazon S3, Dropbox, Google Cloud Storage, Amazon Drive, Microsoft One Drive, Hubic, Backblaze B2, Yandex Disk, or the local filesystem. framework mono 5.12.0.301 5.20.1.19 Website Mono is an open source implementation of Microsoft's .NET Framework based on the ECMA standards for C# and the Common Language Runtime. language tcltk 8.6.6 Website Tcl (Tool Command Language) is a dynamic programming language, suitable for web and desktop applications, networking, administration, testing. Tk is a graphical user interface toolkit. libs apr 1.6.3 Website The Apache Portable Runtime is a supporting library for the Apache web server. It provides a set of APIs that map to the underlying operating system. libs apr-util 1.6.1 Website The Apache Portable Runtime is a supporting library for the Apache web server. It provides a set of APIs that map to the underlying operating system. libs atk 2.24.0 Website ATK is the Accessibility Toolkit. It provides a set of generic interfaces allowing accessibility technologies such as screen readers to interact with a graphical user interface. libs benchmark 1.2.0 Website A microbenchmark support library libs cairo 1.14.10 Website Cairo is a 2D graphics library with support for multiple output devices. libs cups 2.2.4 Website CUPS is the standards-based, open source printing system. libs dbus 1.10.22 Website D-Bus is a message bus system, a simple way for applications to talk to one another. libs enchant 1.6.1 2.2.3 Website Enchant is a library (and command-line program) that wraps a number of different spelling libraries and programs with a consistent interface. libs fltk 1.3.4 Website FLTK (pronounced 'fulltick') is a cross-platform C++ GUI toolkit. libs fontconfig 2.12.4 Website Fontconfig is a library for configuring and customizing font access. libs freeglut 3.0.0 Website FreeGLUT is a free-software/open-source alternative to the OpenGL Utility Toolkit (GLUT) library. libs freetype 2.8 2.9.1 Website FreeType is a software font engine that is designed to be small, efficient, highly customizable, and portable while capable of producing high-quality output (glyph images). libs gc 7.6.0 Website The Boehm-Demers-Weiser conservative garbage collector can be used as a garbage collecting replacement for C malloc or C++ new. libs gconf 2.9.91 Website GConf is a system for storing application preferences. libs gdk-pixbuf 2.36.8 Website The GdkPixbuf library provides facilities for loading images in a variety of file formats. libs gflags 2.2.1 Website The gflags package contains a C++ library that implements commandline flags processing. libs giflib 5.1.4 Website GIFLIB is a package of portable tools and library routines for working with GIF images. libs glib 2.52.3 Website The GLib library provides core non-graphical functionality such as high level data types, Unicode manipulation, and an object and type system to C programs. libs glog 0.3.5 Website C++ implementation of the Google logging module. libs gnutls 3.5.9 Website GnuTLS is a secure communications library implementing the SSL, TLS and DTLS protocols and technologies around them. libs gobject-introspection 1.52.1 Website GObject introspection is a middleware layer between C libraries (using GObject) and language bindings. libs googletest 1.8.0 Website Google Test is Google's C++ test framework. libs gtk+ 2.24.30 3.22.18 Website GTK+, or the GIMP Toolkit, is a multi-platform toolkit for creating graphical user interfaces. libs harfbuzz 1.4.8 Website HarfBuzz is an OpenType text shaping engine. libs hunspell 1.6.2 Website Hunspell is a spell checker. libs hyphen 2.8.8 Website Hyphen is a hyphenation library to use converted TeX hyphenation patterns. libs icu 59.1 Website ICU is a set of C/C++ and Java libraries providing Unicode and Globalization support for software applications. libs json-glib 1.4.4 Website JSON-GLib is a library providing serialization and deserialization support for the JavaScript Object Notation (JSON) format described by RFC 4627. libs libaio 0.3.111 Website libaio provides the Linux-native API for async I/O . libs libepoxy 1.4.1 Website Epoxy is a library for handling OpenGL function pointer management for you. libs libexif 0.6.21 Website A library for parsing, editing, and saving EXIF data. libs libffi 3.2.1 Website libffi is a portable Foreign Function Interface library. libs libgcrypt 1.8.2 Website Libgcrypt is a general purpose cryptographic library originally based on code from GnuPG. libs libgd 2.2.5 Website GD is an open source code library for the dynamic creation of images by programmers. libs libgdiplus 5.6 Website C-based implementation of the GDI+ API libs libgpg-error 1.27 Website Libgpg-error is a small library that originally defined common error values for all GnuPG components. libs libidl 0.8.14 Website The libIDL package contains libraries for Interface Definition Language files. This is a specification for defining portable interfaces. libs libjpeg-turbo 1.5.1 Website libjpeg-turbo is a JPEG image codec that uses SIMD instructions (MMX, SSE2, AVX2, NEON, AltiVec) to accelerate baseline JPEG compression and decompression on x86, x86-64, ARM, and PowerPC systems libs libmng 2.0.3 Website THE reference library for reading, displaying, writing and examining Multiple-Image Network Graphics. MNG is the animation extension to the popular PNG image-format. libs libpng 1.2.57 1.6.29 Website libpng is the official PNG reference library. It supports almost all PNG features, is extensible, and has been extensively tested for over 20 years. libs libproxy 0.4.15 Website libproxy is a library that provides automatic proxy configuration management. libs libressl 2.5.3 3.2.1 Website LibreSSL is a version of the TLS/crypto stack forked from OpenSSL in 2014, with goals of modernizing the codebase, improving security, and applying best practice development processes. libs libseccomp 2.3.3 Website The libseccomp library provides an easy to use, platform independent, interface to the Linux Kernel's syscall filtering mechanism.. libs libsodium 1.0.18 Website Sodium is a modern, easy-to-use software library for encryption, decryption, signatures, password hashing and more. libs libsoup 2.61.2 Website libsoup is an HTTP client/server library for GNOME. libs libtasn1 4.13 Website Libtasn1 is the ASN.1 library used by GnuTLS, p11-kit and some other packages. libs libtiff 4.0.8 Website libtiff provides support for the Tag Image File Format (TIFF), a widely used format for storing image data. libs libunistring 0.9.7 Website Libunistring provides functions for manipulating Unicode strings and for manipulating C strings according to the Unicode standard. libs libuuid 1.0.3 Website Portable uuid C library. libs libuv 1.38.1 Website libuv is a multi-platform support library with a focus on asynchronous I/O . libs libwebp 0.6.1 Website WebP is a modern image format that provides superior lossless and lossy compression for images on the web. libs libxkbcommon 0.9.1 Website libxkbcommon is a keyboard keymap compiler and support library which processes a reduced subset of keymaps as defined by the XKB (X Keyboard Extension) specification. libs libxml2 2.9.4 Website Libxml2 is a XML C parser and toolkit. libs libxslt 1.1.32 Website Libxslt is the XSLT C library developed for the GNOME project. XSLT itself is a an XML language to define transformation for XML. libs mesa 17.1.6 Website Mesa is an open-source implementation of the OpenGL, Vulkan and other specifications. libs ncurses 6.0 Website The ncurses (new curses) library is a free software emulation of curses in System V Release 4.0 (SVr4), and more. libs nettle 3.3 Website Nettle is a cryptographic library that is designed to fit easily in more or less any context. libs openjpeg 2.3.1 Website OpenJPEG is an open-source JPEG 2000 codec written in C language. libs orbit 2.14.19 Website ORBit2 is a CORBA 2.4-compliant Object Request Broker (ORB) featuring mature C, C++ and Python bindings. libs pango 1.40.10 Website Pango is a library for laying out and rendering of text, with an emphasis on internationalization. libs pcre 8.40 Website The PCRE library is a set of functions that implement regular expression pattern matching using the same syntax and semantics as Perl 5. libs pcre2 10.35 Website The PCRE22 library is a set of functions that implement regular expression pattern matching using the same syntax and semantics as Perl 5. libs popt 1.16 Website Library for parsing command line options. libs py-lmdb 0.93 Website Universal Python binding for the LMDB 'Lightning' Database. libs py-mako 1.0.7_py27 1.0.7_py36 Website Mako is a template library written in Python. It provides a familiar, non-XML syntax which compiles into Python modules for maximum performance. libs py-pygobject 3.32.2_py36 Website PyGObject is a Python package which provides bindings for GObject based libraries such as GTK, GStreamer, WebKitGTK, GLib, GIO and many more. libs py-pyopengl 3.1.5_py39 Website Standard OpenGL bindings for Python. libs py-pyqt5 5.9.1_py36 Website PyQt5 is a comprehensive set of Python bindings for Qt v5. libs readline 7.0 Website The GNU Readline library provides a set of functions for use by applications that allow users to edit command lines as they are typed in. libs serf 1.3.9 Website The serf library is a high performance C-based HTTP client library built upon the Apache Portable Runtime (APR) library. libs snappy 1.1.7 Website A fast compressor/decompressor. libs talloc 2.1.14 Website talloc is a hierarchical, reference counted memory pool system with destructors. libs utf8proc 2.4.0 Website iutf8proc is a small, clean C library that provides Unicode normalization, case-folding, and other operations for data in the UTF-8 encoding. libs wxwidgets 3.0.4 Website wxWidgets is a C++ library that lets developers create applications for Windows, macOS, Linux and other platforms with a single code base. media ffmpeg 4.0 4.2.1 Website FFmpeg is the leading multimedia framework, able to decode, encode, transcode, mux, demux, stream, filter and play pretty much anything that humans and machines have created. media libsndfile 1.0.28 Website Libsndfile is a C library for reading and writing files containing sampled sound (such as MS Windows WAV and the Apple/SGI AIFF format) through one standard library interface. performance likwid 4.3.2 Website Likwid is a simple toolsuite of command line applications for performance oriented programmers. resource monitoring nvtop 1.1.0 Website Nvtop stands for NVidia TOP, a (h)top like task monitor for NVIDIA GPUs. scm git 2.12.2 Website Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. scm git-lfs 2.4.0 Website Git Large File Storage (LFS) replaces large files such as audio samples, videos, datasets, and graphics with text pointers inside Git, while storing the file contents on a remote server. scm libgit2 1.1.0 Website libgit2 is a portable, pure C implementation of the Git core methods provided as a re-entrant linkable library with a solid API scm mercurial 4.5.3 Website Mercurial is a free, distributed source control management tool. scm py-dvc 0.91.1_py36 Website Data Version Control or DVC is an open-source tool for data science and machine learning projects. scm subversion 1.9.7 1.12.2 Website Subversion is an open source version control system. tools clinfo 2.2.18.04.06 Website clinfo is a simple command-line application that enumerates all possible (known) properties of the OpenCL platform and devices available on the system. tools curl 7.54.0 Website curl is an open source command line tool and library for transferring data with URL syntax. tools depot_tools 20200731 Website Tools for working with Chromium development. tools expat 2.2.3 Website Expat is a stream-oriented XML parser library written in C. tools graphicsmagick 1.3.26 Website GraphicsMagick is the swiss army knife of image processing. tools imagemagick 7.0.7-2 Website ImageMagick is a free and open-source software suite for displaying, converting, and editing raster image and vector image files. tools leveldb 1.20 Website Symas LMDB is an extraordinarily fast, memory-efficient database we developed for the Symas OpenLDAP Project. tools lmdb 0.9.21 Website Symas LMDB is an extraordinarily fast, memory-efficient database we developed for the Symas OpenLDAP Project. tools motif 2.3.7 Website Motif is the toolkit for the Common Desktop Environment. tools parallel 20180122 20200822 Website GNU parallel is a shell tool for executing jobs in parallel using one or more computers. tools qt 5.9.1 Website QT is a cross-platform application framework that is used for developing application software that can be run on various software and hardware platforms. tools ripgrep 11.0.1 Website ripgrep recursively searches directories for a regex pattern. tools rocksdb 5.7.3 Website A library that provides an embeddable, persistent key-value store for fast storage. tools x11 7.7 Website The X.Org project provides an open source implementation of the X Window System. tools xkeyboard-config 2.21 Website The non-arch keyboard configuration database for X Window.","title":"system"},{"location":"docs/software/list/#viz","text":"Field Module name Version(s) URL Description data ncview 2.1.7 Website Ncview is a visual browser for netCDF format files. gis panoply 4.10.8 Website Panoply plots geo-referenced and other arrays from netCDF, HDF, GRIB, and other datasets. graphs graphviz 2.40.1 2.44.1 Website Graphviz is open source graph visualization software. imaging py-pillow 5.1.0_py27 5.1.0_py36 7.0.0_py36 8.2.0_py39 Website Pillow is a friendly PIL (Python Imaging Library) fork. imaging py-pillow-simd 7.0.0.post3_py36 Website Pillow-SIMD is an optimized version of Pillow molecular visualization pymol 1.8.6.2 Website PyMOL is a Python-enhanced molecular graphics tool. plotting gnuplot 5.2.0 Website Gnuplot is a portable command-line driven graphing utility for Linux, OS /2, MS Windows, OSX, VMS, and many other platforms. plotting grace 5.1.25 Website Grace is a WYSIWYG tool to make two-dimensional plots of numerical data. plotting py-basemap 1.1.0_py27 1.1.0_py36 Website The matplotlib basemap toolkit is a library for plotting 2D data on maps in Python. plotting py-matplotlib 2.2.2_py27 2.1.2_py27 2.1.2_py36 2.2.2_py36 3.1.1_py36 3.2.1_py36 3.4.2_py39 Website Matplotlib is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. plotting py-plotly 2.4.1_py27 Website Plotly's Python graphing library makes interactive, publication-quality graphs online. remote display virtualgl 2.5.2 Website VirtualGL is an open source toolkit that gives any Unix or Linux remote display software the ability to run OpenGL applications with full 3D hardware acceleration.","title":"viz"},{"location":"docs/software/modules/","text":"Environment modules # Software is provided on Sherlock under the form of loadable environment modules . Software is only accessible via modules The use of a module system means that most software is not accessible by default and has to be loaded using the module command. This mechanism allows us to provide multiple versions of the same software concurrently, and gives users the possibility to easily switch between software versions. Sherlock uses Lmod to manage software installations. The modules system helps setting up the user's shell environment to give access to applications, and make running and compiling software easier. It also allows us to provide multiple versions of the same software, that would otherwise conflict with each other, and abstract things from the OS sometimes rigid versions and dependencies. When you first log into Sherlock, you'll be presented with a default, bare bone environment with minimal software available. The module system is used to manage the user environment and to activate software packages on demand. In order to use software installed on Sherlock, you must first load the corresponding software module. When you load a module, the system will set or modify your user environment variables to enable access to the software package provided by that module. For instance, the $PATH environment variable might be updated so that appropriate executables for that package can be used. Module categories # Modules on Sherlock are organized by scientific field, in distinct categories. This is to limit the information overload that can result when displaying the full list of available modules. Given the large diversity of the Sherlock user population, all users are not be interested in the same kind of software, and high-energy physicists may not want to see their screens cluttered with the latest bioinformatics packages. Module categories You will first have to load a category module before getting access to individual modules. The math and devel categories are loaded by default, and modules in those categories can be loaded directly For instance, to be able to load the gromacs module, you'll first need to load the chemistry module. This can be done in a single command, by specifying first the category, then the actual application module name: $ module load chemistry gromacs The math and devel categories, which are loaded by default, provide direct access to compilers, languages, and MPI and numerical libraries. For a complete list of software odule categories, please refer to the list of available software Searching for a module To know how to access a module, you can use the module spider <module_name> command. It will search through all the installed modules, even if they're masked, and display instructions to load them. See the Examples section for details. Module usage # The most common module commands are outlined in the following table. module commands may be shortened with the ml alias, with slightly different semantics. Module names auto-completion The module command supports auto-completion, so you can just start typing the name of a module, and press Tab to let the shell automatically complete the module name and/or version. Module command Short version Description module avail ml av List available software 1 module spider gromacs ml spider gromacs Search for particular software module keyword blas ml key blas Search for blas in module names and descriptions module whatis gcc ml whatis gcc Display information about the gcc module module help gcc ml help gcc Display module specific help module load gcc ml gcc Load a module to use the associated software module load gsl/2.3 ml gsl/2.3 Load specific version of a module module unload gcc ml -gcc Unload a module module swap gcc icc ml -gcc icc Swap a module (unload gcc and replace it with icc ) module purge ml purge Remove all modules 2 module save foo ml save foo Save the state of all loaded modules in a collection named foo module restore foo ml restore foo Restore the state of saved modules from the foo collection Additional module sub-commands are documented in the module help command. For complete reference, please refer to the official Lmod documentation . Module properties # Multiple versions When multiple versions of the same module exist, module will load the one marked as Default (D) . For the sake of reproducibility, we recommend always specifying the module version you want to load, as defaults may evolve over time. To quickly see some of the modules characteristics, module avail will display colored property attributes next to the module names. The main module properties are: S : Module is sticky, requires --force to unload or purge L : Indicate currently loaded module D : Default module that will be loaded when multiple versions are available r : Restricted access, typically software under license. Contact us for details g : GPU -accelerated software, will only run on GPU nodes m : Software supports parallel execution using MPI Searching for modules # You can search through all the available modules for either: a module name (if you already know it), using module spider any string within modules names and descriptions, using module keyword For instance, if you want to know how to load the gromacs module, you can do: $ module spider gromacs If you don't know the module name, or want to list all the modules that contain a specific string of characters in their name or description, you can use module keyword . For instance, the following command will list all the modules providing a BLAS library: $ module keyword blas Examples # Listing # To list all the modules that can be loaded, you can do: $ ml av -- math -- numerical libraries, statistics, deep-learning, computer science --- R/3.4.0 gsl/1.16 openblas/0.2.19 cudnn/5.1 ( g ) gsl/2.3 ( D ) py-scipystack/1.0_py27 ( D ) cudnn/6.0 ( g,D ) imkl/2017.u2 py-scipystack/1.0_py36 fftw/3.3.6 matlab/R2017a ( r ) ------------------ devel -- compilers, MPI, languages, libs ------------------- boost/1.64.0 icc/2017.u2 python/2.7.13 ( D ) cmake/3.8.1 ifort/2017.u2 python/3.6.1 cuda/8.0.61 ( g ) impi/2017.u2 ( m ) scons/2.5.1_py27 ( D ) eigen/3.3.3 java/1.8.0_131 scons/2.5.1_py36 gcc/6.3.0 ( D ) julia/0.5.1 sqlite/3.18.0 gcc/7.1.0 llvm/4.0.0 tbb/2017.u2 h5utils/1.12.1 nccl/1.3.4 ( g ) tcltk/8.6.6 hdf5/1.10.0p1 openmpi/2.0.2 ( m ) -------------- categories -- load to make more modules available -------------- biology devel ( S,L ) physics system chemistry math ( S,L ) staging viz Where: S: Module is Sticky, requires --force to unload or purge r: Restricted access g: GPU support L: Module is loaded m: MPI support D: Default Module Use \"module spider\" to find all possible modules. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\" . Searching # To search for a specific string in modules names and descriptions, you can run: $ module keyword numpy --------------------------------------------------------------------------- The following modules match your search criteria: \"numpy\" --------------------------------------------------------------------------- py-scipystack: py-scipystack/1.0_py27, py-scipystack/1.0_py36 The SciPy Stack is a collection of open source software for scientific computing in Python. It provides the following packages: numpy, scipy, matplotlib, ipython, jupyter, pandas, sympy and nose. --------------------------------------------------------------------------- [ ... ] $ ml key compiler --------------------------------------------------------------------------- The following modules match your search criteria: \"compiler\" --------------------------------------------------------------------------- cmake: cmake/3.8.1 CMake is an extensible, open-source system that manages the build process in an operating system and in a compiler-independent manner. gcc: gcc/6.3.0, gcc/7.1.0 The GNU Compiler Collection includes front ends for C, C++, Fortran, Java, and Go, as well as libraries for these languages ( libstdc++, libgcj,... ) . icc: icc/2017.u2 Intel C++ Compiler, also known as icc or icl, is a group of C and C++ compilers from Intel ifort: ifort/2017.u2 Intel Fortran Compiler, also known as ifort, is a group of Fortran compilers from Intel llvm: llvm/4.0.0 The LLVM Project is a collection of modular and reusable compiler and toolchain technologies. Clang is an LLVM native C/C++/Objective-C compiler, --------------------------------------------------------------------------- To get information about a specific module, especially how to load it, the following command can be used: $ module spider gromacs ------------------------------------------------------------------------------- gromacs: gromacs/2016.3 ------------------------------------------------------------------------------- Description: GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. Properties: GPU support MPI support You will need to load all module ( s ) on any one of the lines below before the \"gromacs/2016.3\" module is available to load. chemistry Loading # Loading a category module allows to get access to field-specific software: $ ml chemistry $ ml av ------------- chemistry -- quantum chemistry, molecular dynamics -------------- gromacs/2016.3 ( g,m ) vasp/5.4.1 ( g,r,m ) -- math -- numerical libraries, statistics, deep-learning, computer science --- R/3.4.0 gsl/1.16 openblas/0.2.19 cudnn/5.1 ( g ) gsl/2.3 ( D ) py-scipystack/1.0_py27 ( D ) cudnn/6.0 ( g,D ) imkl/2017.u2 py-scipystack/1.0_py36 fftw/3.3.6 matlab/R2017a ( r ) ------------------ devel -- compilers, MPI, languages, libs ------------------- boost/1.64.0 icc/2017.u2 python/2.7.13 ( D ) cmake/3.8.1 ifort/2017.u2 python/3.6.1 cuda/8.0.61 ( g ) impi/2017.u2 ( m ) scons/2.5.1_py27 ( D ) eigen/3.3.3 java/1.8.0_131 scons/2.5.1_py36 gcc/6.3.0 ( D ) julia/0.5.1 sqlite/3.18.0 gcc/7.1.0 llvm/4.0.0 tbb/2017.u2 h5utils/1.12.1 nccl/1.3.4 ( g ) tcltk/8.6.6 hdf5/1.10.0p1 openmpi/2.0.2 ( m ) -------------- categories -- load to make more modules available -------------- biology devel ( S,L ) physics system chemistry ( L ) math ( S,L ) staging viz [ ... ] Reseting the modules environment # If you want to reset your modules environment as it was when you initially connected to Sherlock, you can use the ml reset command: it will remove all the modules you have loaded, and restore the original state where only the math and devel categories are accessible. If you want to remove all modules from your environment, including the default math and devel modules, you can use ml --force purge . Loading modules in jobs # In order for an application running in a Slurm job to have access to any necessary module-provided software packages, we recommend loading those modules in the job script directly. Since Slurm propagates all user environment variables by default, this is not strictly necessary, as jobs will inherit the modules loaded at submission time. But to make sure things are reproducible and avoid issues, it is preferable to explicitly load the modules in the batch scripts. module load commands should be placed right after #SBATCH directives and before the actual executable calls. For instance: #!/bin/bash #SBATCH ... #SBATCH ... #SBATCH ... ml reset ml load gromacs/2016.3 srun gmx_mpi ... Custom modules # Users are welcome and encouraged to build and install their own software on Sherlock. To that end, and to facilitate usage or sharing of their custom software installations, they can create their own module repositories. See the Software Installation page for more details. Lab-provided software # PI groups and Labs can share their software installations and modules with the whole Sherlock community of users, and let everyone benefit from their tuning efforts and software developments. Those modules are available in the specific labs category, and organized by lab name. For instance, listing the available lab modules can be done with: $ ml labs $ ml av -------------------- labs -- lab-contributed software ---------------------- poldrack To get information about a specific lab module: $ ml show poldrack ---------------------------------------------------------------------------- /share/software/modules/labs/poldrack.lua: ---------------------------------------------------------------------------- prepend_path ( \"MODULEPATH\" , \"/home/groups/russpold/modules\" ) whatis ( \"Name: poldrack\" ) whatis ( \"Version: 1.0\" ) whatis ( \"Category: labs\" ) whatis ( \"URL: https://github.com/poldracklab/lmod_modules\" ) whatis ( \"Description: Software modules contributed by the Poldrack Lab.\" ) And to list the available software modules contributed by the lab: $ ml poldrack $ ml av ------------------------ /home/groups/russpold/modules ------------------------- afni/17.3.03 freesurfer/6.0.1 gsl/2.3 ( D ) anaconda/5.0.0-py36 fsl/5.0.9 pigz/2.4 ants/2.1.0.post710 fsl/5.0.11 ( D ) remora/1.8.2 c3d/1.1.0 git-annex/6.20171109 xft/2.3.2 [ ... ] If a module is not listed here, it might be unavailable in the loaded modules categories, and require loading another category module. Search for not-listed software using the module spider command. \u21a9 The math and devel category modules will not be unloaded with module purge as they are \"sticky\". If a user wants to unload a sticky module, they must specify the --force option. \u21a9","title":"Modules"},{"location":"docs/software/modules/#environment-modules","text":"Software is provided on Sherlock under the form of loadable environment modules . Software is only accessible via modules The use of a module system means that most software is not accessible by default and has to be loaded using the module command. This mechanism allows us to provide multiple versions of the same software concurrently, and gives users the possibility to easily switch between software versions. Sherlock uses Lmod to manage software installations. The modules system helps setting up the user's shell environment to give access to applications, and make running and compiling software easier. It also allows us to provide multiple versions of the same software, that would otherwise conflict with each other, and abstract things from the OS sometimes rigid versions and dependencies. When you first log into Sherlock, you'll be presented with a default, bare bone environment with minimal software available. The module system is used to manage the user environment and to activate software packages on demand. In order to use software installed on Sherlock, you must first load the corresponding software module. When you load a module, the system will set or modify your user environment variables to enable access to the software package provided by that module. For instance, the $PATH environment variable might be updated so that appropriate executables for that package can be used.","title":"Environment modules"},{"location":"docs/software/modules/#module-categories","text":"Modules on Sherlock are organized by scientific field, in distinct categories. This is to limit the information overload that can result when displaying the full list of available modules. Given the large diversity of the Sherlock user population, all users are not be interested in the same kind of software, and high-energy physicists may not want to see their screens cluttered with the latest bioinformatics packages. Module categories You will first have to load a category module before getting access to individual modules. The math and devel categories are loaded by default, and modules in those categories can be loaded directly For instance, to be able to load the gromacs module, you'll first need to load the chemistry module. This can be done in a single command, by specifying first the category, then the actual application module name: $ module load chemistry gromacs The math and devel categories, which are loaded by default, provide direct access to compilers, languages, and MPI and numerical libraries. For a complete list of software odule categories, please refer to the list of available software Searching for a module To know how to access a module, you can use the module spider <module_name> command. It will search through all the installed modules, even if they're masked, and display instructions to load them. See the Examples section for details.","title":"Module categories"},{"location":"docs/software/modules/#module-usage","text":"The most common module commands are outlined in the following table. module commands may be shortened with the ml alias, with slightly different semantics. Module names auto-completion The module command supports auto-completion, so you can just start typing the name of a module, and press Tab to let the shell automatically complete the module name and/or version. Module command Short version Description module avail ml av List available software 1 module spider gromacs ml spider gromacs Search for particular software module keyword blas ml key blas Search for blas in module names and descriptions module whatis gcc ml whatis gcc Display information about the gcc module module help gcc ml help gcc Display module specific help module load gcc ml gcc Load a module to use the associated software module load gsl/2.3 ml gsl/2.3 Load specific version of a module module unload gcc ml -gcc Unload a module module swap gcc icc ml -gcc icc Swap a module (unload gcc and replace it with icc ) module purge ml purge Remove all modules 2 module save foo ml save foo Save the state of all loaded modules in a collection named foo module restore foo ml restore foo Restore the state of saved modules from the foo collection Additional module sub-commands are documented in the module help command. For complete reference, please refer to the official Lmod documentation .","title":"Module usage"},{"location":"docs/software/modules/#module-properties","text":"Multiple versions When multiple versions of the same module exist, module will load the one marked as Default (D) . For the sake of reproducibility, we recommend always specifying the module version you want to load, as defaults may evolve over time. To quickly see some of the modules characteristics, module avail will display colored property attributes next to the module names. The main module properties are: S : Module is sticky, requires --force to unload or purge L : Indicate currently loaded module D : Default module that will be loaded when multiple versions are available r : Restricted access, typically software under license. Contact us for details g : GPU -accelerated software, will only run on GPU nodes m : Software supports parallel execution using MPI","title":"Module properties"},{"location":"docs/software/modules/#searching-for-modules","text":"You can search through all the available modules for either: a module name (if you already know it), using module spider any string within modules names and descriptions, using module keyword For instance, if you want to know how to load the gromacs module, you can do: $ module spider gromacs If you don't know the module name, or want to list all the modules that contain a specific string of characters in their name or description, you can use module keyword . For instance, the following command will list all the modules providing a BLAS library: $ module keyword blas","title":"Searching for modules"},{"location":"docs/software/modules/#examples","text":"","title":"Examples"},{"location":"docs/software/modules/#listing","text":"To list all the modules that can be loaded, you can do: $ ml av -- math -- numerical libraries, statistics, deep-learning, computer science --- R/3.4.0 gsl/1.16 openblas/0.2.19 cudnn/5.1 ( g ) gsl/2.3 ( D ) py-scipystack/1.0_py27 ( D ) cudnn/6.0 ( g,D ) imkl/2017.u2 py-scipystack/1.0_py36 fftw/3.3.6 matlab/R2017a ( r ) ------------------ devel -- compilers, MPI, languages, libs ------------------- boost/1.64.0 icc/2017.u2 python/2.7.13 ( D ) cmake/3.8.1 ifort/2017.u2 python/3.6.1 cuda/8.0.61 ( g ) impi/2017.u2 ( m ) scons/2.5.1_py27 ( D ) eigen/3.3.3 java/1.8.0_131 scons/2.5.1_py36 gcc/6.3.0 ( D ) julia/0.5.1 sqlite/3.18.0 gcc/7.1.0 llvm/4.0.0 tbb/2017.u2 h5utils/1.12.1 nccl/1.3.4 ( g ) tcltk/8.6.6 hdf5/1.10.0p1 openmpi/2.0.2 ( m ) -------------- categories -- load to make more modules available -------------- biology devel ( S,L ) physics system chemistry math ( S,L ) staging viz Where: S: Module is Sticky, requires --force to unload or purge r: Restricted access g: GPU support L: Module is loaded m: MPI support D: Default Module Use \"module spider\" to find all possible modules. Use \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\" .","title":"Listing"},{"location":"docs/software/modules/#searching","text":"To search for a specific string in modules names and descriptions, you can run: $ module keyword numpy --------------------------------------------------------------------------- The following modules match your search criteria: \"numpy\" --------------------------------------------------------------------------- py-scipystack: py-scipystack/1.0_py27, py-scipystack/1.0_py36 The SciPy Stack is a collection of open source software for scientific computing in Python. It provides the following packages: numpy, scipy, matplotlib, ipython, jupyter, pandas, sympy and nose. --------------------------------------------------------------------------- [ ... ] $ ml key compiler --------------------------------------------------------------------------- The following modules match your search criteria: \"compiler\" --------------------------------------------------------------------------- cmake: cmake/3.8.1 CMake is an extensible, open-source system that manages the build process in an operating system and in a compiler-independent manner. gcc: gcc/6.3.0, gcc/7.1.0 The GNU Compiler Collection includes front ends for C, C++, Fortran, Java, and Go, as well as libraries for these languages ( libstdc++, libgcj,... ) . icc: icc/2017.u2 Intel C++ Compiler, also known as icc or icl, is a group of C and C++ compilers from Intel ifort: ifort/2017.u2 Intel Fortran Compiler, also known as ifort, is a group of Fortran compilers from Intel llvm: llvm/4.0.0 The LLVM Project is a collection of modular and reusable compiler and toolchain technologies. Clang is an LLVM native C/C++/Objective-C compiler, --------------------------------------------------------------------------- To get information about a specific module, especially how to load it, the following command can be used: $ module spider gromacs ------------------------------------------------------------------------------- gromacs: gromacs/2016.3 ------------------------------------------------------------------------------- Description: GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. Properties: GPU support MPI support You will need to load all module ( s ) on any one of the lines below before the \"gromacs/2016.3\" module is available to load. chemistry","title":"Searching"},{"location":"docs/software/modules/#loading","text":"Loading a category module allows to get access to field-specific software: $ ml chemistry $ ml av ------------- chemistry -- quantum chemistry, molecular dynamics -------------- gromacs/2016.3 ( g,m ) vasp/5.4.1 ( g,r,m ) -- math -- numerical libraries, statistics, deep-learning, computer science --- R/3.4.0 gsl/1.16 openblas/0.2.19 cudnn/5.1 ( g ) gsl/2.3 ( D ) py-scipystack/1.0_py27 ( D ) cudnn/6.0 ( g,D ) imkl/2017.u2 py-scipystack/1.0_py36 fftw/3.3.6 matlab/R2017a ( r ) ------------------ devel -- compilers, MPI, languages, libs ------------------- boost/1.64.0 icc/2017.u2 python/2.7.13 ( D ) cmake/3.8.1 ifort/2017.u2 python/3.6.1 cuda/8.0.61 ( g ) impi/2017.u2 ( m ) scons/2.5.1_py27 ( D ) eigen/3.3.3 java/1.8.0_131 scons/2.5.1_py36 gcc/6.3.0 ( D ) julia/0.5.1 sqlite/3.18.0 gcc/7.1.0 llvm/4.0.0 tbb/2017.u2 h5utils/1.12.1 nccl/1.3.4 ( g ) tcltk/8.6.6 hdf5/1.10.0p1 openmpi/2.0.2 ( m ) -------------- categories -- load to make more modules available -------------- biology devel ( S,L ) physics system chemistry ( L ) math ( S,L ) staging viz [ ... ]","title":"Loading"},{"location":"docs/software/modules/#reseting-the-modules-environment","text":"If you want to reset your modules environment as it was when you initially connected to Sherlock, you can use the ml reset command: it will remove all the modules you have loaded, and restore the original state where only the math and devel categories are accessible. If you want to remove all modules from your environment, including the default math and devel modules, you can use ml --force purge .","title":"Reseting the modules environment"},{"location":"docs/software/modules/#loading-modules-in-jobs","text":"In order for an application running in a Slurm job to have access to any necessary module-provided software packages, we recommend loading those modules in the job script directly. Since Slurm propagates all user environment variables by default, this is not strictly necessary, as jobs will inherit the modules loaded at submission time. But to make sure things are reproducible and avoid issues, it is preferable to explicitly load the modules in the batch scripts. module load commands should be placed right after #SBATCH directives and before the actual executable calls. For instance: #!/bin/bash #SBATCH ... #SBATCH ... #SBATCH ... ml reset ml load gromacs/2016.3 srun gmx_mpi ...","title":"Loading modules in jobs"},{"location":"docs/software/modules/#custom-modules","text":"Users are welcome and encouraged to build and install their own software on Sherlock. To that end, and to facilitate usage or sharing of their custom software installations, they can create their own module repositories. See the Software Installation page for more details.","title":"Custom modules"},{"location":"docs/software/modules/#lab-provided-software","text":"PI groups and Labs can share their software installations and modules with the whole Sherlock community of users, and let everyone benefit from their tuning efforts and software developments. Those modules are available in the specific labs category, and organized by lab name. For instance, listing the available lab modules can be done with: $ ml labs $ ml av -------------------- labs -- lab-contributed software ---------------------- poldrack To get information about a specific lab module: $ ml show poldrack ---------------------------------------------------------------------------- /share/software/modules/labs/poldrack.lua: ---------------------------------------------------------------------------- prepend_path ( \"MODULEPATH\" , \"/home/groups/russpold/modules\" ) whatis ( \"Name: poldrack\" ) whatis ( \"Version: 1.0\" ) whatis ( \"Category: labs\" ) whatis ( \"URL: https://github.com/poldracklab/lmod_modules\" ) whatis ( \"Description: Software modules contributed by the Poldrack Lab.\" ) And to list the available software modules contributed by the lab: $ ml poldrack $ ml av ------------------------ /home/groups/russpold/modules ------------------------- afni/17.3.03 freesurfer/6.0.1 gsl/2.3 ( D ) anaconda/5.0.0-py36 fsl/5.0.9 pigz/2.4 ants/2.1.0.post710 fsl/5.0.11 ( D ) remora/1.8.2 c3d/1.1.0 git-annex/6.20171109 xft/2.3.2 [ ... ] If a module is not listed here, it might be unavailable in the loaded modules categories, and require loading another category module. Search for not-listed software using the module spider command. \u21a9 The math and devel category modules will not be unloaded with module purge as they are \"sticky\". If a user wants to unload a sticky module, they must specify the --force option. \u21a9","title":"Lab-provided software"},{"location":"docs/software/overview/","text":"Available software # A set of supported software installations is provided for use on Sherlock. This software is made available through a Software Modules system. For the complete list of available software, please refer to the Software List page . Licensed software can be used on Sherlock, under certain conditions. Feel free to contact us for more details or if you have questions. For more information about purchasing software licenses, you can contact the Stanford Software Licensing office . Installation requests # Installation requests The SRCC team installs, for general use, a set of libraries, tools and software applications that are commonly used across many research groups. However, our staff resources are quite limited and don't allow us to build nor maintain custom software applications that may be requested by or be of use to a small number of users. We strongly encourage users to build custom and field- or domain-specific software themselves, and install it in their own personal or group shared directories . That way, they can share the software installations with the rest of the users in their group, if necessary. Users may even maintain and publish their own local module files to dynamically configure a running environment to use the software. They could share those modules with other users to simplify the use of their own custom software installations. Installing your own software For more information about building your own software on Sherlock, please see the Software Installation page . If the software you need is not in the list of available software , and you have trouble installing it on your own, please contact us with as much details about the package as possible , and we will try to help you install it. If it's a widely used software that could benefit multiple users across different scientific communities, we will consider install it globally as resources permit 1 . Lab-provided software # PI groups and Labs can share their software installations and modules with the whole Sherlock community of users, and let everyone benefit from their tuning efforts and software developments. Lab-provided software is supported and maintained by each lab, and contact information is usually provided in the lab category module . See the Modules page for more information about using software modules on Sherlock. If you're interested in sharing your software installations beyond your own group on Sherlock, please let us know , and we'll get in touch. Software requests, including version upgrades, are fulfilled in the order they are received, and as time permits. We don't have any dedicated team for software installations, and requests are handled along with other duties, typically within two to three weeks of being received. \u21a9","title":"Overview"},{"location":"docs/software/overview/#available-software","text":"A set of supported software installations is provided for use on Sherlock. This software is made available through a Software Modules system. For the complete list of available software, please refer to the Software List page . Licensed software can be used on Sherlock, under certain conditions. Feel free to contact us for more details or if you have questions. For more information about purchasing software licenses, you can contact the Stanford Software Licensing office .","title":"Available software"},{"location":"docs/software/overview/#installation-requests","text":"Installation requests The SRCC team installs, for general use, a set of libraries, tools and software applications that are commonly used across many research groups. However, our staff resources are quite limited and don't allow us to build nor maintain custom software applications that may be requested by or be of use to a small number of users. We strongly encourage users to build custom and field- or domain-specific software themselves, and install it in their own personal or group shared directories . That way, they can share the software installations with the rest of the users in their group, if necessary. Users may even maintain and publish their own local module files to dynamically configure a running environment to use the software. They could share those modules with other users to simplify the use of their own custom software installations. Installing your own software For more information about building your own software on Sherlock, please see the Software Installation page . If the software you need is not in the list of available software , and you have trouble installing it on your own, please contact us with as much details about the package as possible , and we will try to help you install it. If it's a widely used software that could benefit multiple users across different scientific communities, we will consider install it globally as resources permit 1 .","title":"Installation requests"},{"location":"docs/software/overview/#lab-provided-software","text":"PI groups and Labs can share their software installations and modules with the whole Sherlock community of users, and let everyone benefit from their tuning efforts and software developments. Lab-provided software is supported and maintained by each lab, and contact information is usually provided in the lab category module . See the Modules page for more information about using software modules on Sherlock. If you're interested in sharing your software installations beyond your own group on Sherlock, please let us know , and we'll get in touch. Software requests, including version upgrades, are fulfilled in the order they are received, and as time permits. We don't have any dedicated team for software installations, and requests are handled along with other duties, typically within two to three weeks of being received. \u21a9","title":"Lab-provided software"},{"location":"docs/software/using/R/","text":"Introduction # R is a programming language and software environment for statistical computing and graphics. It is similar to the S language and environment developed at Bell Laboratories (formerly AT&T, now Lucent Technologies). R provides a wide variety of statistical and graphical techniques and is highly extensible. More documentation # The following documentation is specifically intended for using R on Sherlock. For more complete documentation about R in general, please see the R documentation . R on Sherlock # R is available on Sherlock and the corresponding module can be loaded with: $ ml R For a list of available versions, you can execute ml spider R at the Sherlock prompt, or refer to the Software list page . Using R # Once your environment is configured ( ie. when the R module is loaded), R can be started by simply typing R at the shell prompt: $ R R version 3 .5.1 ( 2018 -07-02 ) -- \"Feather Spray\" Copyright ( C ) 2018 The R Foundation for Statistical Computing Platform: x86_64-pc-linux-gnu ( 64 -bit ) [ ... ] Type 'demo()' for some demos, 'help()' for on-line help, or 'help.start()' for an HTML browser interface to help. Type 'q()' to quit R. > For a listing of command line options: $ R --help Running a R script # There are several ways to launch an R script on the command line, which will have different ways of presenting the script's output: Method Output Rscript script.R displayed on screen, on stdout R CMD BATCH script.R redirected to a script.Rout file R --no-save < script.R displayed on screen, on stdout Submitting a R job # Here's an example R batch script that can be submitted via sbatch . It runs a simple matrix multiplication example, and demonstrate how to feed R code as a HEREDOC to R directly, so no intermediate R script is necessary: R-test.sbatch #!/usr/bin/bash #SBATCH --time=00:10:00 #SBATCH --mem=10G #SBATCH --output=R-test.log # load the module ml R # run R code R --no-save << EOF set.seed (1) m <- 4000 n <- 4000 A <- matrix (runif (m*n),m,n) system.time (B <- crossprod(A)) EOF You can save this script as R-test.sbatch and submit it to the scheduler with: $ sbatch R-test.sbatch Once the job is done, you should get a R-test.out file in the current directory, with the following contents: R version 3 .5.1 ( 2018 -07-02 ) -- \"Feather Spray\" [ ... ] > set.seed ( 1 ) > m <- 4000 > n <- 4000 > A <- matrix ( runif ( m*n ) ,m,n ) > system.time ( B <- crossprod ( A )) user system elapsed 2 .649 0 .077 2 .726 R packages # R comes with a single package library in $R_HOME/library , which contains the standard and most common packages. This is usually in a system location and is not writable by end-users. To accommodate individual user's requirements, R provides a way for each user to install packages in the location of their choice. The default value for a directory where users can install their own R packages is $HOME/R/x86_64-pc-linux-gnu-library/<R_version> where <R_version> depends on the R version that is used. For instance, if you have the R/3.5.1 module loaded, the default R user library path will be $HOME/R/x86_64-pc-linux-gnu-library/3.5 . This directory doesn't exist by default. The first time a user installs an R package, R will ask if she wants to use the default location and create the directory. Installing packages # To install a R package in your personal environment, the first thing to do is load the R module: $ ml R Then start a R session, and use the install.packages() function at the R prompt. For instance, the following example will install the doParallel package, using the US mirror of the CRAN repository : $ R R version 3 .5.1 ( 2018 -07-02 ) -- \"Feather Spray\" [ ... ] > install.packages ( 'doParallel' , repos = 'http://cran.us.r-project.org' ) It should give the following warning: Warning in install.packages ( \"doParallel\" , repos = \"http://cran.us.r-project.org\" ) : 'lib = \"/share/software/user/open/R/3.5.1/lib64/R/library\"' is not writable Would you like to use a personal library instead? ( yes/No/cancel ) Would you like to create a personal library \u2018~/R/x86_64-pc-linux-gnu-library/3.5\u2019 to install packages into? ( yes/No/cancel ) y Answering y twice will make R create a ~/R/x86_64-pc-linux-gnu-library/3.5 directory and instruct it to install future R packages there. The installation will then proceed: trying URL 'http://cran.us.r-project.org/src/contrib/doParallel_1.0.14.tar.gz' Content type 'application/x-gzip' length 173607 bytes ( 169 KB ) ================================================== downloaded 169 KB * installing *source* package \u2018doParallel\u2019 ... ** package \u2018doParallel\u2019 successfully unpacked and MD5 sums checked ** R ** demo ** inst ** byte-compile and prepare package for lazy loading ** help *** installing help indices ** building package indices ** installing vignettes ** testing if installed package can be loaded * DONE ( doParallel ) The downloaded source packages are in \u2018/tmp/Rtmp0RHrMZ/downloaded_packages\u2019 > and when it's done, you should be able to load the package within R with: > library ( doParallel ) Loading required package : foreach Loading required package : iterators Loading required package : parallel > Package dependencies # Sometimes when installing R packages, other software is needed for the installation and/or compilation. For instance, when trying to install the sf package, you may encounter the following error messages: > install.packages ( \"sf\" ) [ ... ] Configuration failed because libudunits2.so was not found. Try installing : ... [ ... ] configure : error : gdal - config not found or not executable. This is because sf needs a few dependencies, like udunits and gdal in order to compile and install successfully. Fortunately those dependencies are already available as modules on Sherlock. Whenever you see \"not found\" errors, you may want to try searching the modules inventory with module spider : $ module spider udunits ---------------------------------------------------------------------------- udunits: udunits/2.2.26 ---------------------------------------------------------------------------- Description: The UDUNITS package from Unidata is a C-based package for the programatic handling of units of physical quantities. You will need to load all module ( s ) on any one of the lines below before the \"udunits/2.2.26\" module is available to load. physics So for sf , in order to load the dependencies, exit R , load the udunits and gdal modules, and try installing sf again: $ ml load physics udunits gdal $ ml R $ R > install.packages ( \"sf\" ) Sometimes, getting dependencies right is a matter of trial and error. You may have to load R, install packages, search modules, load modules, install packages again and so forth. Fortunately, R packages only need to be installed once, and many R package dependencies are already available as modules on Sherlock, you just need to search for them with module spider and load them. And in case you're stuck, you can of course always send us an email and we'll be happy to assist. Alternative installation path # To install R packages in a different location, you'll need to create that directory, and instruct R to install the packages there: $ mkdir ~/R_libs/ $ R [ ... ] > install.packages ( 'doParallel' , repos = 'http://cran.us.r-project.org' , lib = \"~/R_libs\" ) The installation will proceed normally and the doParallel package will be installed in $HOME/R_libs/ . Specifying the full destination path for each package installation could quickly become tiresome, so to avoid this, you can create a .Renviron file in your $HOME directory, and define your R_libs path there: $ cat << EOF > $HOME/.Renviron R_LIBS=~/R_libs EOF With this, whenever R is started, the $HOME/R_libs/ directory will be added to the list of places R will look for packages, and you won't need to specify this installation path when using install.packages() anymore. Where does R look for packages? To see the directories where R searches for packages and libraries, you can use the following command in R: > .libPaths () Sharing R packages If you'd like to share R packages within your group, you can simply define $R_LIBS to point to a shared directory, such as $GROUP_HOME/R_libs and have each user in the group use the instructions below to define it in their own environment. Setting the repository # When installing a package, R needs to know from which repository the package should be downloaded. If it's not specified, it will prompt for it and display a list of available CRAN mirrors. To avoid setting the CRAN mirror each time you run install.packages you can permanently set the mirror by creating a .Rprofile file in your $HOME directory, which R will execute each time it starts. For instance, adding the following contents to your ~/.Rprofile will make sure that every install.packages() invocation will use the closest CRAN mirror: ## local creates a new, empty environment ## This avoids polluting the global environment with ## the object r local ({ r = getOption ( \"repos\" ) r [ \"CRAN\" ] = \"https://cloud.r-project.org/\" options ( repos = r ) }) Once this is set, you only need to specify the name of the package to install, and R will use the mirror you defined automatically: > install.packages ( \"doParallel\" ) [ ... ] trying URL 'https://cloud.r-project.org/src/contrib/doParallel_1.0.14.tar.gz' Content type 'application/x-gzip' length 173607 bytes ( 169 KB ) ================================================== downloaded 169 KB Installing packages from GitHub # R packages can be directly installed from GitHub using the devtools package. devtools needs to be installed first, with: > install.packages ( \"devtools\" ) And then, you can then install a R package directly from its GitHub repository. For instance, to install dplyr from url_dplyr : > library ( devtools ) > install_github ( \"tidyverse/dplyr\" ) Updating Packages # To upgrade R packages, you can use the update.packages() function within a R session. For instance, to update the doParallel package: > update.packages ( 'doParallel' ) When the package name is omitted, update.pacakges() will try to update all the packages that are installed. Which is the most efficient way to ensure that all the packages in your local R library are up to date. Centrally installed packages can not be updated Note that attempting to update centrally installed packages will fail. You will have to use install.packages() to install your own version of the packages in your $HOME directory instead. Removing packages # To remove a package from your local R library, you can use the remove.packages() function. For instance: > remove.packages ( 'doParallel' ) Examples # Single node # R has a couple of powerful and easy to use tools for parallelizing your R jobs. doParallel is one of them. If the doParallel package is not installed in your environment yet, you can install it in a few easy step . Here is a quick doParallel example that uses one node and 16 cores on Sherlock (more nodes or CPU cores can be requested, as needed). Save the two scripts below in a directory on Sherlock: doParallel_test.R # Example doParallel script if ( ! require ( doParallel )) install.packages ( \"doParallel\" ) library ( doParallel ) # use the environment variable SLURM_NTASKS_PER_NODE to set # the number of cores to use registerDoParallel ( cores = ( Sys.getenv ( \"SLURM_NTASKS_PER_NODE\" ))) # bootstrap iteration example x <- iris [ which ( iris [, 5 ] != \"setosa\" ), c ( 1 , 5 )] iterations <- 10000 # Number of iterations to run # parallel loop # note the '%dopar%' instruction parallel_time <- system.time ({ r <- foreach ( icount ( iterations ), .combine = cbind ) %dopar% { ind <- sample ( 100 , 100 , replace = TRUE ) result1 <- glm ( x [ ind , 2 ] ~ x [ ind , 1 ], family = binomial ( logit )) coefficients ( result1 ) } })[ 3 ] # show the number of parallel workers to be used getDoParWorkers () # execute the function parallel_time doParallel_test.sbatch #!/bin/bash #SBATCH --nodes=1 #SBATCH --ntasks-per-node=16 #SBATCH --output=doParallel_test.log # --ntasks-per-node will be used in doParallel_test.R to specify the number # of cores to use on the machine. # load modules ml R/3.5.1 # execute script Rscript doParallel_test.R And then submit the job with: $ sbatch doParallel_test.sbatch Once the job has completed, the output file should contain something like this: $ cat doParallel_test.out [ 1 ] \"16\" elapsed 3 .551 Bonus points : observe the scalability of the doParallel loop by submitting the same script using a varying number of CPU cores: $ for i in 2 4 8 16 ; do sbatch --out = doP_ ${ i } .out --ntasks-per-node = $i doParallel_test.sbatch done When the jobs are done: $ for i in 2 4 8 16 ; do printf \"%2i cores: %4.1fs\\n\" $i $( tail -n1 doP_ $i .out ) done 2 cores: 13 .6s 4 cores: 7 .8s 8 cores: 4 .9s 16 cores: 3 .6s Multiple nodes # To distribute parallel R tasks on multiple nodes, you can use the Rmpi package, which provides MPI bindings for R. To install the Rmpi package, a module providing MPI library must first be loaded. For instance: $ ml openmpi R $ R > install.packages ( \"Rmpi\" ) Once the package is installed, the following scripts demonstrate a very basic Rmpi example. Rmpi-test.R # Example Rmpi script if ( ! require ( \"Rmpi\" )) install.packages ( \"Rmpi\" ) library ( Rmpi ) # initialize an Rmpi environment ns <- mpi.universe.size () - 1 mpi.spawn.Rslaves ( nslaves = ns , needlog = TRUE ) # send these commands to the slaves mpi.bcast.cmd ( id <- mpi.comm.rank () ) mpi.bcast.cmd ( ns <- mpi.comm.size () ) mpi.bcast.cmd ( host <- mpi.get.processor.name () ) # all slaves execute this command mpi.remote.exec ( paste ( \"I am\" , id , \"of\" , ns , \"running on\" , host )) # close down the Rmpi environment mpi.close.Rslaves ( dellog = FALSE ) mpi.exit () Rmpi-test.sbatch #!/bin/bash #SBATCH --nodes=2 #SBATCH --ntasks=4 #SBATCH --output=Rmpi-test.log ## load modules # openmpi is not loaded by default with R, so it must be loaded explicitely ml R openmpi ## run script # we use '-np 1' since Rmpi does its own task management mpirun -np 1 Rscript Rmpi-test.R You can save those scripts as Rmpi-test.R and Rmpi-test.sbatch and then submit your job with: $ sbatch Rmpi-test.sbatch When the job is done, its output should look like this: $ cat Rmpi-test.log 3 slaves are spawned successfully. 0 failed. master ( rank 0 , comm 1 ) of size 4 is running on: sh-06-33 slave1 ( rank 1 , comm 1 ) of size 4 is running on: sh-06-33 slave2 ( rank 2 , comm 1 ) of size 4 is running on: sh-06-33 slave3 ( rank 3 , comm 1 ) of size 4 is running on: sh-06-34 $slave1 [ 1 ] \"I am 1 of 4 running on sh-06-33\" $slave2 [ 1 ] \"I am 2 of 4 running on sh-06-33\" $slave3 [ 1 ] \"I am 3 of 4 running on sh-06-34\" [ 1 ] 1 [ 1 ] \"Detaching Rmpi. Rmpi cannot be used unless relaunching R.\" GPUs # Here's a quick example that compares running a matrix multiplication on a CPU and on a GPU using R. It requires submitting a job to a GPU node and the gpuR R package. gpuR-test.R # Example gpuR script if ( ! require ( \"gpuR\" )) install.packages ( \"gpuR\" ) library ( gpuR ) print ( \"CPU times\" ) for ( i in seq ( 1 : 7 )) { ORDER = 64 * ( 2 ^ i ) A = matrix ( rnorm ( ORDER ^ 2 ), nrow = ORDER ) B = matrix ( rnorm ( ORDER ^ 2 ), nrow = ORDER ) print ( paste ( i , sprintf ( \"%5.2f\" , system.time ({ C = A %*% B })[ 3 ]))) } print ( \"GPU times\" ) for ( i in seq ( 1 : 7 )) { ORDER = 64 * ( 2 ^ i ) A = matrix ( rnorm ( ORDER ^ 2 ), nrow = ORDER ) B = matrix ( rnorm ( ORDER ^ 2 ), nrow = ORDER ) gpuA = gpuMatrix ( A , type = \"double\" ) gpuB = gpuMatrix ( B , type = \"double\" ) print ( paste ( i , sprintf ( \"%5.2f\" , system.time ({ gpuC = gpuA %*% gpuB })[ 3 ]))) } gpuR-test.sbatch #!/bin/bash #SBATCH --partition gpu #SBATCH --mem 8GB #SBATCH --gres gpu:1 #SBATCH --output=gpuR-test.log ## load modules # cuda is not loaded by default with R, so it must be loaded explicitely ml R cuda Rscript gpuR-test.R After submitting the job with sbatch gpuR-test.sbatch , the output file should contain something like this: [ 1 ] \"CPU times\" [ 1 ] \"1 0.00\" [ 1 ] \"2 0.00\" [ 1 ] \"3 0.02\" [ 1 ] \"4 0.13\" [ 1 ] \"5 0.97\" [ 1 ] \"6 7.56\" [ 1 ] \"7 60.47\" [ 1 ] \"GPU times\" [ 1 ] \"1 0.10\" [ 1 ] \"2 0.04\" [ 1 ] \"3 0.02\" [ 1 ] \"4 0.07\" [ 1 ] \"5 0.39\" [ 1 ] \"6 2.04\" [ 1 ] \"7 11.59\" which shows a decent speedup for running on a GPU for the largest matrix sizes.","title":"R"},{"location":"docs/software/using/R/#introduction","text":"R is a programming language and software environment for statistical computing and graphics. It is similar to the S language and environment developed at Bell Laboratories (formerly AT&T, now Lucent Technologies). R provides a wide variety of statistical and graphical techniques and is highly extensible.","title":"Introduction"},{"location":"docs/software/using/R/#more-documentation","text":"The following documentation is specifically intended for using R on Sherlock. For more complete documentation about R in general, please see the R documentation .","title":"More documentation"},{"location":"docs/software/using/R/#r-on-sherlock","text":"R is available on Sherlock and the corresponding module can be loaded with: $ ml R For a list of available versions, you can execute ml spider R at the Sherlock prompt, or refer to the Software list page .","title":"R on Sherlock"},{"location":"docs/software/using/R/#using-r","text":"Once your environment is configured ( ie. when the R module is loaded), R can be started by simply typing R at the shell prompt: $ R R version 3 .5.1 ( 2018 -07-02 ) -- \"Feather Spray\" Copyright ( C ) 2018 The R Foundation for Statistical Computing Platform: x86_64-pc-linux-gnu ( 64 -bit ) [ ... ] Type 'demo()' for some demos, 'help()' for on-line help, or 'help.start()' for an HTML browser interface to help. Type 'q()' to quit R. > For a listing of command line options: $ R --help","title":"Using R"},{"location":"docs/software/using/R/#running-a-r-script","text":"There are several ways to launch an R script on the command line, which will have different ways of presenting the script's output: Method Output Rscript script.R displayed on screen, on stdout R CMD BATCH script.R redirected to a script.Rout file R --no-save < script.R displayed on screen, on stdout","title":"Running a R script"},{"location":"docs/software/using/R/#submitting-a-r-job","text":"Here's an example R batch script that can be submitted via sbatch . It runs a simple matrix multiplication example, and demonstrate how to feed R code as a HEREDOC to R directly, so no intermediate R script is necessary: R-test.sbatch #!/usr/bin/bash #SBATCH --time=00:10:00 #SBATCH --mem=10G #SBATCH --output=R-test.log # load the module ml R # run R code R --no-save << EOF set.seed (1) m <- 4000 n <- 4000 A <- matrix (runif (m*n),m,n) system.time (B <- crossprod(A)) EOF You can save this script as R-test.sbatch and submit it to the scheduler with: $ sbatch R-test.sbatch Once the job is done, you should get a R-test.out file in the current directory, with the following contents: R version 3 .5.1 ( 2018 -07-02 ) -- \"Feather Spray\" [ ... ] > set.seed ( 1 ) > m <- 4000 > n <- 4000 > A <- matrix ( runif ( m*n ) ,m,n ) > system.time ( B <- crossprod ( A )) user system elapsed 2 .649 0 .077 2 .726","title":"Submitting a R job"},{"location":"docs/software/using/R/#r-packages","text":"R comes with a single package library in $R_HOME/library , which contains the standard and most common packages. This is usually in a system location and is not writable by end-users. To accommodate individual user's requirements, R provides a way for each user to install packages in the location of their choice. The default value for a directory where users can install their own R packages is $HOME/R/x86_64-pc-linux-gnu-library/<R_version> where <R_version> depends on the R version that is used. For instance, if you have the R/3.5.1 module loaded, the default R user library path will be $HOME/R/x86_64-pc-linux-gnu-library/3.5 . This directory doesn't exist by default. The first time a user installs an R package, R will ask if she wants to use the default location and create the directory.","title":"R packages"},{"location":"docs/software/using/R/#installing-packages","text":"To install a R package in your personal environment, the first thing to do is load the R module: $ ml R Then start a R session, and use the install.packages() function at the R prompt. For instance, the following example will install the doParallel package, using the US mirror of the CRAN repository : $ R R version 3 .5.1 ( 2018 -07-02 ) -- \"Feather Spray\" [ ... ] > install.packages ( 'doParallel' , repos = 'http://cran.us.r-project.org' ) It should give the following warning: Warning in install.packages ( \"doParallel\" , repos = \"http://cran.us.r-project.org\" ) : 'lib = \"/share/software/user/open/R/3.5.1/lib64/R/library\"' is not writable Would you like to use a personal library instead? ( yes/No/cancel ) Would you like to create a personal library \u2018~/R/x86_64-pc-linux-gnu-library/3.5\u2019 to install packages into? ( yes/No/cancel ) y Answering y twice will make R create a ~/R/x86_64-pc-linux-gnu-library/3.5 directory and instruct it to install future R packages there. The installation will then proceed: trying URL 'http://cran.us.r-project.org/src/contrib/doParallel_1.0.14.tar.gz' Content type 'application/x-gzip' length 173607 bytes ( 169 KB ) ================================================== downloaded 169 KB * installing *source* package \u2018doParallel\u2019 ... ** package \u2018doParallel\u2019 successfully unpacked and MD5 sums checked ** R ** demo ** inst ** byte-compile and prepare package for lazy loading ** help *** installing help indices ** building package indices ** installing vignettes ** testing if installed package can be loaded * DONE ( doParallel ) The downloaded source packages are in \u2018/tmp/Rtmp0RHrMZ/downloaded_packages\u2019 > and when it's done, you should be able to load the package within R with: > library ( doParallel ) Loading required package : foreach Loading required package : iterators Loading required package : parallel >","title":"Installing packages"},{"location":"docs/software/using/R/#updating-packages","text":"To upgrade R packages, you can use the update.packages() function within a R session. For instance, to update the doParallel package: > update.packages ( 'doParallel' ) When the package name is omitted, update.pacakges() will try to update all the packages that are installed. Which is the most efficient way to ensure that all the packages in your local R library are up to date. Centrally installed packages can not be updated Note that attempting to update centrally installed packages will fail. You will have to use install.packages() to install your own version of the packages in your $HOME directory instead.","title":"Updating Packages"},{"location":"docs/software/using/R/#removing-packages","text":"To remove a package from your local R library, you can use the remove.packages() function. For instance: > remove.packages ( 'doParallel' )","title":"Removing packages"},{"location":"docs/software/using/R/#examples","text":"","title":"Examples"},{"location":"docs/software/using/R/#single-node","text":"R has a couple of powerful and easy to use tools for parallelizing your R jobs. doParallel is one of them. If the doParallel package is not installed in your environment yet, you can install it in a few easy step . Here is a quick doParallel example that uses one node and 16 cores on Sherlock (more nodes or CPU cores can be requested, as needed). Save the two scripts below in a directory on Sherlock: doParallel_test.R # Example doParallel script if ( ! require ( doParallel )) install.packages ( \"doParallel\" ) library ( doParallel ) # use the environment variable SLURM_NTASKS_PER_NODE to set # the number of cores to use registerDoParallel ( cores = ( Sys.getenv ( \"SLURM_NTASKS_PER_NODE\" ))) # bootstrap iteration example x <- iris [ which ( iris [, 5 ] != \"setosa\" ), c ( 1 , 5 )] iterations <- 10000 # Number of iterations to run # parallel loop # note the '%dopar%' instruction parallel_time <- system.time ({ r <- foreach ( icount ( iterations ), .combine = cbind ) %dopar% { ind <- sample ( 100 , 100 , replace = TRUE ) result1 <- glm ( x [ ind , 2 ] ~ x [ ind , 1 ], family = binomial ( logit )) coefficients ( result1 ) } })[ 3 ] # show the number of parallel workers to be used getDoParWorkers () # execute the function parallel_time doParallel_test.sbatch #!/bin/bash #SBATCH --nodes=1 #SBATCH --ntasks-per-node=16 #SBATCH --output=doParallel_test.log # --ntasks-per-node will be used in doParallel_test.R to specify the number # of cores to use on the machine. # load modules ml R/3.5.1 # execute script Rscript doParallel_test.R And then submit the job with: $ sbatch doParallel_test.sbatch Once the job has completed, the output file should contain something like this: $ cat doParallel_test.out [ 1 ] \"16\" elapsed 3 .551 Bonus points : observe the scalability of the doParallel loop by submitting the same script using a varying number of CPU cores: $ for i in 2 4 8 16 ; do sbatch --out = doP_ ${ i } .out --ntasks-per-node = $i doParallel_test.sbatch done When the jobs are done: $ for i in 2 4 8 16 ; do printf \"%2i cores: %4.1fs\\n\" $i $( tail -n1 doP_ $i .out ) done 2 cores: 13 .6s 4 cores: 7 .8s 8 cores: 4 .9s 16 cores: 3 .6s","title":"Single node"},{"location":"docs/software/using/R/#multiple-nodes","text":"To distribute parallel R tasks on multiple nodes, you can use the Rmpi package, which provides MPI bindings for R. To install the Rmpi package, a module providing MPI library must first be loaded. For instance: $ ml openmpi R $ R > install.packages ( \"Rmpi\" ) Once the package is installed, the following scripts demonstrate a very basic Rmpi example. Rmpi-test.R # Example Rmpi script if ( ! require ( \"Rmpi\" )) install.packages ( \"Rmpi\" ) library ( Rmpi ) # initialize an Rmpi environment ns <- mpi.universe.size () - 1 mpi.spawn.Rslaves ( nslaves = ns , needlog = TRUE ) # send these commands to the slaves mpi.bcast.cmd ( id <- mpi.comm.rank () ) mpi.bcast.cmd ( ns <- mpi.comm.size () ) mpi.bcast.cmd ( host <- mpi.get.processor.name () ) # all slaves execute this command mpi.remote.exec ( paste ( \"I am\" , id , \"of\" , ns , \"running on\" , host )) # close down the Rmpi environment mpi.close.Rslaves ( dellog = FALSE ) mpi.exit () Rmpi-test.sbatch #!/bin/bash #SBATCH --nodes=2 #SBATCH --ntasks=4 #SBATCH --output=Rmpi-test.log ## load modules # openmpi is not loaded by default with R, so it must be loaded explicitely ml R openmpi ## run script # we use '-np 1' since Rmpi does its own task management mpirun -np 1 Rscript Rmpi-test.R You can save those scripts as Rmpi-test.R and Rmpi-test.sbatch and then submit your job with: $ sbatch Rmpi-test.sbatch When the job is done, its output should look like this: $ cat Rmpi-test.log 3 slaves are spawned successfully. 0 failed. master ( rank 0 , comm 1 ) of size 4 is running on: sh-06-33 slave1 ( rank 1 , comm 1 ) of size 4 is running on: sh-06-33 slave2 ( rank 2 , comm 1 ) of size 4 is running on: sh-06-33 slave3 ( rank 3 , comm 1 ) of size 4 is running on: sh-06-34 $slave1 [ 1 ] \"I am 1 of 4 running on sh-06-33\" $slave2 [ 1 ] \"I am 2 of 4 running on sh-06-33\" $slave3 [ 1 ] \"I am 3 of 4 running on sh-06-34\" [ 1 ] 1 [ 1 ] \"Detaching Rmpi. Rmpi cannot be used unless relaunching R.\"","title":"Multiple nodes"},{"location":"docs/software/using/R/#gpus","text":"Here's a quick example that compares running a matrix multiplication on a CPU and on a GPU using R. It requires submitting a job to a GPU node and the gpuR R package. gpuR-test.R # Example gpuR script if ( ! require ( \"gpuR\" )) install.packages ( \"gpuR\" ) library ( gpuR ) print ( \"CPU times\" ) for ( i in seq ( 1 : 7 )) { ORDER = 64 * ( 2 ^ i ) A = matrix ( rnorm ( ORDER ^ 2 ), nrow = ORDER ) B = matrix ( rnorm ( ORDER ^ 2 ), nrow = ORDER ) print ( paste ( i , sprintf ( \"%5.2f\" , system.time ({ C = A %*% B })[ 3 ]))) } print ( \"GPU times\" ) for ( i in seq ( 1 : 7 )) { ORDER = 64 * ( 2 ^ i ) A = matrix ( rnorm ( ORDER ^ 2 ), nrow = ORDER ) B = matrix ( rnorm ( ORDER ^ 2 ), nrow = ORDER ) gpuA = gpuMatrix ( A , type = \"double\" ) gpuB = gpuMatrix ( B , type = \"double\" ) print ( paste ( i , sprintf ( \"%5.2f\" , system.time ({ gpuC = gpuA %*% gpuB })[ 3 ]))) } gpuR-test.sbatch #!/bin/bash #SBATCH --partition gpu #SBATCH --mem 8GB #SBATCH --gres gpu:1 #SBATCH --output=gpuR-test.log ## load modules # cuda is not loaded by default with R, so it must be loaded explicitely ml R cuda Rscript gpuR-test.R After submitting the job with sbatch gpuR-test.sbatch , the output file should contain something like this: [ 1 ] \"CPU times\" [ 1 ] \"1 0.00\" [ 1 ] \"2 0.00\" [ 1 ] \"3 0.02\" [ 1 ] \"4 0.13\" [ 1 ] \"5 0.97\" [ 1 ] \"6 7.56\" [ 1 ] \"7 60.47\" [ 1 ] \"GPU times\" [ 1 ] \"1 0.10\" [ 1 ] \"2 0.04\" [ 1 ] \"3 0.02\" [ 1 ] \"4 0.07\" [ 1 ] \"5 0.39\" [ 1 ] \"6 2.04\" [ 1 ] \"7 11.59\" which shows a decent speedup for running on a GPU for the largest matrix sizes.","title":"GPUs"},{"location":"docs/software/using/julia/","text":"Introduction # Julia is a high-level general-purpose dynamic programming language that was originally designed to address the needs of high-performance numerical analysis and computational science, without the typical need of separate compilation to be fast, also usable for client and server web use, low-level systems programming or as a specification language. Julia aims to create an unprecedented combination of ease-of-use, power, and efficiency in a single language. More documentation # The following documentation is specifically intended for using Julia on Sherlock. For more complete documentation about Julia in general, please see the Julia documentation . Julia on Sherlock # Julia is available on Sherlock and the corresponding module can be loaded with: $ ml julia For a list of available versions, you can execute ml spider julia at the Sherlock prompt, or refer to the Software list page . Using Julia # Once your environment is configured ( ie. when the julia module is loaded), julia can be started by simply typing julia at the shell prompt: $ julia _ _ _ _ ( _ ) _ | Documentation: https://docs.julialang.org ( _ ) | ( _ ) ( _ ) | _ _ _ | | _ __ _ | Type \"?\" for help, \"]?\" for Pkg help. | | | | | | | / _ ` | | | | | _ | | | | ( _ | | | Version 1 .0.0 ( 2018 -08-08 ) _/ | \\_ _ '_|_|_|\\__' _ | | Official https://julialang.org/ release | __/ | julia> For a listing of command line options: $ julia --help julia [ switches ] -- [ programfile ] [ args... ] -v, --version Display version information -h, --help Print this message -J, --sysimage <file> Start up with the given system image file -H, --home <dir> Set location of ` julia ` executable --startup-file ={ yes | no } Load ` ~/.julia/config/startup.jl ` --handle-signals ={ yes | no } Enable or disable Julia ' s default signal handlers --sysimage-native-code ={ yes | no } Use native code from system image if available --compiled-modules ={ yes | no } Enable or disable incremental precompilation of modules -e, --eval <expr> Evaluate <expr> -E, --print <expr> Evaluate <expr> and display the result -L, --load <file> Load <file> immediately on all processors -p, --procs { N | auto } Integer value N launches N additional local worker processes \"auto\" launches as many workers as the number of local CPU threads ( logical cores ) --machine-file <file> Run processes on hosts listed in <file> -i Interactive mode ; REPL runs and isinteractive () is true -q, --quiet Quiet startup: no banner, suppress REPL warnings Running a Julia script # A Julia program is easy to run on the command line outside of its interactive mode. Here is an example where we create a simple Hello World program and launch it with Julia $ echo 'println(\"hello world\")' > helloworld.jl That script can now simply be executed by calling julia <script_name> : $ julia helloworld.jl hello world Submitting a Julia job # Here's an example Julia sbatch script that can be submitted via sbatch : julia_test.sbatch #!/bin/bash #SBATCH --time=00:10:00 #SBATCH --mem=4G #SBATCH --output=julia_test.log # load the module ml julia # run the Julia application srun julia helloworld.jl You can save this script as julia_test.sbatch and submit it to the scheduler with: $ sbatch julia_test.sbatch Once the job is done, you should get a julia_test.log file in the current directory, with the following contents: $ cat julia_test.log hello world Julia packages # Julia provides an ever-growing list of packages that can be used to install add-on functionality to your Julia code. Installing packages with Julia is very simple. Julia includes a package module in its base installation that handles installing, updating, and removing packages. First import the Pkg module: julia> import Pkg julia> Pkg.status () Status ` ~/.julia/environments/v1.0/Project.toml ` Julia packages only need to be installed once You only need to install Julia packages once on Sherlock. Since fielsystems are shared, packages installed on one node will immediately be available on all nodes on the cluster. Installing packages # You can first check the status of packages installed on Julia using the status function of the Pkg module: julia> Pkg.status () No packages installed. You can then add packages using the add function of the Pkg module: julia> Pkg.add ( \"Distributions\" ) INFO: Cloning cache of Distributions from git://github.com/JuliaStats/Distributions.jl.git INFO: Cloning cache of NumericExtensions from git://github.com/lindahua/NumericExtensions.jl.git INFO: Cloning cache of Stats from git://github.com/JuliaStats/Stats.jl.git INFO: Installing Distributions v0.2.7 INFO: Installing NumericExtensions v0.2.17 INFO: Installing Stats v0.2.6 INFO: REQUIRE updated. Using the status function again, you can see that the package and its dependencies have been installed: julia> Pkg.status () Required packages: - Distributions 0 .2.7 Additional packages: - NumericExtensions 0 .2.17 - Stats 0 .2.6 Updating Packages # The update function of the Pkg module can update all packages installed: julia> Pkg.update () INFO: Updating METADATA... INFO: Computing changes... INFO: Upgrading Distributions: v0.2.8 = > v0.2.10 INFO: Upgrading Stats: v0.2.7 = > v0.2.8 Removing packages # The remove function of the Pkg module can remove any packages installed as well: julia> Pkg.rm ( \"Distributions\" ) INFO: Removing Distributions v0.2.7 INFO: Removing Stats v0.2.6 INFO: Removing NumericExtensions v0.2.17 INFO: REQUIRE updated. julia> Pkg.status () Required packages: - SHA 0 .3.2 julia> Pkg.rm ( \"SHA\" ) INFO: Removing SHA v0.3.2 INFO: REQUIRE updated. julia> Pkg.status () No packages installed. Working with packages in Julia is simple! Examples # Julia can natively spawn parallel workers across multiple compute nodes, without using MPI . There are two main modes of operation: ClusterManager: in this mode, you can spawn workers from within the Julia interpreter, and each worker will actually submit jobs to the scheduler, executing instructions within those jobs. using the --machine-file option: here, you submit a SLURM job and run the Julia interpreter in parallel mode within the job's resources. The second mode is easier to use, and more convenient, since you have all your resources available and ready to use when the job starts. In mode 1, you'll need to wait for jobs to be dispatched and executed inside Julia. Here is a quick example on how to use the --machine-file option on Sherlock. Given following Julia script ( julia_parallel_test.jl ) that will print a line with the process id and the node it's executing on, in parallel: @everywhere println ( \"process: $( myid ( ) ) on host $( gethostname ( ) )\" ) You can submit the following job: julia_test.sbatch #!/bin/bash #SBATCH --nodes 2 #SBATCH --ntasks-per-node 4 #SBATCH --time 5:0 ml julia julia --machine-file < ( srun hostname -s ) ./julia_parallel_test.jl Save as julia_test.sbatch , and then: $ sbatch julia_test.sbatch It will: Request 2 nodes, 4 tasks per node (8 tasks total) load the julia module Run Julia in parallel with a machine file that is automatically generated, listing the nodes that are assigned to your job. It should output something like this in your job's output file: process: 1 on host sh-06-33.int From worker 2 : process: 2 on host sh-06-33.int From worker 3 : process: 3 on host sh-06-34.int From worker 5 : process: 5 on host sh-06-33.int From worker 4 : process: 4 on host sh-06-33.int From worker 6 : process: 6 on host sh-06-33.int From worker 8 : process: 8 on host sh-06-34.int From worker 9 : process: 9 on host sh-06-34.int From worker 7 : process: 7 on host sh-06-34.int","title":"Julia"},{"location":"docs/software/using/julia/#introduction","text":"Julia is a high-level general-purpose dynamic programming language that was originally designed to address the needs of high-performance numerical analysis and computational science, without the typical need of separate compilation to be fast, also usable for client and server web use, low-level systems programming or as a specification language. Julia aims to create an unprecedented combination of ease-of-use, power, and efficiency in a single language.","title":"Introduction"},{"location":"docs/software/using/julia/#more-documentation","text":"The following documentation is specifically intended for using Julia on Sherlock. For more complete documentation about Julia in general, please see the Julia documentation .","title":"More documentation"},{"location":"docs/software/using/julia/#julia-on-sherlock","text":"Julia is available on Sherlock and the corresponding module can be loaded with: $ ml julia For a list of available versions, you can execute ml spider julia at the Sherlock prompt, or refer to the Software list page .","title":"Julia on Sherlock"},{"location":"docs/software/using/julia/#using-julia","text":"Once your environment is configured ( ie. when the julia module is loaded), julia can be started by simply typing julia at the shell prompt: $ julia _ _ _ _ ( _ ) _ | Documentation: https://docs.julialang.org ( _ ) | ( _ ) ( _ ) | _ _ _ | | _ __ _ | Type \"?\" for help, \"]?\" for Pkg help. | | | | | | | / _ ` | | | | | _ | | | | ( _ | | | Version 1 .0.0 ( 2018 -08-08 ) _/ | \\_ _ '_|_|_|\\__' _ | | Official https://julialang.org/ release | __/ | julia> For a listing of command line options: $ julia --help julia [ switches ] -- [ programfile ] [ args... ] -v, --version Display version information -h, --help Print this message -J, --sysimage <file> Start up with the given system image file -H, --home <dir> Set location of ` julia ` executable --startup-file ={ yes | no } Load ` ~/.julia/config/startup.jl ` --handle-signals ={ yes | no } Enable or disable Julia ' s default signal handlers --sysimage-native-code ={ yes | no } Use native code from system image if available --compiled-modules ={ yes | no } Enable or disable incremental precompilation of modules -e, --eval <expr> Evaluate <expr> -E, --print <expr> Evaluate <expr> and display the result -L, --load <file> Load <file> immediately on all processors -p, --procs { N | auto } Integer value N launches N additional local worker processes \"auto\" launches as many workers as the number of local CPU threads ( logical cores ) --machine-file <file> Run processes on hosts listed in <file> -i Interactive mode ; REPL runs and isinteractive () is true -q, --quiet Quiet startup: no banner, suppress REPL warnings","title":"Using Julia"},{"location":"docs/software/using/julia/#running-a-julia-script","text":"A Julia program is easy to run on the command line outside of its interactive mode. Here is an example where we create a simple Hello World program and launch it with Julia $ echo 'println(\"hello world\")' > helloworld.jl That script can now simply be executed by calling julia <script_name> : $ julia helloworld.jl hello world","title":"Running a Julia script"},{"location":"docs/software/using/julia/#submitting-a-julia-job","text":"Here's an example Julia sbatch script that can be submitted via sbatch : julia_test.sbatch #!/bin/bash #SBATCH --time=00:10:00 #SBATCH --mem=4G #SBATCH --output=julia_test.log # load the module ml julia # run the Julia application srun julia helloworld.jl You can save this script as julia_test.sbatch and submit it to the scheduler with: $ sbatch julia_test.sbatch Once the job is done, you should get a julia_test.log file in the current directory, with the following contents: $ cat julia_test.log hello world","title":"Submitting a Julia job"},{"location":"docs/software/using/julia/#julia-packages","text":"Julia provides an ever-growing list of packages that can be used to install add-on functionality to your Julia code. Installing packages with Julia is very simple. Julia includes a package module in its base installation that handles installing, updating, and removing packages. First import the Pkg module: julia> import Pkg julia> Pkg.status () Status ` ~/.julia/environments/v1.0/Project.toml ` Julia packages only need to be installed once You only need to install Julia packages once on Sherlock. Since fielsystems are shared, packages installed on one node will immediately be available on all nodes on the cluster.","title":"Julia packages"},{"location":"docs/software/using/julia/#installing-packages","text":"You can first check the status of packages installed on Julia using the status function of the Pkg module: julia> Pkg.status () No packages installed. You can then add packages using the add function of the Pkg module: julia> Pkg.add ( \"Distributions\" ) INFO: Cloning cache of Distributions from git://github.com/JuliaStats/Distributions.jl.git INFO: Cloning cache of NumericExtensions from git://github.com/lindahua/NumericExtensions.jl.git INFO: Cloning cache of Stats from git://github.com/JuliaStats/Stats.jl.git INFO: Installing Distributions v0.2.7 INFO: Installing NumericExtensions v0.2.17 INFO: Installing Stats v0.2.6 INFO: REQUIRE updated. Using the status function again, you can see that the package and its dependencies have been installed: julia> Pkg.status () Required packages: - Distributions 0 .2.7 Additional packages: - NumericExtensions 0 .2.17 - Stats 0 .2.6","title":"Installing packages"},{"location":"docs/software/using/julia/#updating-packages","text":"The update function of the Pkg module can update all packages installed: julia> Pkg.update () INFO: Updating METADATA... INFO: Computing changes... INFO: Upgrading Distributions: v0.2.8 = > v0.2.10 INFO: Upgrading Stats: v0.2.7 = > v0.2.8","title":"Updating Packages"},{"location":"docs/software/using/julia/#removing-packages","text":"The remove function of the Pkg module can remove any packages installed as well: julia> Pkg.rm ( \"Distributions\" ) INFO: Removing Distributions v0.2.7 INFO: Removing Stats v0.2.6 INFO: Removing NumericExtensions v0.2.17 INFO: REQUIRE updated. julia> Pkg.status () Required packages: - SHA 0 .3.2 julia> Pkg.rm ( \"SHA\" ) INFO: Removing SHA v0.3.2 INFO: REQUIRE updated. julia> Pkg.status () No packages installed. Working with packages in Julia is simple!","title":"Removing packages"},{"location":"docs/software/using/julia/#examples","text":"Julia can natively spawn parallel workers across multiple compute nodes, without using MPI . There are two main modes of operation: ClusterManager: in this mode, you can spawn workers from within the Julia interpreter, and each worker will actually submit jobs to the scheduler, executing instructions within those jobs. using the --machine-file option: here, you submit a SLURM job and run the Julia interpreter in parallel mode within the job's resources. The second mode is easier to use, and more convenient, since you have all your resources available and ready to use when the job starts. In mode 1, you'll need to wait for jobs to be dispatched and executed inside Julia. Here is a quick example on how to use the --machine-file option on Sherlock. Given following Julia script ( julia_parallel_test.jl ) that will print a line with the process id and the node it's executing on, in parallel: @everywhere println ( \"process: $( myid ( ) ) on host $( gethostname ( ) )\" ) You can submit the following job: julia_test.sbatch #!/bin/bash #SBATCH --nodes 2 #SBATCH --ntasks-per-node 4 #SBATCH --time 5:0 ml julia julia --machine-file < ( srun hostname -s ) ./julia_parallel_test.jl Save as julia_test.sbatch , and then: $ sbatch julia_test.sbatch It will: Request 2 nodes, 4 tasks per node (8 tasks total) load the julia module Run Julia in parallel with a machine file that is automatically generated, listing the nodes that are assigned to your job. It should output something like this in your job's output file: process: 1 on host sh-06-33.int From worker 2 : process: 2 on host sh-06-33.int From worker 3 : process: 3 on host sh-06-34.int From worker 5 : process: 5 on host sh-06-33.int From worker 4 : process: 4 on host sh-06-33.int From worker 6 : process: 6 on host sh-06-33.int From worker 8 : process: 8 on host sh-06-34.int From worker 9 : process: 9 on host sh-06-34.int From worker 7 : process: 7 on host sh-06-34.int","title":"Examples"},{"location":"docs/software/using/mariadb/","text":"Introduction # MariaDB is a community-developed fork of the MySQL relational database management system. It is completely compatible with MySQL and could be use as a drop-in replacement in the vast majority of cases. More documentation # The following documentation specifically intended for using MariaDB on Sherlock. For more complete documentation about MariaDB in general, please see the MariaDB documentation . MariaDB on Sherlock # We don't provide any centralized database service on Sherlock, but we provide a centralized installation of MariaDB, and each user is welcome to start their own instance of the database server to fit their jobs' needs. The overall process to run an instance of MariaDB on Sherlock would look like this: configure and initialize your environment so you can start a database instance under your user account, start the database server, run SQL queries from the same node (via a local socket), or from other nodes and/or jobs (via the network). Single-node access # In that example, the database server and client will run within the same job, on the same compute node . Preparation # You first need to let MariaDB know where to store its database, where to log things, and how to allow connections from clients. The commands below only need to be executed once. For this, you'll need to create a .my.cnf file in your home directory. Assuming you'll want to store your database files in a db/ directory in your $SCRATCH folder, you can run the following commands: $ export DB_DIR = $SCRATCH /db $ mkdir $DB_DIR $ cat << EOF > ~/.my.cnf [mysqld] datadir=$DB_DIR socket=$DB_DIR/mariadb.sock user=$USER symbolic-links=0 skip-networking [mysqld_safe] log-error=$DB_DIR/mariadbd.log pid-file=$DB_DIR/mariadbd.pid [mysql] socket=$DB_DIR/mariadb.sock EOF .my.cnf doesn't support environment variables Please note that if you edit your ~/.my.cnf file directly in a file editor, without using the HEREDOC syntax above, environment variables such as $DB_DIR , $HOME or $USER won't work: you will need to specify absolute paths explicitely, such as /scratch/users/kilian/db/mariadbd.log . If you use the HEREDOC syntax, you can verify that the resulting .my.cnf file does actually contain full paths, and not environment variables anymore. Once you have the .my.cnf file in place, you need to initialize your database with some internal data that MariaDB needs. In the same terminal, run the following commands: $ ml system mariadb $ $MARIADB_DIR /scripts/mysql_install_db --basedir = $MARIADB_DIR --datadir = $DB_DIR Start the server # You can now start the MariaDB server. For this, first get an allocation on a compute node, note the hostname of the compute node your job has been allocated, load the mariadb module, and then run the mysqld_safe process: $ srun --pty bash $ echo $SLURM_JOB_NODELIST sh-01-01 $ ml system mariadb $ mysqld_safe 180705 18 :14:27 mysqld_safe Logging to '/home/users/kilian/db/mysqld.log' . 180705 18 :14:28 mysqld_safe Starting mysqld daemon with databases from /home/users/kilian/db/ The mysqld_safe will be blocking, meaning it will not give the prompt back for as long as the MariaDB server runs. If it does return on its own, it probably means that something went wrong, and you'll find more information about the issue in the $DB_DIR/mysqld.log file you defined in ~/.my.cnf . Run queries # You're now ready to run queries against that MariaDB instance, from the same node your job is running on. From another terminal on Sherlock, connect to your job's compute node (here, it's sh-01-01 , as shown above), load the mariadb module, and then run the mysql command: it will open the MariaDB shell, ready to run your SQL queries: $ ssh sh-01-01 $ ml system mariadb $ mysql Welcome to the MariaDB monitor. Commands end with ; or \\g . Your MariaDB connection id is 8 Server version: 10 .2.11-MariaDB Source distribution Copyright ( c ) 2000 , 2017 , Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [( none )] > Once you're done with your MariaDB instance, you can just terminate your job, and all the processes will be terminated automatically. Multi-node access # In case you need to run a more persistent instance of MariaDB, you can for instance submit a dedicated job to run the server, make it accessible over the network, and run queries from other jobs and/or nodes. Enable network access # The preparation steps are pretty similar to the single-node case , except the MariaDB server instance will be accessed over the network rather than through a local socket. Network access must be secured When running an networked instance of MariaDB, please keep in mind that any user on Sherlock will be able to connect to the TCP ports that mysqld runs on, and that proper configuration must be done to prevent unauthrozied access. Like in the single-node case, you need to create a ~/.my.cnf file, but without the skip-networking directive. $ export DB_DIR = $SCRATCH /db $ mkdir $DB_DIR $ cat << EOF > ~/.my.cnf [mysqld] datadir=$DB_DIR socket=$DB_DIR/mariadb.sock user=$USER symbolic-links=0 [mysqld_safe] log-error=$DB_DIR/mariadbd.log pid-file=$DB_DIR/mariadbd.pid [mysql] socket=$DB_DIR/mariadb.sock EOF And then initiate the database: $ ml system mariadb $ $MARIADB_DIR /scripts/mysql_install_db --basedir = $MARIADB_DIR --datadir = $DB_DIR Secure access # We will now set a password for the MariaDB root user to a random string, just for the purpose of preventing unauthorized access, since we won't need it for anything. We will actually create a MariaDB user with all privileges on the databases, that will be able to connect to this instance from any node. This user will need a real password, though. So please make sure to replace the my-secure-password string below by the actual password of your choice. Choose a proper password This password will only be used to access this specific instance of MariaDB. Note that anybody knowing that password will be allowed to connect to your MariaDB instances and modify data in the tables. do NOT literally use my-secure-password do NOT use your SUNet ID password Once you've chosen your password, you can start the mysqld process on a compute node, like before: $ srun --pty bash $ echo $SLURM_JOB_NODELIST sh-01-01 $ ml system mariadb $ mysqld_safe And then, from another terminal, run the following commands to secure access to your MariaDB database. $ ssh sh-01-01 $ mysql -u root << EOF UPDATE mysql.user SET Password=PASSWORD(RAND()) WHERE User='root'; DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1'); DELETE FROM mysql.user WHERE User=''; DELETE FROM mysql.db WHERE Db='test' OR Db='test_%'; GRANT ALL PRIVILEGES ON *.* TO '$USER'@'%' IDENTIFIED BY 'my-secure-password' WITH GRANT OPTION; FLUSH PRIVILEGES; EOF Once you've done that, you're ready to terminate that interactive job, and start a dedicated MariaDB server job. Start MariaDB in a job # You can use the following mariadb.sbatch job as a template: #!/bin/bash #SBATCH --job-name=mariadb #SBATCH --time=8:0:0 #SBATCH --dependency=singleton ml system mariadb mysqld_safe and submit it with: $ sbatch mariadb.sbatch Concurrent instances will lead to data corruption An important thing to keep in mind is that having multiple instances of a MariaDB server running at the same time, using the same database files, will certainly lead to catastrophic situations and the corruption of those files. To prevent this from happening, the --dependency=singleton job submission option will make sure that only one instance of that job (based on its name and user) will run at any given time. Connect to the running instance # Now, from any node on Sherlock, whether from a login node, an interactive job, or a batch job, using the mysql CLI or any application binding in any language, you should be able to connect to your running MariaDB instance, First, identify the node your job is running on with squeue : $ squeue -u $USER -n mariadb JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 21383445 normal mariadb kilian R 0 :07 1 sh-01-02 and then, point your MariaDB client to that node: $ ml system mariadb $ mysql -h sh-01-02 -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g . Your MariaDB connection id is 15 Server version: 10 .2.11-MariaDB Source distribution Copyright ( c ) 2000 , 2017 , Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [( none )] > That's it! You can now run SQL queries from anywhere on Sherlock to your own MariaDB instance. Persistent DB instances # SQL data is persistent All the data you import in your SQL databases will be persistent across jobs. Meaning that you can run a PostgreSQL server job for the day, import data in its database, stop the job, and resubmit the same PostgreSQL server job the next day: all your data will still be there as long as the location you've chosen for your database (the $DB_DIR defined in the Preparation steps) is on a persistent storage location . If you need database access for more than the maximum runtime of a job, you can use the instructions provided to define self-resubmitting recurring jobs and submit long-running database instances.","title":"MariaDB"},{"location":"docs/software/using/mariadb/#introduction","text":"MariaDB is a community-developed fork of the MySQL relational database management system. It is completely compatible with MySQL and could be use as a drop-in replacement in the vast majority of cases.","title":"Introduction"},{"location":"docs/software/using/mariadb/#more-documentation","text":"The following documentation specifically intended for using MariaDB on Sherlock. For more complete documentation about MariaDB in general, please see the MariaDB documentation .","title":"More documentation"},{"location":"docs/software/using/mariadb/#mariadb-on-sherlock","text":"We don't provide any centralized database service on Sherlock, but we provide a centralized installation of MariaDB, and each user is welcome to start their own instance of the database server to fit their jobs' needs. The overall process to run an instance of MariaDB on Sherlock would look like this: configure and initialize your environment so you can start a database instance under your user account, start the database server, run SQL queries from the same node (via a local socket), or from other nodes and/or jobs (via the network).","title":"MariaDB on Sherlock"},{"location":"docs/software/using/mariadb/#single-node-access","text":"In that example, the database server and client will run within the same job, on the same compute node .","title":"Single-node access"},{"location":"docs/software/using/mariadb/#preparation","text":"You first need to let MariaDB know where to store its database, where to log things, and how to allow connections from clients. The commands below only need to be executed once. For this, you'll need to create a .my.cnf file in your home directory. Assuming you'll want to store your database files in a db/ directory in your $SCRATCH folder, you can run the following commands: $ export DB_DIR = $SCRATCH /db $ mkdir $DB_DIR $ cat << EOF > ~/.my.cnf [mysqld] datadir=$DB_DIR socket=$DB_DIR/mariadb.sock user=$USER symbolic-links=0 skip-networking [mysqld_safe] log-error=$DB_DIR/mariadbd.log pid-file=$DB_DIR/mariadbd.pid [mysql] socket=$DB_DIR/mariadb.sock EOF .my.cnf doesn't support environment variables Please note that if you edit your ~/.my.cnf file directly in a file editor, without using the HEREDOC syntax above, environment variables such as $DB_DIR , $HOME or $USER won't work: you will need to specify absolute paths explicitely, such as /scratch/users/kilian/db/mariadbd.log . If you use the HEREDOC syntax, you can verify that the resulting .my.cnf file does actually contain full paths, and not environment variables anymore. Once you have the .my.cnf file in place, you need to initialize your database with some internal data that MariaDB needs. In the same terminal, run the following commands: $ ml system mariadb $ $MARIADB_DIR /scripts/mysql_install_db --basedir = $MARIADB_DIR --datadir = $DB_DIR","title":"Preparation"},{"location":"docs/software/using/mariadb/#start-the-server","text":"You can now start the MariaDB server. For this, first get an allocation on a compute node, note the hostname of the compute node your job has been allocated, load the mariadb module, and then run the mysqld_safe process: $ srun --pty bash $ echo $SLURM_JOB_NODELIST sh-01-01 $ ml system mariadb $ mysqld_safe 180705 18 :14:27 mysqld_safe Logging to '/home/users/kilian/db/mysqld.log' . 180705 18 :14:28 mysqld_safe Starting mysqld daemon with databases from /home/users/kilian/db/ The mysqld_safe will be blocking, meaning it will not give the prompt back for as long as the MariaDB server runs. If it does return on its own, it probably means that something went wrong, and you'll find more information about the issue in the $DB_DIR/mysqld.log file you defined in ~/.my.cnf .","title":"Start the server"},{"location":"docs/software/using/mariadb/#run-queries","text":"You're now ready to run queries against that MariaDB instance, from the same node your job is running on. From another terminal on Sherlock, connect to your job's compute node (here, it's sh-01-01 , as shown above), load the mariadb module, and then run the mysql command: it will open the MariaDB shell, ready to run your SQL queries: $ ssh sh-01-01 $ ml system mariadb $ mysql Welcome to the MariaDB monitor. Commands end with ; or \\g . Your MariaDB connection id is 8 Server version: 10 .2.11-MariaDB Source distribution Copyright ( c ) 2000 , 2017 , Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [( none )] > Once you're done with your MariaDB instance, you can just terminate your job, and all the processes will be terminated automatically.","title":"Run queries"},{"location":"docs/software/using/mariadb/#multi-node-access","text":"In case you need to run a more persistent instance of MariaDB, you can for instance submit a dedicated job to run the server, make it accessible over the network, and run queries from other jobs and/or nodes.","title":"Multi-node access"},{"location":"docs/software/using/mariadb/#enable-network-access","text":"The preparation steps are pretty similar to the single-node case , except the MariaDB server instance will be accessed over the network rather than through a local socket. Network access must be secured When running an networked instance of MariaDB, please keep in mind that any user on Sherlock will be able to connect to the TCP ports that mysqld runs on, and that proper configuration must be done to prevent unauthrozied access. Like in the single-node case, you need to create a ~/.my.cnf file, but without the skip-networking directive. $ export DB_DIR = $SCRATCH /db $ mkdir $DB_DIR $ cat << EOF > ~/.my.cnf [mysqld] datadir=$DB_DIR socket=$DB_DIR/mariadb.sock user=$USER symbolic-links=0 [mysqld_safe] log-error=$DB_DIR/mariadbd.log pid-file=$DB_DIR/mariadbd.pid [mysql] socket=$DB_DIR/mariadb.sock EOF And then initiate the database: $ ml system mariadb $ $MARIADB_DIR /scripts/mysql_install_db --basedir = $MARIADB_DIR --datadir = $DB_DIR","title":"Enable network access"},{"location":"docs/software/using/mariadb/#secure-access","text":"We will now set a password for the MariaDB root user to a random string, just for the purpose of preventing unauthorized access, since we won't need it for anything. We will actually create a MariaDB user with all privileges on the databases, that will be able to connect to this instance from any node. This user will need a real password, though. So please make sure to replace the my-secure-password string below by the actual password of your choice. Choose a proper password This password will only be used to access this specific instance of MariaDB. Note that anybody knowing that password will be allowed to connect to your MariaDB instances and modify data in the tables. do NOT literally use my-secure-password do NOT use your SUNet ID password Once you've chosen your password, you can start the mysqld process on a compute node, like before: $ srun --pty bash $ echo $SLURM_JOB_NODELIST sh-01-01 $ ml system mariadb $ mysqld_safe And then, from another terminal, run the following commands to secure access to your MariaDB database. $ ssh sh-01-01 $ mysql -u root << EOF UPDATE mysql.user SET Password=PASSWORD(RAND()) WHERE User='root'; DELETE FROM mysql.user WHERE User='root' AND Host NOT IN ('localhost', '127.0.0.1', '::1'); DELETE FROM mysql.user WHERE User=''; DELETE FROM mysql.db WHERE Db='test' OR Db='test_%'; GRANT ALL PRIVILEGES ON *.* TO '$USER'@'%' IDENTIFIED BY 'my-secure-password' WITH GRANT OPTION; FLUSH PRIVILEGES; EOF Once you've done that, you're ready to terminate that interactive job, and start a dedicated MariaDB server job.","title":"Secure access"},{"location":"docs/software/using/mariadb/#start-mariadb-in-a-job","text":"You can use the following mariadb.sbatch job as a template: #!/bin/bash #SBATCH --job-name=mariadb #SBATCH --time=8:0:0 #SBATCH --dependency=singleton ml system mariadb mysqld_safe and submit it with: $ sbatch mariadb.sbatch Concurrent instances will lead to data corruption An important thing to keep in mind is that having multiple instances of a MariaDB server running at the same time, using the same database files, will certainly lead to catastrophic situations and the corruption of those files. To prevent this from happening, the --dependency=singleton job submission option will make sure that only one instance of that job (based on its name and user) will run at any given time.","title":"Start MariaDB in a job"},{"location":"docs/software/using/mariadb/#connect-to-the-running-instance","text":"Now, from any node on Sherlock, whether from a login node, an interactive job, or a batch job, using the mysql CLI or any application binding in any language, you should be able to connect to your running MariaDB instance, First, identify the node your job is running on with squeue : $ squeue -u $USER -n mariadb JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 21383445 normal mariadb kilian R 0 :07 1 sh-01-02 and then, point your MariaDB client to that node: $ ml system mariadb $ mysql -h sh-01-02 -p Enter password: Welcome to the MariaDB monitor. Commands end with ; or \\g . Your MariaDB connection id is 15 Server version: 10 .2.11-MariaDB Source distribution Copyright ( c ) 2000 , 2017 , Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [( none )] > That's it! You can now run SQL queries from anywhere on Sherlock to your own MariaDB instance.","title":"Connect to the running instance"},{"location":"docs/software/using/mariadb/#persistent-db-instances","text":"SQL data is persistent All the data you import in your SQL databases will be persistent across jobs. Meaning that you can run a PostgreSQL server job for the day, import data in its database, stop the job, and resubmit the same PostgreSQL server job the next day: all your data will still be there as long as the location you've chosen for your database (the $DB_DIR defined in the Preparation steps) is on a persistent storage location . If you need database access for more than the maximum runtime of a job, you can use the instructions provided to define self-resubmitting recurring jobs and submit long-running database instances.","title":"Persistent DB instances"},{"location":"docs/software/using/matlab/","text":"Introduction # MATLAB is a numerical computing environment and proprietary programming language developed by MathWorks . More documentation # The following documentation is specifically intended for using Matlab on Sherlock. For more complete documentation about Matlab in general, please see the official MATLAB documentation . MATLAB on Sherlock # Licensing # MATLAB is a commercial software suite, which is now available to no cost for all Stanford Faculty, students, and staff . Note : a number of free, open-source alternatives exist and can be used in many situations: Octave , R , Julia , or Python are all available on Sherlock, and can often replace MATLAB with good results. Using MATLAB # The MATLAB module can be loaded with: $ ml load matlab This will load the current default version. For a list of available versions run ml spider matlab at the Sherlock prompt, or refer to the Software list page . MATLAB can't run on login nodes Running MATLAB directly on login nodes is not supported and will produce the following message: ----------------------------------------------------------------------- WARNING: running MATLAB directly on login nodes is not supported. Please make sure you request an interactive session on a compute node with \"sdev\" for instance) before launching MATLAB interactively. ----------------------------------------------------------------------- You will need to submit a job or request an interactive session on a compute node before you can start MATLAB. Once you are on a compute node and your environment is configured ( ie. when the matlab module is loaded), MATLAB can be started by simply typing matlab at the shell prompt. $ sdev $ ml load matlab $ matlab MATLAB is selecting SOFTWARE OPENGL rendering. < M A T L A B ( R ) > Copyright 1984 -2019 The MathWorks, Inc. R2019a ( 9 .6.0.1072779 ) 64 -bit ( glnxa64 ) March 8 , 2019 To get started, type doc. For product information, visit www.mathworks.com. >> For a listing of command line options: $ matlab -help Running a MATLAB script # There are several ways to launch a MATLAB script on the command line, as documented in the MATLAB documentation : Method Output matlab -nodesktop < script.m MATLAB will run the code from script.m and display output on stdout matlab -nodisplay Start MATLAB in CLI mode, without its graphical desktop environment matlab -nojvm do not start the JVM 1 MATLAB GUI # It's often best to use your laptop or desktop to develop, debug MATLAB and visualize the output. If you do need to use the MATLAB GUI on a large cluster like Sherlock, you will need to enable X11 forwarding in your SSH client . For instance: $ ssh -X <YourSUNetID>@login.sherlock.stanford.edu And then, once on Sherlock: $ sdev $ ml load matlab $ matlab For more info on X11 forwarding, you can refer to this UIT page . Examples # Simple MATLAB job # Here is an example MATLAB batch script that can submitted with sbatch : #!/bin/bash #SBATCH --job-name=matlab_test #SBATCH --output=matlab_test.\"%j\".out #SBATCH --error=matlab_test.\"%j\".err #SBATCH --partition=normal #SBATCH --time=00:10:00 #SBATCH --cpus-per-task=1 #SBATCH --mem=8G #SBATCH --mail-type=ALL module load matlab matlab -nodisplay < example.m This simple job, named matlab_test will run a MATLAB script named example.m in the normal partition , for a duration of 10 minutes, and use 1 CPU and 8GB of RAM . It will send you an email (to whatever email you used wen you signed up for Sherlock) when it begins, ends or fails. Additionally, to aid in debugging, it will log any errors and output to the files matlab_test.JOBID.{out,err} with the jobid appended to the filename ( %j ). To create the script, open a text editor on Sherlock, copy the contents of the script, and save it as matlab_test.sbatch Then, submit the job with the sbatch command: $ sbatch matlab_test.sbatch Submitted batch job 59942277 You can check the status of the job with the squeue command, and check the contents of the matlab_test.JOBID.{out,err} files to see the results. Parallel loop # You can run your MATLAB code across multiple CPUs on Sherlock using parfor loops, to take advantage of the multiple CPU cores that each node features. You can submit a job requesting as many CPUs as there are on a node in a single job. The key is to grab the SLURM environment variable $SLURM_CPUS_PER_TASK and create the worker pool in your MATLAB code with: parpool ( 'local' , str2num ( getenv ( 'SLURM_CPUS_PER_TASK' ))) Here is an example of a sbatch submission script that requests 16 CPUs on a node, and runs a simple MATLAB script using parfor . Save the two scripts below as parfor.sbatch and parfor.m : === parfor.sbatch #!/bin/bash #SBATCH -J pfor_matlab #SBATCH -o pfor\".%j\".out #SBATCH -e pfor\".%j\".err #SBATCH -t 20:00 #SBATCH -p normal #SBATCH -c 16 #SBATCH --mail-type=ALL module load matlab matlab -nosplash -nodesktop -r parfor === parfor.m %============================================================================ % Parallel Monte Carlo calculation of PI %============================================================================ parpool ( 'local' , str2num ( getenv ( 'SLURM_CPUS_PER_TASK' ))) R = 1 ; darts = 1e7 ; count = 0 ; tic parfor i = 1 : darts % Compute the X and Y coordinates of where the dart hit the............... % square using Uniform distribution....................................... x = R * rand ( 1 ); y = R * rand ( 1 ); if x ^ 2 + y ^ 2 <= R ^ 2 % Increment the count of darts that fell inside of the................. % circle............................................................... count = count + 1 ; % Count is a reduction variable. end end % Compute pi................................................................. myPI = 4 * count / darts ; T = toc ; fprintf ( 'The computed value of pi is %8.7f.n' , myPI ); fprintf ( 'The parallel Monte-Carlo method is executed in %8.2f seconds.n' , T ); delete ( gcp ); exit ; You can now submit the job with the following command: sbatch parfor.sbatch If you run htop or pstree -u $USER on the compute node that is running your job, you will see all 16 cores allocated to your MATLAB code. You can also try that same job with different numbers of CPUs, and see how well it scales. MATLAB uses the Java\u00ae Virtual Machine (JVM\u2122) software to run the desktop and to display graphics. The -nojvm option enables you to start MATLAB without the JVM. Using this option minimizes memory usage and improves initial start-up speed, but restricts functionality. \u21a9","title":"Matlab"},{"location":"docs/software/using/matlab/#introduction","text":"MATLAB is a numerical computing environment and proprietary programming language developed by MathWorks .","title":"Introduction"},{"location":"docs/software/using/matlab/#more-documentation","text":"The following documentation is specifically intended for using Matlab on Sherlock. For more complete documentation about Matlab in general, please see the official MATLAB documentation .","title":"More documentation"},{"location":"docs/software/using/matlab/#matlab-on-sherlock","text":"","title":"MATLAB on Sherlock"},{"location":"docs/software/using/matlab/#licensing","text":"MATLAB is a commercial software suite, which is now available to no cost for all Stanford Faculty, students, and staff . Note : a number of free, open-source alternatives exist and can be used in many situations: Octave , R , Julia , or Python are all available on Sherlock, and can often replace MATLAB with good results.","title":"Licensing"},{"location":"docs/software/using/matlab/#using-matlab","text":"The MATLAB module can be loaded with: $ ml load matlab This will load the current default version. For a list of available versions run ml spider matlab at the Sherlock prompt, or refer to the Software list page . MATLAB can't run on login nodes Running MATLAB directly on login nodes is not supported and will produce the following message: ----------------------------------------------------------------------- WARNING: running MATLAB directly on login nodes is not supported. Please make sure you request an interactive session on a compute node with \"sdev\" for instance) before launching MATLAB interactively. ----------------------------------------------------------------------- You will need to submit a job or request an interactive session on a compute node before you can start MATLAB. Once you are on a compute node and your environment is configured ( ie. when the matlab module is loaded), MATLAB can be started by simply typing matlab at the shell prompt. $ sdev $ ml load matlab $ matlab MATLAB is selecting SOFTWARE OPENGL rendering. < M A T L A B ( R ) > Copyright 1984 -2019 The MathWorks, Inc. R2019a ( 9 .6.0.1072779 ) 64 -bit ( glnxa64 ) March 8 , 2019 To get started, type doc. For product information, visit www.mathworks.com. >> For a listing of command line options: $ matlab -help","title":"Using MATLAB"},{"location":"docs/software/using/matlab/#running-a-matlab-script","text":"There are several ways to launch a MATLAB script on the command line, as documented in the MATLAB documentation : Method Output matlab -nodesktop < script.m MATLAB will run the code from script.m and display output on stdout matlab -nodisplay Start MATLAB in CLI mode, without its graphical desktop environment matlab -nojvm do not start the JVM 1","title":"Running a MATLAB script"},{"location":"docs/software/using/matlab/#matlab-gui","text":"It's often best to use your laptop or desktop to develop, debug MATLAB and visualize the output. If you do need to use the MATLAB GUI on a large cluster like Sherlock, you will need to enable X11 forwarding in your SSH client . For instance: $ ssh -X <YourSUNetID>@login.sherlock.stanford.edu And then, once on Sherlock: $ sdev $ ml load matlab $ matlab For more info on X11 forwarding, you can refer to this UIT page .","title":"MATLAB GUI"},{"location":"docs/software/using/matlab/#examples","text":"","title":"Examples"},{"location":"docs/software/using/matlab/#simple-matlab-job","text":"Here is an example MATLAB batch script that can submitted with sbatch : #!/bin/bash #SBATCH --job-name=matlab_test #SBATCH --output=matlab_test.\"%j\".out #SBATCH --error=matlab_test.\"%j\".err #SBATCH --partition=normal #SBATCH --time=00:10:00 #SBATCH --cpus-per-task=1 #SBATCH --mem=8G #SBATCH --mail-type=ALL module load matlab matlab -nodisplay < example.m This simple job, named matlab_test will run a MATLAB script named example.m in the normal partition , for a duration of 10 minutes, and use 1 CPU and 8GB of RAM . It will send you an email (to whatever email you used wen you signed up for Sherlock) when it begins, ends or fails. Additionally, to aid in debugging, it will log any errors and output to the files matlab_test.JOBID.{out,err} with the jobid appended to the filename ( %j ). To create the script, open a text editor on Sherlock, copy the contents of the script, and save it as matlab_test.sbatch Then, submit the job with the sbatch command: $ sbatch matlab_test.sbatch Submitted batch job 59942277 You can check the status of the job with the squeue command, and check the contents of the matlab_test.JOBID.{out,err} files to see the results.","title":"Simple MATLAB job"},{"location":"docs/software/using/matlab/#parallel-loop","text":"You can run your MATLAB code across multiple CPUs on Sherlock using parfor loops, to take advantage of the multiple CPU cores that each node features. You can submit a job requesting as many CPUs as there are on a node in a single job. The key is to grab the SLURM environment variable $SLURM_CPUS_PER_TASK and create the worker pool in your MATLAB code with: parpool ( 'local' , str2num ( getenv ( 'SLURM_CPUS_PER_TASK' ))) Here is an example of a sbatch submission script that requests 16 CPUs on a node, and runs a simple MATLAB script using parfor . Save the two scripts below as parfor.sbatch and parfor.m : === parfor.sbatch #!/bin/bash #SBATCH -J pfor_matlab #SBATCH -o pfor\".%j\".out #SBATCH -e pfor\".%j\".err #SBATCH -t 20:00 #SBATCH -p normal #SBATCH -c 16 #SBATCH --mail-type=ALL module load matlab matlab -nosplash -nodesktop -r parfor === parfor.m %============================================================================ % Parallel Monte Carlo calculation of PI %============================================================================ parpool ( 'local' , str2num ( getenv ( 'SLURM_CPUS_PER_TASK' ))) R = 1 ; darts = 1e7 ; count = 0 ; tic parfor i = 1 : darts % Compute the X and Y coordinates of where the dart hit the............... % square using Uniform distribution....................................... x = R * rand ( 1 ); y = R * rand ( 1 ); if x ^ 2 + y ^ 2 <= R ^ 2 % Increment the count of darts that fell inside of the................. % circle............................................................... count = count + 1 ; % Count is a reduction variable. end end % Compute pi................................................................. myPI = 4 * count / darts ; T = toc ; fprintf ( 'The computed value of pi is %8.7f.n' , myPI ); fprintf ( 'The parallel Monte-Carlo method is executed in %8.2f seconds.n' , T ); delete ( gcp ); exit ; You can now submit the job with the following command: sbatch parfor.sbatch If you run htop or pstree -u $USER on the compute node that is running your job, you will see all 16 cores allocated to your MATLAB code. You can also try that same job with different numbers of CPUs, and see how well it scales. MATLAB uses the Java\u00ae Virtual Machine (JVM\u2122) software to run the desktop and to display graphics. The -nojvm option enables you to start MATLAB without the JVM. Using this option minimizes memory usage and improves initial start-up speed, but restricts functionality. \u21a9","title":"Parallel loop"},{"location":"docs/software/using/perl/","text":"Introduction # Perl is a high-level, general-purpose, interpreted, dynamic programming language. Originally developed by Larry Wall in 1987 as a general-purpose Unix scripting language to make report processing easier, it has since undergone many changes and revisions. Perl provides a framework allowing users to easily extend the language by installing new modules in their local environment. The Comprehensive Perl Archive Network (CPAN 1 ) is an archive of over 25,000 distributions of software written in Perl, as well as documentation for it. It is searchable at http://metacpan.org or http://search.cpan.org and mirrored in over 270 locations around the world. More documentation # The following documentation specifically intended for using Perl on Sherlock. For more complete documentation about Perl in general, please see the Perl documentation . Perl modules on Sherlock # To install Perl modules from CPAN, we recommend using the (provided) App::cpanminus module and local::lib modules: App::cpanminus is a popular alternative CPAN client that can be used to manage Perl distributions. It has many great features, including uninstalling modules. local::lib allows users to install Perl modules in the directory of their choice (typically their home directory) without administrative privileges. Both are already installed on Sherlock, and are automatically enabled and configured when you load the perl module. You don't need to add anything in your ~/.bashrc file, the Sherlock perl module will automatically create everything that is required so you can directly run a command to install Perl modules locally. Installation # Perl modules installation is only necessary once You only need to install Perl modules once on Sherlock. Since fielsystems are shared, modules installed on one node will immediately be available on all nodes on the cluster. As an example, to install the DateTime::TimeZone module, you can do the following: $ ml perl $ cpanm DateTime::TimeZone Usage # Once installed, you can use the Perl modules directly, no specific options or syntax is required. For instance, to check that the DateTime::TimeZone module is correctly installed: $ perl -MDateTime::TimeZone -e 'print $DateTime::TimeZone::VERSION . \"\\n\"' ; 2 .13 Uninstallation # To uninstall a Perl module: $ cpanm -U DateTime::TimeZone CPAN can denote either the archive network itself, or the Perl program that acts as an interface to the network and as an automated software installer (somewhat like a package manager). Most software on CPAN is free and open source. \u21a9","title":"Perl"},{"location":"docs/software/using/perl/#introduction","text":"Perl is a high-level, general-purpose, interpreted, dynamic programming language. Originally developed by Larry Wall in 1987 as a general-purpose Unix scripting language to make report processing easier, it has since undergone many changes and revisions. Perl provides a framework allowing users to easily extend the language by installing new modules in their local environment. The Comprehensive Perl Archive Network (CPAN 1 ) is an archive of over 25,000 distributions of software written in Perl, as well as documentation for it. It is searchable at http://metacpan.org or http://search.cpan.org and mirrored in over 270 locations around the world.","title":"Introduction"},{"location":"docs/software/using/perl/#more-documentation","text":"The following documentation specifically intended for using Perl on Sherlock. For more complete documentation about Perl in general, please see the Perl documentation .","title":"More documentation"},{"location":"docs/software/using/perl/#perl-modules-on-sherlock","text":"To install Perl modules from CPAN, we recommend using the (provided) App::cpanminus module and local::lib modules: App::cpanminus is a popular alternative CPAN client that can be used to manage Perl distributions. It has many great features, including uninstalling modules. local::lib allows users to install Perl modules in the directory of their choice (typically their home directory) without administrative privileges. Both are already installed on Sherlock, and are automatically enabled and configured when you load the perl module. You don't need to add anything in your ~/.bashrc file, the Sherlock perl module will automatically create everything that is required so you can directly run a command to install Perl modules locally.","title":"Perl modules on Sherlock"},{"location":"docs/software/using/perl/#installation","text":"Perl modules installation is only necessary once You only need to install Perl modules once on Sherlock. Since fielsystems are shared, modules installed on one node will immediately be available on all nodes on the cluster. As an example, to install the DateTime::TimeZone module, you can do the following: $ ml perl $ cpanm DateTime::TimeZone","title":"Installation"},{"location":"docs/software/using/perl/#usage","text":"Once installed, you can use the Perl modules directly, no specific options or syntax is required. For instance, to check that the DateTime::TimeZone module is correctly installed: $ perl -MDateTime::TimeZone -e 'print $DateTime::TimeZone::VERSION . \"\\n\"' ; 2 .13","title":"Usage"},{"location":"docs/software/using/perl/#uninstallation","text":"To uninstall a Perl module: $ cpanm -U DateTime::TimeZone CPAN can denote either the archive network itself, or the Perl program that acts as an interface to the network and as an automated software installer (somewhat like a package manager). Most software on CPAN is free and open source. \u21a9","title":"Uninstallation"},{"location":"docs/software/using/postgresql/","text":"Introduction # PostgreSQL is a powerful, open source object-relational database system with a strong focus on reliability, feature robustness, and performance. More documentation # The following documentation specifically intended for using PostgreSQL on Sherlock. For more complete documentation about PostgreSQL in general, please see the PostgreSQL documentation . PostgreSQL on Sherlock # We don't provide any centralized database service on Sherlock, but we provide a centralized installation of PostgreSQL, and each user is welcome to start their own instance of the database server to fit their jobs' needs. The overall process to run an instance of PostgreSQL on Sherlock would look like this: configure and initialize your environment so you can start a database instance under your user account, start the database server, run SQL queries from the same node (via a local socket), or from other nodes and/or jobs (via the network). Single-node access # In that example, the database server and client will run within the same job, on the same compute node . Preparation # You first need to let PostgreSQL know where to store its database. The commands below only need to be executed once. Assuming you'll want to store your database files in a db/ directory in your $SCRATCH folder, you can run the following commands: $ export DB_DIR = $SCRATCH /db $ mkdir $DB_DIR Once you have your $DB_DIR in place, you need to initialize your database with some internal data that PostgreSQL needs. In the same terminal, run the following commands: $ ml system postgresql $ initdb $DB_DIR Start the server # You can now start the PostgreSQL server. For this, first get an allocation on a compute node, note the hostname of the compute node your job has been allocated, load the postgresql module, and then run the postgresql server: $ srun --pty bash $ echo $SLURM_JOB_NODELIST sh-01-01 $ ml system postgresql $ export DB_DIR = $SCRATCH /db $ postgres -D $DB_DIR [ ... ] 2018 -10-09 17 :42:08.094 PDT [ 3841 ] LOG: database system is ready to accept connections The postgres process will be blocking, meaning it will not give the prompt back for as long as the PostgreSQL server runs. Run queries # You're now ready to run queries against that PostgreSQL instance, from the same node your job is running on. From another terminal on Sherlock, connect to your job's compute node (here, it's sh-01-01 , as shown above), load the postgresql module, and then run the createdb command: it will create a database that you can use as a testbed: $ ssh sh-01-01 $ ml system postgresql $ createdb test_db Once this is done, from the same shell, you can run the psql command, which will open the PostgreSQL shell, ready to run your SQL queries: $ psql test_db psql ( 10 .5 ) Type \"help\" for help. test_db = # Once you're done with your PostgreSQL instance, you can just terminate your job, and all the processes will be terminated automatically. Multi-node access # In case you need to run a more persistent instance of PostgreSQL, you can for instance submit a dedicated job to run the server, make it accessible over the network, and run queries from other jobs and/or nodes. Enable network access # The preparation steps are pretty similar to the single-node case , except the PostgreSQL server instance will be accessed over the network rather than through a local socket. Network access must be secured When running an networked instance of PostgreSQL, please keep in mind that any user on Sherlock could potentially be able to connect to the TCP ports that postgres runs on, and that proper configuration must be done to prevent unauthrozied access. Like in the single-node case, you need to start the postgres server process, but with the -i option to enable network connections, and define user access in your $DB_DIR/pg_hba.conf file (see below). Secure access # To allow network connections to the database server, a password will need to be defined for the PostgreSQL user. That will allow this user to connect to the PostgreSQL instance from any node. Please make sure to replace the my-secure-password string below by the actual password of your choice. Choose a proper password This password will only be used to access this specific instance of PostgreSQL. Note that anybody knowing that password will be allowed to connect to your PostgreSQL instances and modify data in the tables. do NOT use my-secure-password do NOT use your SUNet ID password Once you've chosen your password, you can now start the PostgreSQL server on a compute, as described in the previous section, initialize the database, and set the user password: $ srun --pty bash $ echo $SLURM_JOB_NODELIST sh-01-01 $ export DB_DIR = $SCRATCH /db $ mkdir $DB_DIR $ ml system postgresql $ initdb $DB_DIR $ createdb test_db $ psql -c \"ALTER USER $USER PASSWORD 'my-secure-password';\" test_db Then, we need to edit the $DB_DIR/ph_hba.conf file to allow network access for user $USER : $ cat << EOF > $DB_DIR/pg_hba.conf local all all trust host all all 127.0.0.1/32 trust host all all ::1/128 trust host all $USER samenet md5 EOF Once you've done that, you're ready to terminate that interactive job, and start a dedicated PostgreSQL server job. $ pg_ctl stop -D $DB_DIR $ logout Start PostgreSQL in a job # You can use the following postgresql.sbatch job as a template: #!/bin/bash #SBATCH --job-name=postgresql #SBATCH --time=8:0:0 #SBATCH --dependency=singleton export DB_DIR = $SCRATCH /db ml system postgresql postgres -i -D $DB_DIR and submit it with: $ sbatch postgresql.sbatch Concurrent instances will lead to data corruption An important thing to keep in mind is that having multiple instances of a PostgreSQL server running at the same time, using the same database files, will certainly lead to catastrophic situations and the corruption of those files. To prevent this from happening, the --dependency=singleton job submission option will make sure that only one instance of that job (based on its name and user) will run at any given time. Connect to the running instance # Now, from any node on Sherlock, whether from a login node, an interactive job, or a batch job, using the mysql CLI or any application binding in any language, you should be able to connect to your running PostgreSQL instance, First, identify the node your job is running on with squeue : $ squeue -u $USER -n postgresql JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 21383445 normal postgresql kilian R 0 :07 1 sh-01-02 and then, point your PostgreSQL client to that node: $ ml system postgresql $ mpsql -h sh-06-34 test_db Password: psql ( 10 .5 ) Type \"help\" for help. test_db = # That's it! You can now run SQL queries from anywhere on Sherlock to your own PostgreSQL instance. Persistent DB instances # SQL data is persistent All the data you import in your SQL databases will be persistent across jobs. Meaning that you can run a PostgreSQL server job for the day, import data in its database, stop the job, and resubmit the same PostgreSQL server job the next day: all your data will still be there as long as the location you've chosen for your database (the $DB_DIR defined in the Preparation steps) is on a persistent storage location . If you need database access for more than the maximum runtime of a job, you can use the instructions provided to define self-resubmitting recurring jobs and submit long-running database instances.","title":"PostgreSQL"},{"location":"docs/software/using/postgresql/#introduction","text":"PostgreSQL is a powerful, open source object-relational database system with a strong focus on reliability, feature robustness, and performance.","title":"Introduction"},{"location":"docs/software/using/postgresql/#more-documentation","text":"The following documentation specifically intended for using PostgreSQL on Sherlock. For more complete documentation about PostgreSQL in general, please see the PostgreSQL documentation .","title":"More documentation"},{"location":"docs/software/using/postgresql/#postgresql-on-sherlock","text":"We don't provide any centralized database service on Sherlock, but we provide a centralized installation of PostgreSQL, and each user is welcome to start their own instance of the database server to fit their jobs' needs. The overall process to run an instance of PostgreSQL on Sherlock would look like this: configure and initialize your environment so you can start a database instance under your user account, start the database server, run SQL queries from the same node (via a local socket), or from other nodes and/or jobs (via the network).","title":"PostgreSQL on Sherlock"},{"location":"docs/software/using/postgresql/#single-node-access","text":"In that example, the database server and client will run within the same job, on the same compute node .","title":"Single-node access"},{"location":"docs/software/using/postgresql/#preparation","text":"You first need to let PostgreSQL know where to store its database. The commands below only need to be executed once. Assuming you'll want to store your database files in a db/ directory in your $SCRATCH folder, you can run the following commands: $ export DB_DIR = $SCRATCH /db $ mkdir $DB_DIR Once you have your $DB_DIR in place, you need to initialize your database with some internal data that PostgreSQL needs. In the same terminal, run the following commands: $ ml system postgresql $ initdb $DB_DIR","title":"Preparation"},{"location":"docs/software/using/postgresql/#start-the-server","text":"You can now start the PostgreSQL server. For this, first get an allocation on a compute node, note the hostname of the compute node your job has been allocated, load the postgresql module, and then run the postgresql server: $ srun --pty bash $ echo $SLURM_JOB_NODELIST sh-01-01 $ ml system postgresql $ export DB_DIR = $SCRATCH /db $ postgres -D $DB_DIR [ ... ] 2018 -10-09 17 :42:08.094 PDT [ 3841 ] LOG: database system is ready to accept connections The postgres process will be blocking, meaning it will not give the prompt back for as long as the PostgreSQL server runs.","title":"Start the server"},{"location":"docs/software/using/postgresql/#run-queries","text":"You're now ready to run queries against that PostgreSQL instance, from the same node your job is running on. From another terminal on Sherlock, connect to your job's compute node (here, it's sh-01-01 , as shown above), load the postgresql module, and then run the createdb command: it will create a database that you can use as a testbed: $ ssh sh-01-01 $ ml system postgresql $ createdb test_db Once this is done, from the same shell, you can run the psql command, which will open the PostgreSQL shell, ready to run your SQL queries: $ psql test_db psql ( 10 .5 ) Type \"help\" for help. test_db = # Once you're done with your PostgreSQL instance, you can just terminate your job, and all the processes will be terminated automatically.","title":"Run queries"},{"location":"docs/software/using/postgresql/#multi-node-access","text":"In case you need to run a more persistent instance of PostgreSQL, you can for instance submit a dedicated job to run the server, make it accessible over the network, and run queries from other jobs and/or nodes.","title":"Multi-node access"},{"location":"docs/software/using/postgresql/#enable-network-access","text":"The preparation steps are pretty similar to the single-node case , except the PostgreSQL server instance will be accessed over the network rather than through a local socket. Network access must be secured When running an networked instance of PostgreSQL, please keep in mind that any user on Sherlock could potentially be able to connect to the TCP ports that postgres runs on, and that proper configuration must be done to prevent unauthrozied access. Like in the single-node case, you need to start the postgres server process, but with the -i option to enable network connections, and define user access in your $DB_DIR/pg_hba.conf file (see below).","title":"Enable network access"},{"location":"docs/software/using/postgresql/#secure-access","text":"To allow network connections to the database server, a password will need to be defined for the PostgreSQL user. That will allow this user to connect to the PostgreSQL instance from any node. Please make sure to replace the my-secure-password string below by the actual password of your choice. Choose a proper password This password will only be used to access this specific instance of PostgreSQL. Note that anybody knowing that password will be allowed to connect to your PostgreSQL instances and modify data in the tables. do NOT use my-secure-password do NOT use your SUNet ID password Once you've chosen your password, you can now start the PostgreSQL server on a compute, as described in the previous section, initialize the database, and set the user password: $ srun --pty bash $ echo $SLURM_JOB_NODELIST sh-01-01 $ export DB_DIR = $SCRATCH /db $ mkdir $DB_DIR $ ml system postgresql $ initdb $DB_DIR $ createdb test_db $ psql -c \"ALTER USER $USER PASSWORD 'my-secure-password';\" test_db Then, we need to edit the $DB_DIR/ph_hba.conf file to allow network access for user $USER : $ cat << EOF > $DB_DIR/pg_hba.conf local all all trust host all all 127.0.0.1/32 trust host all all ::1/128 trust host all $USER samenet md5 EOF Once you've done that, you're ready to terminate that interactive job, and start a dedicated PostgreSQL server job. $ pg_ctl stop -D $DB_DIR $ logout","title":"Secure access"},{"location":"docs/software/using/postgresql/#start-postgresql-in-a-job","text":"You can use the following postgresql.sbatch job as a template: #!/bin/bash #SBATCH --job-name=postgresql #SBATCH --time=8:0:0 #SBATCH --dependency=singleton export DB_DIR = $SCRATCH /db ml system postgresql postgres -i -D $DB_DIR and submit it with: $ sbatch postgresql.sbatch Concurrent instances will lead to data corruption An important thing to keep in mind is that having multiple instances of a PostgreSQL server running at the same time, using the same database files, will certainly lead to catastrophic situations and the corruption of those files. To prevent this from happening, the --dependency=singleton job submission option will make sure that only one instance of that job (based on its name and user) will run at any given time.","title":"Start PostgreSQL in a job"},{"location":"docs/software/using/postgresql/#connect-to-the-running-instance","text":"Now, from any node on Sherlock, whether from a login node, an interactive job, or a batch job, using the mysql CLI or any application binding in any language, you should be able to connect to your running PostgreSQL instance, First, identify the node your job is running on with squeue : $ squeue -u $USER -n postgresql JOBID PARTITION NAME USER ST TIME NODES NODELIST ( REASON ) 21383445 normal postgresql kilian R 0 :07 1 sh-01-02 and then, point your PostgreSQL client to that node: $ ml system postgresql $ mpsql -h sh-06-34 test_db Password: psql ( 10 .5 ) Type \"help\" for help. test_db = # That's it! You can now run SQL queries from anywhere on Sherlock to your own PostgreSQL instance.","title":"Connect to the running instance"},{"location":"docs/software/using/postgresql/#persistent-db-instances","text":"SQL data is persistent All the data you import in your SQL databases will be persistent across jobs. Meaning that you can run a PostgreSQL server job for the day, import data in its database, stop the job, and resubmit the same PostgreSQL server job the next day: all your data will still be there as long as the location you've chosen for your database (the $DB_DIR defined in the Preparation steps) is on a persistent storage location . If you need database access for more than the maximum runtime of a job, you can use the instructions provided to define self-resubmitting recurring jobs and submit long-running database instances.","title":"Persistent DB instances"},{"location":"docs/software/using/python/","text":"Introduction # Python is an interpreted high-level programming language for general-purpose programming. Its design philosophy emphasizes code readability, notably using significant whitespace. It provides constructs that enable clear programming on both small and large scales, which makes it both easy to learn and very well-suited for rapid prototyping. More documentation # The following documentation is specifically intended for using Python on Sherlock. For more complete documentation about Python in general, please see the Python documentation . Python on Sherlock # Sherlock features multiple versions of Python (currently 2.7 and 3.6 ). Some applications only work with legacy features of version 2.x, while more recent code will require specific version 3.x features. Modules on Sherlock may only be available in a single flavor (as denoted by their suffix: _py27 or _py36 , because the application only supports one or the other. You can load either version on Sherlock by doing the following commands: $ ml python/2.7.13 or $ ml python/3.6.1 The Python3 interpreter is python3 The Python3 executable is named python3 , not python . So, once you have the \"python/3.6.1\" module loaded on Sherlock, you will need to use python3 to invoke the proper interpreter. python will still refer to the default, older system-level Python installation, and may result in errors when trying to run Python3 code. This is an upstream decision detailled in PEP-394 , not something specific to Sherlock. Using Python # Once your environment is configured (ie. when the Python module is loaded), Python can be started by simply typing python at the shell prompt: $ python Python 2 .7.13 ( default, Apr 27 2017 , 14 :19:21 ) [ GCC 4 .8.5 20150623 ( Red Hat 4 .8.5-11 )] on linux2 Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. >>> Python packages # The capabilities of Python can be extended with packages developed by third parties. In general, to simplify operations, it is left up to individual users and groups to install these third-party packages in their own directories. However, Sherlock provides tools to help you install the third-party packages that you need. Among many others , the following common Python packages are provided on Sherlock: NumPy SciPy TensorFlow Python modules on Sherlock generally follow the naming scheme below: py-<package_name>/version_py<python_version> For instance, NumPy modules are: py-numpy/1.14.3_py27 py-numpy/1.14.3_py36 You can list all available module versions for a package with ml spider <package_name> . For instance: $ ml spider tensorflow ------------------------------------------------------------------------------- py-tensorflow: ------------------------------------------------------------------------------- Description: TensorFlow\u2122 is an open source software library for numerical computation using data flow graphs. Versions: py-tensorflow/1.6.0_py27 py-tensorflow/1.6.0_py36 py-tensorflow/1.7.0_py27 py-tensorflow/1.9.0_py27 py-tensorflow/1.9.0_py36 Dependencies are handled automatically When you decide to use NumPy on Sherlock, you just need to load the py-numpy module of your choice, and the correct Python interpreter will be loaded automatically. No need to load a python module explicitly. Installing packages # If you need to use a Python package that is not already provided as a module on Sherlock, you can use the pip command. This command takes care of compiling and installing most of Python packages and their dependencies. All of pip 's commands and options are explained in detail in the Pip user guide . A comprehensive index of Python packages can be found at PyPI . To install Python packages with pip , you'll need to use the --user option. This will make sure that those packages are installed in a user-writable location (by default, your $HOME directory). Since your $HOME directory is shared across nodes on Sherlock, you'll only need to install your Python packages once, and they'll be ready to be used on every single node in the cluster. For example: $ pip install --user <package_name> For Python 3, use pip3 : $ pip3 install --user <package_name> Python packages will be installed in $HOME/.local/lib/python< <version> /site-packages , meaning that packages for Python 2.x and Python 3.x will be kept separate. This both means that they won't interfere with each other, but also that if you need to use a package with both Python 2.x and 3.x, you'll need to install it twice, once for each Python version. List installed packages # You can easily see the list of the Python packages installed in your environment, and their location, with pip list : $ pip list -v Package Version Location Installer ---------- ------- ------------------------------------------------------------------- --------- pip 18 .1 /share/software/user/open/python/2.7.13/lib/python2.7/site-packages pip setuptools 28 .8.0 /share/software/user/open/python/2.7.13/lib/python2.7/site-packages pip urllib3 1 .24 /home/users/kilian/.local/lib/python2.7/site-packages pip virtualenv 15 .1.0 /share/software/user/open/python/2.7.13/lib/python2.7/site-packages pip Alternative installation path # Python paths While theoretically possible, installing Python packages in alternate locations can be tricky, so we recommend trying to stick to the pip install --user way as often as possible. But in case you absolutely need it, we provide some guidelines below. One common case of needing to install Python packages in alternate locations is to share those packages with a group of users. Here's an example that will show how to install the urllib3 Python package in a group-shared location and let users from the group use it without having to install it themselves. First, you need to create a directory to store those packages. We'll put it in $GROUP_HOME : $ mkdir -p $GROUP_HOME /python/ Then, we load the Python module we need, and we instruct pip to install its packages in the directory we just created: $ ml python/2.7.13 $ PYTHONUSERBASE = $GROUP_HOME /python pip install --user urllib3 We still use the --user option, but with PYTHONUSERBASE pointing to a different directory, pip will install packages there. Now, to be able to use that Python module, since it's not been installed in a default directory, you (and all the members of the group who will want to use that module) need to set their PYTHONPATH to include our new shared directory 1 : $ export PYTHONPATH = $GROUP_HOME /python/lib/python2.7/site-packages: $PYTHONPATH And now, the module should be visible: $ pip list -v Package Version Location Installer ---------- ------- ------------------------------------------------------------------- --------- pip 18 .1 /share/software/user/open/python/2.7.13/lib/python2.7/site-packages pip setuptools 28 .8.0 /share/software/user/open/python/2.7.13/lib/python2.7/site-packages pip urllib3 1 .24 /home/groups/ruthm/python/lib/python2.7/site-packages pip virtualenv 15 .1.0 /share/software/user/open/python/2.7.13/lib/python2.7/site-packages pip $PYTHONPATH depends on the Python version The $PYTHONPATH environment variable is dependent on the Python version you're using, so for Python 3.6, it should include $GROUP_HOME/python/lib/python3.6/site-packages $PATH may also need to be updated Some Python package sometimes also install executable scripts. To make them easily accessible in your environment, you may also want to modify your $PATH to include their installation directory. For instance, if you installed Python packages in $GROUP_HOME/python : $ export PATH=$GROUP_HOME/python/bin:$PATH Installing from GitHub # pip also supports installing packages from a variety of sources, including GitHub repositories. For instance, to install HTTPie , you can do: $ pip install --user git+git://github.com/jkbr/httpie.git Installing from a requirements file # pip allows installing a list of packages listed in a file, which can be pretty convenient to install several dependencies at once. In order to do this, create a text file called requirements.txt and place each package you would like to install on its own line: requirements.txt numpy scikit-learn keras tensorflow You can now install your modules like so: $ ml python $ pip install--user -r requirements.txt Upgrading packages # pip can update already installed packages with the following command: $ pip install --user --upgrade <package_name> Upgrading packages also works with requirements.txt files: $ pip install --user --upgrade -r requirements.txt Uninstalling packages # To uninstall a Python package, you can use the pip uninstall command (note that it doesn't take any --user option): $ pip uninstall <package_name> $ pip uninstall -r requirements.txt This line can also be added to a user's ~/.profile file, for a more permanent setting. \u21a9","title":"Python"},{"location":"docs/software/using/python/#introduction","text":"Python is an interpreted high-level programming language for general-purpose programming. Its design philosophy emphasizes code readability, notably using significant whitespace. It provides constructs that enable clear programming on both small and large scales, which makes it both easy to learn and very well-suited for rapid prototyping.","title":"Introduction"},{"location":"docs/software/using/python/#more-documentation","text":"The following documentation is specifically intended for using Python on Sherlock. For more complete documentation about Python in general, please see the Python documentation .","title":"More documentation"},{"location":"docs/software/using/python/#python-on-sherlock","text":"Sherlock features multiple versions of Python (currently 2.7 and 3.6 ). Some applications only work with legacy features of version 2.x, while more recent code will require specific version 3.x features. Modules on Sherlock may only be available in a single flavor (as denoted by their suffix: _py27 or _py36 , because the application only supports one or the other. You can load either version on Sherlock by doing the following commands: $ ml python/2.7.13 or $ ml python/3.6.1 The Python3 interpreter is python3 The Python3 executable is named python3 , not python . So, once you have the \"python/3.6.1\" module loaded on Sherlock, you will need to use python3 to invoke the proper interpreter. python will still refer to the default, older system-level Python installation, and may result in errors when trying to run Python3 code. This is an upstream decision detailled in PEP-394 , not something specific to Sherlock.","title":"Python on Sherlock"},{"location":"docs/software/using/python/#using-python","text":"Once your environment is configured (ie. when the Python module is loaded), Python can be started by simply typing python at the shell prompt: $ python Python 2 .7.13 ( default, Apr 27 2017 , 14 :19:21 ) [ GCC 4 .8.5 20150623 ( Red Hat 4 .8.5-11 )] on linux2 Type \"help\" , \"copyright\" , \"credits\" or \"license\" for more information. >>>","title":"Using Python"},{"location":"docs/software/using/python/#python-packages","text":"The capabilities of Python can be extended with packages developed by third parties. In general, to simplify operations, it is left up to individual users and groups to install these third-party packages in their own directories. However, Sherlock provides tools to help you install the third-party packages that you need. Among many others , the following common Python packages are provided on Sherlock: NumPy SciPy TensorFlow Python modules on Sherlock generally follow the naming scheme below: py-<package_name>/version_py<python_version> For instance, NumPy modules are: py-numpy/1.14.3_py27 py-numpy/1.14.3_py36 You can list all available module versions for a package with ml spider <package_name> . For instance: $ ml spider tensorflow ------------------------------------------------------------------------------- py-tensorflow: ------------------------------------------------------------------------------- Description: TensorFlow\u2122 is an open source software library for numerical computation using data flow graphs. Versions: py-tensorflow/1.6.0_py27 py-tensorflow/1.6.0_py36 py-tensorflow/1.7.0_py27 py-tensorflow/1.9.0_py27 py-tensorflow/1.9.0_py36 Dependencies are handled automatically When you decide to use NumPy on Sherlock, you just need to load the py-numpy module of your choice, and the correct Python interpreter will be loaded automatically. No need to load a python module explicitly.","title":"Python packages"},{"location":"docs/software/using/python/#installing-packages","text":"If you need to use a Python package that is not already provided as a module on Sherlock, you can use the pip command. This command takes care of compiling and installing most of Python packages and their dependencies. All of pip 's commands and options are explained in detail in the Pip user guide . A comprehensive index of Python packages can be found at PyPI . To install Python packages with pip , you'll need to use the --user option. This will make sure that those packages are installed in a user-writable location (by default, your $HOME directory). Since your $HOME directory is shared across nodes on Sherlock, you'll only need to install your Python packages once, and they'll be ready to be used on every single node in the cluster. For example: $ pip install --user <package_name> For Python 3, use pip3 : $ pip3 install --user <package_name> Python packages will be installed in $HOME/.local/lib/python< <version> /site-packages , meaning that packages for Python 2.x and Python 3.x will be kept separate. This both means that they won't interfere with each other, but also that if you need to use a package with both Python 2.x and 3.x, you'll need to install it twice, once for each Python version.","title":"Installing packages"},{"location":"docs/software/using/python/#upgrading-packages","text":"pip can update already installed packages with the following command: $ pip install --user --upgrade <package_name> Upgrading packages also works with requirements.txt files: $ pip install --user --upgrade -r requirements.txt","title":"Upgrading packages"},{"location":"docs/software/using/python/#uninstalling-packages","text":"To uninstall a Python package, you can use the pip uninstall command (note that it doesn't take any --user option): $ pip uninstall <package_name> $ pip uninstall -r requirements.txt This line can also be added to a user's ~/.profile file, for a more permanent setting. \u21a9","title":"Uninstalling packages"},{"location":"docs/software/using/rclone/","text":"Introduction # If you need to sync files between cloud storage to Sherlock, rclone is a command line program that can help. You can easily use it to transfer files from a cloud storage provider to Sherlock, or vice versa. The following tutorial is provided by a member of the Stanford community, and walks through transferring files from Box to Sherlock on a Mac. Setup # Connection # If you haven't done so already, open up a terminal and shell to sherlock: $ ssh <sunetid>@login.sherlock.stanford.edu You then will want to go to a location that has enough room to save the files. Since $HOME has a smaller limit (and you can lock yourself out if it fills up) let's go to the $SCRATCH space: $ cd $SCRATCH Since we don't want to run anything computationally intensive on a login node, let's request an interactive session. You can either ask for one with a particular time and partition on the fly: $ srun --partition normal --time 1 :00:00 --pty bash or ask for a development node for 1 hour: $ sdev Module # Rclone is readily available on Sherlock, but the corresponding module needs to be explicitely loaded to be made available in your environment: $ ml load system rclone Configuration # We can then configure it as follows: $ rclone config You'll notice that it's going to store a configuration file in your $HOME directory: 2019 /07/09 13 :03:56 NOTICE: Config file \"/home/users/vsochat/.config/rclone/rclone.conf\" not found - using defaults Remotes # It will first tell you that there are no \"remotes\" (cloud endpoints that you connect to) found, and you can press \"n\" to make a new one: No remotes found - make a new one n ) New remote s ) Set configuration password q ) Quit config n/s/q> n Next, it asks for a meaningful name. It's recommended to use some combination to remind your future self that the endpoint is intended to be from Sherlock, and to your cloud provider. For example, I might do: $ name> VanessaSherlockToBox The next choice is the cloud endpoint itself. This is where you would select the cloud provider that has the files that you want to connect to. There are many to choose from! You would want to select the number that corresponds with your choice. For example, I'd choose 5 or type \"box\" to select Box: Type of storage to configure. Enter a string value. Press Enter for the default ( \"\" ) . Choose a number from below, or type in your own value 1 / Alias for a existing remote \\ \"alias\" 2 / Amazon Drive \\ \"amazon cloud drive\" 3 / Amazon S3 Compliant Storage Providers ( AWS, Ceph, Dreamhost, IBM COS, Minio ) \\ \"s3\" 4 / Backblaze B2 \\ \"b2\" 5 / Box \\ \"box\" 6 / Cache a remote \\ \"cache\" 7 / Dropbox \\ \"dropbox\" 8 / Encrypt/Decrypt a remote \\ \"crypt\" 9 / FTP Connection \\ \"ftp\" 10 / Google Cloud Storage ( this is not Google Drive ) \\ \"google cloud storage\" 11 / Google Drive \\ \"drive\" 12 / Hubic \\ \"hubic\" 13 / JottaCloud \\ \"jottacloud\" 14 / Local Disk \\ \"local\" 15 / Mega \\ \"mega\" 16 / Microsoft Azure Blob Storage \\ \"azureblob\" 17 / Microsoft OneDrive \\ \"onedrive\" 18 / OpenDrive \\ \"opendrive\" 19 / Openstack Swift ( Rackspace Cloud Files, Memset Memstore, OVH ) \\ \"swift\" 20 / Pcloud \\ \"pcloud\" 21 / QingCloud Object Storage \\ \"qingstor\" 22 / SSH/SFTP Connection \\ \"sftp\" 23 / Webdav \\ \"webdav\" 24 / Yandex Disk \\ \"yandex\" 25 / http Connection \\ \"http\" Storage> 5 For client id and client secret, we will leave it blank (press ENTER for each) to designate that we want to enter it manually when we run it, as opposed to saving our credentials somewhere. Box App Client Id. Leave blank normally. Enter a string value. Press Enter for the default ( \"\" ) . client_id> Box App Client Secret Leave blank normally. Enter a string value. Press Enter for the default ( \"\" ) . client_secret> Finally, it will ask you if you want to edit the Advanced config. You can say no (n). Edit advanced config? ( y/n ) y ) Yes n ) No y/n> n And finally, since you are working on a remote and headless machine (Sherlock), you should say no to the next answer. Remote config Use auto config? * Say Y if not sure * Say N if you are working on a remote or headless machine y ) Yes n ) No y/n> n Authentication # The next part is important, because we need to open a separate terminal (one where we have a web browser available) to enter result asked for here. If you have a Mac, you can select Shell -> New Window -> New Window with Profile . If you have another flavor of Linux (or Windows) then you will need to install rclone locally and then issue this command: $ rclone authorize \"box\" A website will open for you to log in with your cloud provider (e.g., Box), and after login, it will tell you to return to your terminal: Success! All done . Please go back to rclone. Back in the (second terminal, not the one on Sherlock) you will see a message (that you might have previously missed) about the browser opening, waiting for a code, and then you will get the code (replaced below with xxxxxxxx): If your browser doesn ' t open automatically go to the following link: http://127.0.0.1:53682/auth Log in and authorize rclone for access Waiting for code... Got code Paste the following into your remote machine ---> { \"access_token\" : \"xxxxxxxxxxxxxx\" , \"token_type\" : \"bearer\" , \"refresh_token\" : \"xxxxxxxxxx\" , \"expiry\" : \"2019-xx-xxxxxxxx\" } ( ---End paste You need to copy the entire thing between the two brackets \"{}\" back into the first terminal running on Sherlock, which will be showing this: For this to work, you will need rclone available on a machine that has a web browser available. Execute the following on your machine: rclone authorize \"box\" Then paste the result below: result> After you paste, it will then ask you if it looks ok, and you can type Y for yes. [ VanessaSherlockToBox ] type = box token = { xxxxxxxxxxxxxxxxxxx } -------------------- y ) Yes this is OK e ) Edit this remote d ) Delete this remote And close up with a listing of your current remotes. You can quit Q after this, because next we will test our setup. Current remotes: Name Type ==== ==== VanessaSherlockToBox box e ) Edit existing remote n ) New remote d ) Delete remote r ) Rename remote c ) Copy remote s ) Set configuration password q ) Quit config e/n/d/r/c/s/q> q Testing # Did it work? Let's test listing files for our remote to see (filenames below are made up). $ rclone lsd VanessaSherlockToBox: --max-depth 1 -1 2018 -08-09 09 :52:01 -1 pancakes -1 2019 -03-13 23 :33:03 -1 miracles -1 2019 -03-06 09 :42:39 -1 alaska -1 2018 -02-06 02 :37:40 -1 share Next, let's copy a file to Sherlock. # rclone copy <remote>:<cloud storage path> <sherlock path> $ rclone copy VanessaSherlockToBox:pancakes /scratch/users/vsochat/pancakes There you go! If you want to interactively browse files, you can use the File Manager on the Sherlock OnDemand interface.","title":"Rclone"},{"location":"docs/software/using/rclone/#introduction","text":"If you need to sync files between cloud storage to Sherlock, rclone is a command line program that can help. You can easily use it to transfer files from a cloud storage provider to Sherlock, or vice versa. The following tutorial is provided by a member of the Stanford community, and walks through transferring files from Box to Sherlock on a Mac.","title":"Introduction"},{"location":"docs/software/using/rclone/#setup","text":"","title":"Setup"},{"location":"docs/software/using/rclone/#connection","text":"If you haven't done so already, open up a terminal and shell to sherlock: $ ssh <sunetid>@login.sherlock.stanford.edu You then will want to go to a location that has enough room to save the files. Since $HOME has a smaller limit (and you can lock yourself out if it fills up) let's go to the $SCRATCH space: $ cd $SCRATCH Since we don't want to run anything computationally intensive on a login node, let's request an interactive session. You can either ask for one with a particular time and partition on the fly: $ srun --partition normal --time 1 :00:00 --pty bash or ask for a development node for 1 hour: $ sdev","title":"Connection"},{"location":"docs/software/using/rclone/#module","text":"Rclone is readily available on Sherlock, but the corresponding module needs to be explicitely loaded to be made available in your environment: $ ml load system rclone","title":"Module"},{"location":"docs/software/using/rclone/#configuration","text":"We can then configure it as follows: $ rclone config You'll notice that it's going to store a configuration file in your $HOME directory: 2019 /07/09 13 :03:56 NOTICE: Config file \"/home/users/vsochat/.config/rclone/rclone.conf\" not found - using defaults","title":"Configuration"},{"location":"docs/software/using/rclone/#remotes","text":"It will first tell you that there are no \"remotes\" (cloud endpoints that you connect to) found, and you can press \"n\" to make a new one: No remotes found - make a new one n ) New remote s ) Set configuration password q ) Quit config n/s/q> n Next, it asks for a meaningful name. It's recommended to use some combination to remind your future self that the endpoint is intended to be from Sherlock, and to your cloud provider. For example, I might do: $ name> VanessaSherlockToBox The next choice is the cloud endpoint itself. This is where you would select the cloud provider that has the files that you want to connect to. There are many to choose from! You would want to select the number that corresponds with your choice. For example, I'd choose 5 or type \"box\" to select Box: Type of storage to configure. Enter a string value. Press Enter for the default ( \"\" ) . Choose a number from below, or type in your own value 1 / Alias for a existing remote \\ \"alias\" 2 / Amazon Drive \\ \"amazon cloud drive\" 3 / Amazon S3 Compliant Storage Providers ( AWS, Ceph, Dreamhost, IBM COS, Minio ) \\ \"s3\" 4 / Backblaze B2 \\ \"b2\" 5 / Box \\ \"box\" 6 / Cache a remote \\ \"cache\" 7 / Dropbox \\ \"dropbox\" 8 / Encrypt/Decrypt a remote \\ \"crypt\" 9 / FTP Connection \\ \"ftp\" 10 / Google Cloud Storage ( this is not Google Drive ) \\ \"google cloud storage\" 11 / Google Drive \\ \"drive\" 12 / Hubic \\ \"hubic\" 13 / JottaCloud \\ \"jottacloud\" 14 / Local Disk \\ \"local\" 15 / Mega \\ \"mega\" 16 / Microsoft Azure Blob Storage \\ \"azureblob\" 17 / Microsoft OneDrive \\ \"onedrive\" 18 / OpenDrive \\ \"opendrive\" 19 / Openstack Swift ( Rackspace Cloud Files, Memset Memstore, OVH ) \\ \"swift\" 20 / Pcloud \\ \"pcloud\" 21 / QingCloud Object Storage \\ \"qingstor\" 22 / SSH/SFTP Connection \\ \"sftp\" 23 / Webdav \\ \"webdav\" 24 / Yandex Disk \\ \"yandex\" 25 / http Connection \\ \"http\" Storage> 5 For client id and client secret, we will leave it blank (press ENTER for each) to designate that we want to enter it manually when we run it, as opposed to saving our credentials somewhere. Box App Client Id. Leave blank normally. Enter a string value. Press Enter for the default ( \"\" ) . client_id> Box App Client Secret Leave blank normally. Enter a string value. Press Enter for the default ( \"\" ) . client_secret> Finally, it will ask you if you want to edit the Advanced config. You can say no (n). Edit advanced config? ( y/n ) y ) Yes n ) No y/n> n And finally, since you are working on a remote and headless machine (Sherlock), you should say no to the next answer. Remote config Use auto config? * Say Y if not sure * Say N if you are working on a remote or headless machine y ) Yes n ) No y/n> n","title":"Remotes"},{"location":"docs/software/using/rclone/#authentication","text":"The next part is important, because we need to open a separate terminal (one where we have a web browser available) to enter result asked for here. If you have a Mac, you can select Shell -> New Window -> New Window with Profile . If you have another flavor of Linux (or Windows) then you will need to install rclone locally and then issue this command: $ rclone authorize \"box\" A website will open for you to log in with your cloud provider (e.g., Box), and after login, it will tell you to return to your terminal: Success! All done . Please go back to rclone. Back in the (second terminal, not the one on Sherlock) you will see a message (that you might have previously missed) about the browser opening, waiting for a code, and then you will get the code (replaced below with xxxxxxxx): If your browser doesn ' t open automatically go to the following link: http://127.0.0.1:53682/auth Log in and authorize rclone for access Waiting for code... Got code Paste the following into your remote machine ---> { \"access_token\" : \"xxxxxxxxxxxxxx\" , \"token_type\" : \"bearer\" , \"refresh_token\" : \"xxxxxxxxxx\" , \"expiry\" : \"2019-xx-xxxxxxxx\" } ( ---End paste You need to copy the entire thing between the two brackets \"{}\" back into the first terminal running on Sherlock, which will be showing this: For this to work, you will need rclone available on a machine that has a web browser available. Execute the following on your machine: rclone authorize \"box\" Then paste the result below: result> After you paste, it will then ask you if it looks ok, and you can type Y for yes. [ VanessaSherlockToBox ] type = box token = { xxxxxxxxxxxxxxxxxxx } -------------------- y ) Yes this is OK e ) Edit this remote d ) Delete this remote And close up with a listing of your current remotes. You can quit Q after this, because next we will test our setup. Current remotes: Name Type ==== ==== VanessaSherlockToBox box e ) Edit existing remote n ) New remote d ) Delete remote r ) Rename remote c ) Copy remote s ) Set configuration password q ) Quit config e/n/d/r/c/s/q> q","title":"Authentication"},{"location":"docs/software/using/rclone/#testing","text":"Did it work? Let's test listing files for our remote to see (filenames below are made up). $ rclone lsd VanessaSherlockToBox: --max-depth 1 -1 2018 -08-09 09 :52:01 -1 pancakes -1 2019 -03-13 23 :33:03 -1 miracles -1 2019 -03-06 09 :42:39 -1 alaska -1 2018 -02-06 02 :37:40 -1 share Next, let's copy a file to Sherlock. # rclone copy <remote>:<cloud storage path> <sherlock path> $ rclone copy VanessaSherlockToBox:pancakes /scratch/users/vsochat/pancakes There you go! If you want to interactively browse files, you can use the File Manager on the Sherlock OnDemand interface.","title":"Testing"},{"location":"docs/software/using/singularity/","text":"Singularity is a tool for running containers on HPC systems, similar to Docker . Introduction # Containers are a solution to the problem of how to get software to run reliably when moved from one computing environment to another. They also resolve installation problems by packaging all the dependencies of an application within a self-sustainable image, a.k.a a container. What's a container? Put simply, a container consists of an entire runtime environment: an application, plus all its dependencies, libraries and other binaries, and configuration files needed to run it, bundled into one package. By containerizing the application platform and its dependencies, differences in OS distributions and underlying infrastructure are abstracted away. Why not Docker? # Docker has long been the reference and the most popular container framework in DevOps and Enterprise IT environments, so why not use Docker on Sherlock? Well, for a variety of technical reasons, mostly related to security. Docker has never been designed nor developed to run in multi-tenants environments, and even less on HPC clusters. Specifically: Docker requires a daemon running as root on all of the compute nodes, which has serious security implications, all authenticated actions (such as login , push ...) are also executed as root , meaning that multiple users can't use those functions on the same node, Docker uses cgroups to isolate containers, as does the Slurm scheduler, which uses cgroups to allocate resources to jobs and enforce limits. Those uses are unfortunately conflicting. but most importantly, allowing users to run Docker containers will give them root privileges inside that container, which will in turn let them access any of the clusters' filesystems as root . This opens the door to user impersonation, inappropriate file tampering or stealing, and is obviously not something that can be allowed on a shared resource. That last point is certainly the single most important reason why we won't use Docker on Sherlock. Why Singularity? # Singularity is Docker for HPC systems Singularity allows running Docker containers natively , and is a perfect replacement for Docker on HPC systems such as Sherlock. That means that existing Docker container can be directly imported and natively run with SIngularity. Despite Docker's shortcomings on HPC systems, the appeal of containers for scientific computing is undeniable, which is why we provide Singularity on Sherlock. Singularity is an alternative container framework, especially designed to run scientific applications on HPC clusters. Singularity provides the same functionalities as Docker, without any of the drawbacks listed above. Using a completely different implementation, it doesn't require any privilege to run containers, and allow direct interaction with existing Docker containers. The main motivation to use Singularity over Docker is the fact that it's been developed with HPC systems in mind, to solve those specific problems: security: a user in the container is the same user as the one running the container, so no privilege escalation possible, ease of deployment: no daemon running as root on each node, a container is simply an executable, no need to mount filesystems or do bind mappings to access devices, ability to run MPI jobs based on containers, and more ... More documentation # The following documentation specifically intended for using Singularity on Sherlock. For more complete documentation about building and running containers with Singularity, please see the Singularity documentation . Singularity on Sherlock # As announced during the SC'18 Supercomputing Conference , Singularity is an integral part of the Sherlock cluster, and Singularity commands can be executed natively on any login or compute node, without the need to load any additional module. Importing containers # Pre-built containers can be obtained from a variety of sources. For instance: DockerHub contains containers for various software packages, which can be directly used with Singularity , SingularityHub is a registry for scientific linux containers, the NVIDIA GPU Cloud registry for GPU -optimized containers, many individual projects contain specific instructions for installation via Docker and/or Singularity, and may provide pre-built images in other locations. To illustrate how Singularity can import and run Docker containers, here's an example how to install and run the OpenFOAM CFD solver using Singularity. OpenFOAM can be quite difficult to install manually, but Singularity makes it very easy. Interactive or batch usage This example shows how to use Singularity interactively, but Singularity containers can be run in batch jobs as well. The first step is to request an interactive shell, and to load the singularity module. Singularity images can be pulled directly from the compute nodes, and Singularity uses multiple CPU cores when assembling the image, so requesting multiple cores in your job can make the pull operation faster: $ srun -c 4 --pty bash We recommend storing Singularity images in $GROUP_HOME , as container images can take significant space in your $HOME directory. $ mkdir -p $GROUP_HOME / $USER /simg $ cd $GROUP_HOME / $USER /simg Then, the OpenFOAM container could be pulled directly from DockerHub by Singularity. This can take a moment to complete: $ singularity pull docker://openfoam/openfoam6-paraview54 Docker image path: index.docker.io/openfoam/openfoam6-paraview54:latest Cache folder set to /scratch/users/kilian/.singularity/docker Importing: base Singularity environment Exploding layer: sha256:1be7f2b886e89a58e59c4e685fcc5905a26ddef3201f290b96f1eff7d778e122.tar.gz [ ... ] Building Singularity image... Singularity container built: ./openfoam6-paraview54.simg Cleaning up... Done. Container is at: ./openfoam6-paraview54.simg Running containers # Once the image is downloaded, you are ready to run OpenFOAM from the container. The singularity shell command can be used to start the container, and run a shell within that image: By default on Sherlock, all the filesystems that are available on the compute node will also be available in the container. If you want to start your shell in a specific directory, you can use the --pwd /path/ option. For instance, we'll create a /tmp/openfoam_test/ directory to store our tests results (that will be wiped out at the end of the job), and start the container shell there: $ mkdir /tmp/openfoam_test $ singularity shell --pwd /tmp/openfoam_test openfoam6-paraview54.simg Singularity: Invoking an interactive shell within container... Singularity openfoam6-paraview54.simg:/tmp/openfoam_test> You're now in the container, as denoted by the shell prompt ( Singularity[...].simg:[path]> ), which is different from the prompt displayed on the compute node (which usually looks like [login]@[compute_node] [path]$ . OpenFOAM provides a convenience script that can be sourced to make OpenFOAM commands directly accessible and set a few useful environment variables: > source /opt/openfoam6/etc/bashrc Now, we can run a simple example using OpenFOAM: > cp -r $FOAM_TUTORIALS /incompressible/simpleFoam/pitzDaily . > cd pitzDaily > blockMesh [ ... ] End > simpleFoam /*---------------------------------------------------------------------------* \\ ========= | \\\\ / F ield | OpenFOAM: The Open Source CFD Toolbox \\\\ / O peration | Website: https://openfoam.org \\\\ / A nd | Version: 6 \\\\ / M anipulation | \\* ---------------------------------------------------------------------------*/ Build : 6 -1a0c91b3baa8 Exec : simpleFoam Date : Oct 05 2018 Time : 23 :37:30 Host : \"sh01-06n33.int\" PID : 14670 I/O : uncollated Case : /tmp/openfoam_test/pitzDaily nProcs : 1 sigFpe : Enabling floating point exception trapping ( FOAM_SIGFPE ) . fileModificationChecking : Monitoring run-time modified files using timeStampMaster ( fileModificationSkew 10 ) allowSystemOperations : Allowing user-supplied system call operations // * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * // Create time [ ... ] SIMPLE solution converged in 288 iterations streamLine streamlines write: seeded 10 particles Tracks:10 Total samples:11980 Writing data to \"/tmp/openfoam_test/pitzDaily/postProcessing/sets/streamlines/288\" End > When the simulation is done, you can exit the container with: > exit Because the container can see all the compute node's filesystems, the simulation output will be available in /tmp/openfoam_test after you exit the container: $ ls /tmp/openfoam_test/pitzDaily/postProcessing/ sets GPU -enabled containers # Sherlock also supports the use of container images provided by NVIDIA in the NVIDIA GPU Cloud (NGC) . This registry provides GPU -accelerated containers for the most popular HPC and deep-learning scientific applications. GPU support Containers provided on NGC are only supported on Pascal and Volta architectures (TITAN Xp, Tesla P40, P100 or V100). For GPUs from the previous generations (GTX TITAN Black/X, Tesla K20/K80), things may or may not work. We recommend making sure to select a supported GPU generation by adding the following directive to your batch script when submitting a job to run GPU -enabled containers from NGC: #SBATCH -C \"GPU_GEN:PSC|GPU_GEN:VLT\" Pulling NGC images # As before, we start by requesting an interactive shell with multiple CPU cores, loading the Singularity module and moving the directory where we'll save those images: $ srun -c 4 --pty bash $ cd $GROUP_HOME /simg A GPU is not required for pulling GPU -enabled containers GPU -enabled containers can be pulled on any node, including nodes without a GPU . But their execution requires a GPU and thus, they need to be executed within a GPU job. See the GPU job section for more information. To be able to pull an image from NGC, authentication credentials must be set. Users need to register and create an NGC API key, complete details could be found in the NGC Getting Started Guide . You can then set the following environment variable to allow Singularity to authenticate with NGC: $ export SINGULARITY_DOCKER_USERNAME = '$oauthtoken' $ export SINGULARITY_DOCKER_PASSWORD = <NVIDIA NGC API key> Note The SINGULARITY_DOCKER_USERNAME environment variable must be set to the literal $oauthtoken string, for every user. It should not be replaced by anything else. Only the API key is specific to each user. Once credentials are set in the environment, container images can be pulled from the NGC registry normally. The general form of the Singularity command used to pull NGC containers is: $ singularity pull docker://nvcr.io/<registry>/<app:tag> For example to pull the NAMD NGC container tagged with version 2.12-171025 the corresponding command would be: $ singularity pull docker://nvcr.io/hpc/namd:2.12-171025 After this command has finished, we'll have a Singularity image file in the current directory, named namd-2.12-171025.simg . Running NGC containers # Instructions about running NGC containers are provided on the NGC website, under each application: Each application comes with specific running instructions, so we recommend to follow the container's particular guidelines before running it with Singularity. Containers that lack Singularity documentation have not been tested with Singularity. Since all NGC containers are optimized for GPU acceleration, they will always be executed with the --nv Singularity option, to enable GPU support within the container. We also need to submit a job requesting a GPU to run GPU -enabled containers. For instance: $ srun -p gpu -c 4 --gres gpu:1 --pty bash This will start an interactive shell on a GPU node, with 4 CPU cores and 1 GPU . The NAMD container that was pulled just before can now be started with the following commands. We start by creating a temporary directory to hold the execution results, and start the container using this as the current directory: $ mkdir /tmp/namd_test $ singularity shell --nv --pwd /tmp/namd_test $GROUP_HOME /simg/namd-2.12-171025.simg Singularity: Invoking an interactive shell within container... Singularity namd-2.12-171025.simg:/tmp/namd_test> From there, we can run a NAMD test to verify that everything is working as expected. > cp -r /workspace/examples . > /opt/namd/namd-multicore +p4 +idlepoll examples/apoa1/apoa1.namd Charm++: standalone mode ( not using charmrun ) Charm++> Running in Multicore mode: 4 threads Charm++> Using recursive bisection ( scheme 3 ) for topology aware partitions Converse/Charm++ Commit ID: v6.8.2 [ ... ] Info: Built with CUDA version 9000 Did not find +devices i,j,k,... argument, using all Pe 1 physical rank 1 will use CUDA device of pe 2 Pe 3 physical rank 3 will use CUDA device of pe 2 Pe 0 physical rank 0 will use CUDA device of pe 2 Pe 2 physical rank 2 binding to CUDA device 0 on sh02-14n13.int: 'TITAN Xp' Mem: 12196MB Rev: 6 .1 Info: NAMD 2 .12 for Linux-x86_64-multicore-CUDA [ ... ] Info: SIMULATION PARAMETERS: Info: TIMESTEP 1 [ ... ] ENERGY: 2000 20247 .5090 20325 .4554 5719 .0088 183 .9328 -340639.3103 25366 .3986 0 .0000 0 .0000 46364 .9951 -222432.0107 168 .6631 -268797.0057 -222054.5175 168 .8733 -1129.9509 -1799.6459 921491 .4634 -2007.8380 -2007.4145 WRITING EXTENDED SYSTEM TO OUTPUT FILE AT STEP 2000 WRITING COORDINATES TO OUTPUT FILE AT STEP 2000 The last position output ( seq = -2 ) takes 0 .001 seconds, 559 .844 MB of memory in use WRITING VELOCITIES TO OUTPUT FILE AT STEP 2000 The last velocity output ( seq = -2 ) takes 0 .001 seconds, 559 .844 MB of memory in use ==================================================== WallClock: 17 .593451 CPUTime: 17 .497925 Memory: 559 .843750 MB [ Partition 0 ][ Node 0 ] End of program The simulation should take a few seconds to run. You can verify that it correctly executed on a GPU in the output above. When it's done, you can exit the container with: > exit Because the container can see all the compute node's filesystems, the simulation output will be available in /tmp/named_test after you exit the container: $ cd /tmp/namd_test/examples/apoa1/ $ ls apoa1-out* apoa1-out.coor apoa1-out.vel apoa1-out.xsc Building your own containers # Building Singularity containers requires root privileges, and as such, cannot be done on Sherlock directly. If you need to modify existing containers or build your own from scratch, The recommended workflow is to prepare and build your containers on your local Linux machine (it could either be a workstation, a laptop or a virtual machine), transfer the resulting container image to Sherlock, and run it there. For complete details about how to build Singularity containers, please refer to the Singularity documentation . For more information about using modules on Sherlock, please see the software modules documentation . \u21a9","title":"Singularity"},{"location":"docs/software/using/singularity/#introduction","text":"Containers are a solution to the problem of how to get software to run reliably when moved from one computing environment to another. They also resolve installation problems by packaging all the dependencies of an application within a self-sustainable image, a.k.a a container. What's a container? Put simply, a container consists of an entire runtime environment: an application, plus all its dependencies, libraries and other binaries, and configuration files needed to run it, bundled into one package. By containerizing the application platform and its dependencies, differences in OS distributions and underlying infrastructure are abstracted away.","title":"Introduction"},{"location":"docs/software/using/singularity/#why-not-docker","text":"Docker has long been the reference and the most popular container framework in DevOps and Enterprise IT environments, so why not use Docker on Sherlock? Well, for a variety of technical reasons, mostly related to security. Docker has never been designed nor developed to run in multi-tenants environments, and even less on HPC clusters. Specifically: Docker requires a daemon running as root on all of the compute nodes, which has serious security implications, all authenticated actions (such as login , push ...) are also executed as root , meaning that multiple users can't use those functions on the same node, Docker uses cgroups to isolate containers, as does the Slurm scheduler, which uses cgroups to allocate resources to jobs and enforce limits. Those uses are unfortunately conflicting. but most importantly, allowing users to run Docker containers will give them root privileges inside that container, which will in turn let them access any of the clusters' filesystems as root . This opens the door to user impersonation, inappropriate file tampering or stealing, and is obviously not something that can be allowed on a shared resource. That last point is certainly the single most important reason why we won't use Docker on Sherlock.","title":"Why not Docker?"},{"location":"docs/software/using/singularity/#why-singularity","text":"Singularity is Docker for HPC systems Singularity allows running Docker containers natively , and is a perfect replacement for Docker on HPC systems such as Sherlock. That means that existing Docker container can be directly imported and natively run with SIngularity. Despite Docker's shortcomings on HPC systems, the appeal of containers for scientific computing is undeniable, which is why we provide Singularity on Sherlock. Singularity is an alternative container framework, especially designed to run scientific applications on HPC clusters. Singularity provides the same functionalities as Docker, without any of the drawbacks listed above. Using a completely different implementation, it doesn't require any privilege to run containers, and allow direct interaction with existing Docker containers. The main motivation to use Singularity over Docker is the fact that it's been developed with HPC systems in mind, to solve those specific problems: security: a user in the container is the same user as the one running the container, so no privilege escalation possible, ease of deployment: no daemon running as root on each node, a container is simply an executable, no need to mount filesystems or do bind mappings to access devices, ability to run MPI jobs based on containers, and more ...","title":"Why Singularity?"},{"location":"docs/software/using/singularity/#more-documentation","text":"The following documentation specifically intended for using Singularity on Sherlock. For more complete documentation about building and running containers with Singularity, please see the Singularity documentation .","title":"More documentation"},{"location":"docs/software/using/singularity/#singularity-on-sherlock","text":"As announced during the SC'18 Supercomputing Conference , Singularity is an integral part of the Sherlock cluster, and Singularity commands can be executed natively on any login or compute node, without the need to load any additional module.","title":"Singularity on Sherlock"},{"location":"docs/software/using/singularity/#importing-containers","text":"Pre-built containers can be obtained from a variety of sources. For instance: DockerHub contains containers for various software packages, which can be directly used with Singularity , SingularityHub is a registry for scientific linux containers, the NVIDIA GPU Cloud registry for GPU -optimized containers, many individual projects contain specific instructions for installation via Docker and/or Singularity, and may provide pre-built images in other locations. To illustrate how Singularity can import and run Docker containers, here's an example how to install and run the OpenFOAM CFD solver using Singularity. OpenFOAM can be quite difficult to install manually, but Singularity makes it very easy. Interactive or batch usage This example shows how to use Singularity interactively, but Singularity containers can be run in batch jobs as well. The first step is to request an interactive shell, and to load the singularity module. Singularity images can be pulled directly from the compute nodes, and Singularity uses multiple CPU cores when assembling the image, so requesting multiple cores in your job can make the pull operation faster: $ srun -c 4 --pty bash We recommend storing Singularity images in $GROUP_HOME , as container images can take significant space in your $HOME directory. $ mkdir -p $GROUP_HOME / $USER /simg $ cd $GROUP_HOME / $USER /simg Then, the OpenFOAM container could be pulled directly from DockerHub by Singularity. This can take a moment to complete: $ singularity pull docker://openfoam/openfoam6-paraview54 Docker image path: index.docker.io/openfoam/openfoam6-paraview54:latest Cache folder set to /scratch/users/kilian/.singularity/docker Importing: base Singularity environment Exploding layer: sha256:1be7f2b886e89a58e59c4e685fcc5905a26ddef3201f290b96f1eff7d778e122.tar.gz [ ... ] Building Singularity image... Singularity container built: ./openfoam6-paraview54.simg Cleaning up... Done. Container is at: ./openfoam6-paraview54.simg","title":"Importing containers"},{"location":"docs/software/using/singularity/#running-containers","text":"Once the image is downloaded, you are ready to run OpenFOAM from the container. The singularity shell command can be used to start the container, and run a shell within that image: By default on Sherlock, all the filesystems that are available on the compute node will also be available in the container. If you want to start your shell in a specific directory, you can use the --pwd /path/ option. For instance, we'll create a /tmp/openfoam_test/ directory to store our tests results (that will be wiped out at the end of the job), and start the container shell there: $ mkdir /tmp/openfoam_test $ singularity shell --pwd /tmp/openfoam_test openfoam6-paraview54.simg Singularity: Invoking an interactive shell within container... Singularity openfoam6-paraview54.simg:/tmp/openfoam_test> You're now in the container, as denoted by the shell prompt ( Singularity[...].simg:[path]> ), which is different from the prompt displayed on the compute node (which usually looks like [login]@[compute_node] [path]$ . OpenFOAM provides a convenience script that can be sourced to make OpenFOAM commands directly accessible and set a few useful environment variables: > source /opt/openfoam6/etc/bashrc Now, we can run a simple example using OpenFOAM: > cp -r $FOAM_TUTORIALS /incompressible/simpleFoam/pitzDaily . > cd pitzDaily > blockMesh [ ... ] End > simpleFoam /*---------------------------------------------------------------------------* \\ ========= | \\\\ / F ield | OpenFOAM: The Open Source CFD Toolbox \\\\ / O peration | Website: https://openfoam.org \\\\ / A nd | Version: 6 \\\\ / M anipulation | \\* ---------------------------------------------------------------------------*/ Build : 6 -1a0c91b3baa8 Exec : simpleFoam Date : Oct 05 2018 Time : 23 :37:30 Host : \"sh01-06n33.int\" PID : 14670 I/O : uncollated Case : /tmp/openfoam_test/pitzDaily nProcs : 1 sigFpe : Enabling floating point exception trapping ( FOAM_SIGFPE ) . fileModificationChecking : Monitoring run-time modified files using timeStampMaster ( fileModificationSkew 10 ) allowSystemOperations : Allowing user-supplied system call operations // * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * // Create time [ ... ] SIMPLE solution converged in 288 iterations streamLine streamlines write: seeded 10 particles Tracks:10 Total samples:11980 Writing data to \"/tmp/openfoam_test/pitzDaily/postProcessing/sets/streamlines/288\" End > When the simulation is done, you can exit the container with: > exit Because the container can see all the compute node's filesystems, the simulation output will be available in /tmp/openfoam_test after you exit the container: $ ls /tmp/openfoam_test/pitzDaily/postProcessing/ sets","title":"Running containers"},{"location":"docs/software/using/singularity/#gpu-enabled-containers","text":"Sherlock also supports the use of container images provided by NVIDIA in the NVIDIA GPU Cloud (NGC) . This registry provides GPU -accelerated containers for the most popular HPC and deep-learning scientific applications. GPU support Containers provided on NGC are only supported on Pascal and Volta architectures (TITAN Xp, Tesla P40, P100 or V100). For GPUs from the previous generations (GTX TITAN Black/X, Tesla K20/K80), things may or may not work. We recommend making sure to select a supported GPU generation by adding the following directive to your batch script when submitting a job to run GPU -enabled containers from NGC: #SBATCH -C \"GPU_GEN:PSC|GPU_GEN:VLT\"","title":"GPU-enabled containers"},{"location":"docs/software/using/singularity/#pulling-ngc-images","text":"As before, we start by requesting an interactive shell with multiple CPU cores, loading the Singularity module and moving the directory where we'll save those images: $ srun -c 4 --pty bash $ cd $GROUP_HOME /simg A GPU is not required for pulling GPU -enabled containers GPU -enabled containers can be pulled on any node, including nodes without a GPU . But their execution requires a GPU and thus, they need to be executed within a GPU job. See the GPU job section for more information. To be able to pull an image from NGC, authentication credentials must be set. Users need to register and create an NGC API key, complete details could be found in the NGC Getting Started Guide . You can then set the following environment variable to allow Singularity to authenticate with NGC: $ export SINGULARITY_DOCKER_USERNAME = '$oauthtoken' $ export SINGULARITY_DOCKER_PASSWORD = <NVIDIA NGC API key> Note The SINGULARITY_DOCKER_USERNAME environment variable must be set to the literal $oauthtoken string, for every user. It should not be replaced by anything else. Only the API key is specific to each user. Once credentials are set in the environment, container images can be pulled from the NGC registry normally. The general form of the Singularity command used to pull NGC containers is: $ singularity pull docker://nvcr.io/<registry>/<app:tag> For example to pull the NAMD NGC container tagged with version 2.12-171025 the corresponding command would be: $ singularity pull docker://nvcr.io/hpc/namd:2.12-171025 After this command has finished, we'll have a Singularity image file in the current directory, named namd-2.12-171025.simg .","title":"Pulling NGC images"},{"location":"docs/software/using/singularity/#running-ngc-containers","text":"Instructions about running NGC containers are provided on the NGC website, under each application: Each application comes with specific running instructions, so we recommend to follow the container's particular guidelines before running it with Singularity. Containers that lack Singularity documentation have not been tested with Singularity. Since all NGC containers are optimized for GPU acceleration, they will always be executed with the --nv Singularity option, to enable GPU support within the container. We also need to submit a job requesting a GPU to run GPU -enabled containers. For instance: $ srun -p gpu -c 4 --gres gpu:1 --pty bash This will start an interactive shell on a GPU node, with 4 CPU cores and 1 GPU . The NAMD container that was pulled just before can now be started with the following commands. We start by creating a temporary directory to hold the execution results, and start the container using this as the current directory: $ mkdir /tmp/namd_test $ singularity shell --nv --pwd /tmp/namd_test $GROUP_HOME /simg/namd-2.12-171025.simg Singularity: Invoking an interactive shell within container... Singularity namd-2.12-171025.simg:/tmp/namd_test> From there, we can run a NAMD test to verify that everything is working as expected. > cp -r /workspace/examples . > /opt/namd/namd-multicore +p4 +idlepoll examples/apoa1/apoa1.namd Charm++: standalone mode ( not using charmrun ) Charm++> Running in Multicore mode: 4 threads Charm++> Using recursive bisection ( scheme 3 ) for topology aware partitions Converse/Charm++ Commit ID: v6.8.2 [ ... ] Info: Built with CUDA version 9000 Did not find +devices i,j,k,... argument, using all Pe 1 physical rank 1 will use CUDA device of pe 2 Pe 3 physical rank 3 will use CUDA device of pe 2 Pe 0 physical rank 0 will use CUDA device of pe 2 Pe 2 physical rank 2 binding to CUDA device 0 on sh02-14n13.int: 'TITAN Xp' Mem: 12196MB Rev: 6 .1 Info: NAMD 2 .12 for Linux-x86_64-multicore-CUDA [ ... ] Info: SIMULATION PARAMETERS: Info: TIMESTEP 1 [ ... ] ENERGY: 2000 20247 .5090 20325 .4554 5719 .0088 183 .9328 -340639.3103 25366 .3986 0 .0000 0 .0000 46364 .9951 -222432.0107 168 .6631 -268797.0057 -222054.5175 168 .8733 -1129.9509 -1799.6459 921491 .4634 -2007.8380 -2007.4145 WRITING EXTENDED SYSTEM TO OUTPUT FILE AT STEP 2000 WRITING COORDINATES TO OUTPUT FILE AT STEP 2000 The last position output ( seq = -2 ) takes 0 .001 seconds, 559 .844 MB of memory in use WRITING VELOCITIES TO OUTPUT FILE AT STEP 2000 The last velocity output ( seq = -2 ) takes 0 .001 seconds, 559 .844 MB of memory in use ==================================================== WallClock: 17 .593451 CPUTime: 17 .497925 Memory: 559 .843750 MB [ Partition 0 ][ Node 0 ] End of program The simulation should take a few seconds to run. You can verify that it correctly executed on a GPU in the output above. When it's done, you can exit the container with: > exit Because the container can see all the compute node's filesystems, the simulation output will be available in /tmp/named_test after you exit the container: $ cd /tmp/namd_test/examples/apoa1/ $ ls apoa1-out* apoa1-out.coor apoa1-out.vel apoa1-out.xsc","title":"Running NGC containers"},{"location":"docs/software/using/singularity/#building-your-own-containers","text":"Building Singularity containers requires root privileges, and as such, cannot be done on Sherlock directly. If you need to modify existing containers or build your own from scratch, The recommended workflow is to prepare and build your containers on your local Linux machine (it could either be a workstation, a laptop or a virtual machine), transfer the resulting container image to Sherlock, and run it there. For complete details about how to build Singularity containers, please refer to the Singularity documentation . For more information about using modules on Sherlock, please see the software modules documentation . \u21a9","title":"Building your own containers"},{"location":"docs/software/using/spark/","text":"Introduction # Apache Spark\u2122 is a general engine for large-scale data processing. This document gives a quick introduction how to get a first test program in Spark running on Sherlock. More documentation # The following documentation specifically intended for using Spark on Sherlock. For more complete documentation about Spark in general, please see the Apache Spark documentation . Spark on Sherlock # Running Apache Spark on Sherlock is a bit different from using a traditional Spark/Hadoop cluster in that it requires some level of integration with the scheduler. In a sense, the computing resources (memory and CPU ) need to be allocated twice. First, sufficient resources for the Spark application need to be allocated via Slurm ; and secondly, spark-submit resource allocation flags need to be properly specified. In order to use Spark, three steps have to be kept in mind when submitting a job to the queuing system: a new Spark cluster has to be started on the allocated nodes once the Spark cluster is up and running, Spark jobs have to be submitted to the cluster after all Spark jobs have finished running, the cluster has to be shut down The following scripts show how to implement these three steps, and use the Pi Monte-Carlo calculation as an example. Single-node job # In this example, all the Spark processes run on the same compute node , which makes for a fairly simply sbatch script. The following example will start a 8-core job on a single node, and run a Spark task within that allocation: #!/bin/bash #SBATCH --job-name=spark_singlenode #SBATCH --nodes=1 #SBATCH --cpus-per-task=8 #SBATCH --time=10 module load spark # This syntax tells spark to use all cpu cores on the node. export MASTER = \"local[*]\" # This is a Scala example run-example SparkPi 1000 # This is a Python example. spark-submit --master $MASTER $SPARK_HOME /examples/src/main/python/pi.py 1000 Multi-node job # To start a Spark cluster and run a task on multiple nodes, more preliminary steps are necessary. Here's an example script that will span 2 nodes, start 2 Spark workers on each node, and allow each worker to use 8 cores: #!/bin/bash #SBATCH --nodes=2 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=8 #SBATCH --ntasks-per-node=2 #SBATCH --output=sparkjob-%j.out ## -------------------------------------- ## 0. Preparation ## -------------------------------------- # load the Spark module module load spark # identify the Spark cluster with the Slurm jobid export SPARK_IDENT_STRING = $SLURM_JOBID # prepare directories export SPARK_WORKER_DIR = ${ SPARK_WORKER_DIR :- $HOME /.spark/worker } export SPARK_LOG_DIR = ${ SPARK_LOG_DIR :- $HOME /.spark/logs } export SPARK_LOCAL_DIRS = ${ SPARK_LOCAL_DIRS :- /tmp/spark } mkdir -p $SPARK_LOG_DIR $SPARK_WORKER_DIR ## -------------------------------------- ## 1. Start the Spark cluster master ## -------------------------------------- start-master.sh sleep 1 MASTER_URL = $( grep -Po '(?=spark://).*' \\ $SPARK_LOG_DIR /spark- ${ SPARK_IDENT_STRING } -org.*master*.out ) ## -------------------------------------- ## 2. Start the Spark cluster workers ## -------------------------------------- # get the resource details from the Slurm job export SPARK_WORKER_CORES = ${ SLURM_CPUS_PER_TASK :- 1 } export SPARK_MEM = $(( ${ SLURM_MEM_PER_CPU :- 4096 } * ${ SLURM_CPUS_PER_TASK :- 1 } )) M export SPARK_DAEMON_MEMORY = $SPARK_MEM export SPARK_WORKER_MEMORY = $SPARK_MEM export SPARK_EXECUTOR_MEMORY = $SPARK_MEM # start the workers on each node allocated to the tjob export SPARK_NO_DAEMONIZE = 1 srun --output = $SPARK_LOG_DIR /spark-%j-workers.out --label \\ start-slave.sh ${ MASTER_URL } & ## -------------------------------------- ## 3. Submit a task to the Spark cluster ## -------------------------------------- spark-submit --master ${ MASTER_URL } \\ --total-executor-cores $(( SLURM_NTASKS * SLURM_CPUS_PER_TASK )) \\ $SPARK_HOME /examples/src/main/python/pi.py 10000 ## -------------------------------------- ## 4. Clean up ## -------------------------------------- # stop the workers scancel ${ SLURM_JOBID } .0 # stop the master stop-master.sh","title":"Spark"},{"location":"docs/software/using/spark/#introduction","text":"Apache Spark\u2122 is a general engine for large-scale data processing. This document gives a quick introduction how to get a first test program in Spark running on Sherlock.","title":"Introduction"},{"location":"docs/software/using/spark/#more-documentation","text":"The following documentation specifically intended for using Spark on Sherlock. For more complete documentation about Spark in general, please see the Apache Spark documentation .","title":"More documentation"},{"location":"docs/software/using/spark/#spark-on-sherlock","text":"Running Apache Spark on Sherlock is a bit different from using a traditional Spark/Hadoop cluster in that it requires some level of integration with the scheduler. In a sense, the computing resources (memory and CPU ) need to be allocated twice. First, sufficient resources for the Spark application need to be allocated via Slurm ; and secondly, spark-submit resource allocation flags need to be properly specified. In order to use Spark, three steps have to be kept in mind when submitting a job to the queuing system: a new Spark cluster has to be started on the allocated nodes once the Spark cluster is up and running, Spark jobs have to be submitted to the cluster after all Spark jobs have finished running, the cluster has to be shut down The following scripts show how to implement these three steps, and use the Pi Monte-Carlo calculation as an example.","title":"Spark on Sherlock"},{"location":"docs/software/using/spark/#single-node-job","text":"In this example, all the Spark processes run on the same compute node , which makes for a fairly simply sbatch script. The following example will start a 8-core job on a single node, and run a Spark task within that allocation: #!/bin/bash #SBATCH --job-name=spark_singlenode #SBATCH --nodes=1 #SBATCH --cpus-per-task=8 #SBATCH --time=10 module load spark # This syntax tells spark to use all cpu cores on the node. export MASTER = \"local[*]\" # This is a Scala example run-example SparkPi 1000 # This is a Python example. spark-submit --master $MASTER $SPARK_HOME /examples/src/main/python/pi.py 1000","title":"Single-node job"},{"location":"docs/software/using/spark/#multi-node-job","text":"To start a Spark cluster and run a task on multiple nodes, more preliminary steps are necessary. Here's an example script that will span 2 nodes, start 2 Spark workers on each node, and allow each worker to use 8 cores: #!/bin/bash #SBATCH --nodes=2 #SBATCH --mem-per-cpu=4G #SBATCH --cpus-per-task=8 #SBATCH --ntasks-per-node=2 #SBATCH --output=sparkjob-%j.out ## -------------------------------------- ## 0. Preparation ## -------------------------------------- # load the Spark module module load spark # identify the Spark cluster with the Slurm jobid export SPARK_IDENT_STRING = $SLURM_JOBID # prepare directories export SPARK_WORKER_DIR = ${ SPARK_WORKER_DIR :- $HOME /.spark/worker } export SPARK_LOG_DIR = ${ SPARK_LOG_DIR :- $HOME /.spark/logs } export SPARK_LOCAL_DIRS = ${ SPARK_LOCAL_DIRS :- /tmp/spark } mkdir -p $SPARK_LOG_DIR $SPARK_WORKER_DIR ## -------------------------------------- ## 1. Start the Spark cluster master ## -------------------------------------- start-master.sh sleep 1 MASTER_URL = $( grep -Po '(?=spark://).*' \\ $SPARK_LOG_DIR /spark- ${ SPARK_IDENT_STRING } -org.*master*.out ) ## -------------------------------------- ## 2. Start the Spark cluster workers ## -------------------------------------- # get the resource details from the Slurm job export SPARK_WORKER_CORES = ${ SLURM_CPUS_PER_TASK :- 1 } export SPARK_MEM = $(( ${ SLURM_MEM_PER_CPU :- 4096 } * ${ SLURM_CPUS_PER_TASK :- 1 } )) M export SPARK_DAEMON_MEMORY = $SPARK_MEM export SPARK_WORKER_MEMORY = $SPARK_MEM export SPARK_EXECUTOR_MEMORY = $SPARK_MEM # start the workers on each node allocated to the tjob export SPARK_NO_DAEMONIZE = 1 srun --output = $SPARK_LOG_DIR /spark-%j-workers.out --label \\ start-slave.sh ${ MASTER_URL } & ## -------------------------------------- ## 3. Submit a task to the Spark cluster ## -------------------------------------- spark-submit --master ${ MASTER_URL } \\ --total-executor-cores $(( SLURM_NTASKS * SLURM_CPUS_PER_TASK )) \\ $SPARK_HOME /examples/src/main/python/pi.py 10000 ## -------------------------------------- ## 4. Clean up ## -------------------------------------- # stop the workers scancel ${ SLURM_JOBID } .0 # stop the master stop-master.sh","title":"Multi-node job"},{"location":"docs/storage/data-protection/","text":"Data protection is mostly a task for the user Except for $HOME and $GROUP_HOME , data on Sherlock is not backed up, nor archived. It's up to each user and group to make sure they maintain multiple copies of their data if needed. Snapshots # File system snapshots represent the state of the file system at a particular point in time. They allow accessing the file system contents as it was a different times in the past, and get back data that may have been deleted or modified since the snapshot was taken. Important Snapshots are only available on $HOME and $GROUP_HOME . Accessing snapshots # Snapshots taken in $HOME and $GROUP_HOME are accessible in a .snapshot directory at any level of the hierarchy. Those .snapshot directories don't appear when listing directory contents with ls , but they can be listed explicitly or accessed with cd : $ cd $HOME $ ls -ald .snapshot/users* [ ... ] drwx------ 118 sunetid group 6680 Jul 21 11 :16 .snapshot/users.daily.20170721 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.daily.20170722 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.daily.20170723 drwx------ 118 sunetid group 6702 Jul 24 10 :57 .snapshot/users.daily.20170724 drwx------ 118 sunetid group 6702 Jul 24 10 :57 .snapshot/users.daily.latest drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.hourly.20170722-16:00 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.hourly.20170722-17:00 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.hourly.20170722-18:00 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.hourly.20170722-19:00 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.hourly.20170722-20:00 [ ... ] $ cd .snapshot/users.daily.latest For instance: the $HOME/.snapshot/users.daily.latest directory is the latest daily snapshot available, and stores the contents of the $HOME directory as they were when the last daily snapshot was taken, the $HOME/foo/.snapshot/users.hourly.20170722-18:00 can be used to retrieve the contents of the $HOME/foo directory as it was at 6pm on July 22th, 2017. Restoring from a snapshot # If you deleted a file or modified it and want to restore an earlier version, you can simply copy the file from its saved version in the appropriate snapshot. Examples: to restore the last known version of $HOME/foo/bar : $ cp $HOME /foo/.snapshot/users.hourly.latest/bar $HOME /foo/bar or $ cp $HOME /.snapshot/foo/users.hourly.latest/bar $HOME /foo/bar (both commands are equivalent) to restore your ~/.bashrc file from 2 days ago: $ SNAP_DATE = $( date +%Y%m%d -d \"2 days ago\" ) $ cp $HOME /.snapshot/users.daily. ${ SNAP_DATE } /.bashrc $HOME /.bashrc Snapshot policy # The current 1 policy is to take snapshots on an hourly, daily and weekly basis. Older snapshots automatically expire after their retention period. The snapshot policy applies to both $HOME and $GROUP_HOME storage spaces. Snapshot frequency Retention period Number of snapshots hourly 2 days 48 daily 1 week 7 weekly 1 month 4 The shortest interval between snapshots is an hour. That means that if you create a file and then delete it within the hour, it won't appear in snapshots, and you won't be able to restore it. If a file exists for more than an hour, and is then deleted, it will be present in the hourly snapshots for the next 48 hours, and you'll be able to retrieve it during that period. Similarly, if a file exists for more than a day, it could be restored for up to 7 days. Snapshots don't count towards your quota. Snapshots, as well as the entire filesystem, are replicated to an off-site system, to ensure that data could be retrieved even in case of a catastrophic failure of the whole system or datacenter-level disaster. Backups # Although the SRCC doesn't offer any backup service per se , we do provide all the tools required to transfer data in and out of Sherlock. Suggested options to backup your data include: Oak , SRCC 's long-term research data storage service ( Recommended ) University IT Storage options and backup services Cloud storage providers (see the Data transfer page for information about the tools we provide to transfer files to/from the cloud) The snapshot policy is subject to change and may be adjusted as the storage system usage conditions evolve. \u21a9","title":"Data protection"},{"location":"docs/storage/data-protection/#snapshots","text":"File system snapshots represent the state of the file system at a particular point in time. They allow accessing the file system contents as it was a different times in the past, and get back data that may have been deleted or modified since the snapshot was taken. Important Snapshots are only available on $HOME and $GROUP_HOME .","title":"Snapshots"},{"location":"docs/storage/data-protection/#accessing-snapshots","text":"Snapshots taken in $HOME and $GROUP_HOME are accessible in a .snapshot directory at any level of the hierarchy. Those .snapshot directories don't appear when listing directory contents with ls , but they can be listed explicitly or accessed with cd : $ cd $HOME $ ls -ald .snapshot/users* [ ... ] drwx------ 118 sunetid group 6680 Jul 21 11 :16 .snapshot/users.daily.20170721 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.daily.20170722 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.daily.20170723 drwx------ 118 sunetid group 6702 Jul 24 10 :57 .snapshot/users.daily.20170724 drwx------ 118 sunetid group 6702 Jul 24 10 :57 .snapshot/users.daily.latest drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.hourly.20170722-16:00 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.hourly.20170722-17:00 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.hourly.20170722-18:00 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.hourly.20170722-19:00 drwx------ 118 sunetid group 6702 Jul 21 16 :19 .snapshot/users.hourly.20170722-20:00 [ ... ] $ cd .snapshot/users.daily.latest For instance: the $HOME/.snapshot/users.daily.latest directory is the latest daily snapshot available, and stores the contents of the $HOME directory as they were when the last daily snapshot was taken, the $HOME/foo/.snapshot/users.hourly.20170722-18:00 can be used to retrieve the contents of the $HOME/foo directory as it was at 6pm on July 22th, 2017.","title":"Accessing snapshots"},{"location":"docs/storage/data-protection/#restoring-from-a-snapshot","text":"If you deleted a file or modified it and want to restore an earlier version, you can simply copy the file from its saved version in the appropriate snapshot. Examples: to restore the last known version of $HOME/foo/bar : $ cp $HOME /foo/.snapshot/users.hourly.latest/bar $HOME /foo/bar or $ cp $HOME /.snapshot/foo/users.hourly.latest/bar $HOME /foo/bar (both commands are equivalent) to restore your ~/.bashrc file from 2 days ago: $ SNAP_DATE = $( date +%Y%m%d -d \"2 days ago\" ) $ cp $HOME /.snapshot/users.daily. ${ SNAP_DATE } /.bashrc $HOME /.bashrc","title":"Restoring from a snapshot"},{"location":"docs/storage/data-protection/#snapshot-policy","text":"The current 1 policy is to take snapshots on an hourly, daily and weekly basis. Older snapshots automatically expire after their retention period. The snapshot policy applies to both $HOME and $GROUP_HOME storage spaces. Snapshot frequency Retention period Number of snapshots hourly 2 days 48 daily 1 week 7 weekly 1 month 4 The shortest interval between snapshots is an hour. That means that if you create a file and then delete it within the hour, it won't appear in snapshots, and you won't be able to restore it. If a file exists for more than an hour, and is then deleted, it will be present in the hourly snapshots for the next 48 hours, and you'll be able to retrieve it during that period. Similarly, if a file exists for more than a day, it could be restored for up to 7 days. Snapshots don't count towards your quota. Snapshots, as well as the entire filesystem, are replicated to an off-site system, to ensure that data could be retrieved even in case of a catastrophic failure of the whole system or datacenter-level disaster.","title":"Snapshot policy"},{"location":"docs/storage/data-protection/#backups","text":"Although the SRCC doesn't offer any backup service per se , we do provide all the tools required to transfer data in and out of Sherlock. Suggested options to backup your data include: Oak , SRCC 's long-term research data storage service ( Recommended ) University IT Storage options and backup services Cloud storage providers (see the Data transfer page for information about the tools we provide to transfer files to/from the cloud) The snapshot policy is subject to change and may be adjusted as the storage system usage conditions evolve. \u21a9","title":"Backups"},{"location":"docs/storage/data-sharing/","text":"The following sections present and detail options to share data across users and groups on Sherlock. Sharing data locally on Sherlock # Traditional Unix permissions # Standard Unix file permissions are supported on Sherlock and provide read , write and execute permissions for the three distinct access classes. The access classes are defined as follows: Files and directories are owned by a user. The owner determines the file's user class . Distinct permissions apply to the owner. Files and directories are assigned a group, which define the file's group class . Distinct permissions apply to members of the file's group. The owner may be a member of the file's group. Users who are not the owner, nor a member of the group, comprise a file's others class . Distinct permissions apply to others. The following permissions apply to each class: The read permission grants the ability to read a file. When set for a directory, this permission grants the ability to read the names of files in the directory, but not to find out any further information about them such as contents, file type, size, ownership, permissions. The write permission grants the ability to modify a file. When set for a directory, this permission grants the ability to modify entries in the directory. This includes creating files, deleting files, and renaming files. The execute permission grants the ability to execute a file. This permission must be set for executable programs, including shell scripts, in order to allow the operating system to run them. When set for a directory, this permission grants the ability to access file contents and meta-information if its name is known, but not list files inside the directory, unless read is set also. Shared directories traversal If you need to give access to one of your files to another user, they will at least need execute permission on each directory within the path to that file. The effective permissions are determined based on the first class the user falls within in the order of user , group then others . For example, the user who is the owner of the file will have the permissions given to the user class regardless of the permissions assigned to the group class or others class. While traditional Unix permissions are sufficient in most cases to share files with all the users within the same group, they are not enough to share files with a specific subset of users, or with users from other groups. Access Control Lists (ACLs) can be used for that purpose. There are two type of ACLs supported on Sherlock depending on the underlying filesystem: Type Filesystems NFSv4 ACLs $HOME and $GROUP_HOME POSIX ACLs $SCRATCH , $GROUP_SCRATCH , $L_SCRATCH and $OAK POSIX ACLs # POSIX ACLs allows you to grant or deny access to files and directories for different users (or groups), independently of the file owner or group. Two types of POSIX ACLs can be defined: Access ACLs : grant permission for a specific file or directory. Default ACLs : allow to set a default set of ACLs that will be applied to any file or directory without any already defined ACL. Can only be set on directories. ACLs are set with the setfacl command, and displayed with getfacl . For more details and examples, please refer to this documentation . In the example below, we allow two users to access a restricted directory located at $GROUP_SCRATCH/restricted-dir/ : $ cd $GROUP_SCRATCH ### Create new directory $ mkdir restricted-dir ### Remove 'group' and 'other' access $ chmod g-rwx,o-rwx restricted-dir ### Give user bob read and traversal permissions to the directory $ setfacl -m u:bob:rX restricted-dir ### Use default ACLs (-d) to give user bob read access to all new ### files and sub-directories that will be created in \"restricted-dir\" $ setfacl -d -m u:bob:rX restricted-dir ### Give user alice read, write and traversal permissions for the directory $ setfacl -m u:alice:rwX restricted-dir ### Use default ACLs (-d) to give user alice read and write access to all ### new files and sub-directories $ setfacl -d -m u:alice:rwX restricted-dir ### Show ACLs $ getfacl restricted-dir # file: restricted-dir/ # owner: joe # group: grp # flags: -s- user::rwx user:bob:r-x group::--- mask::r-x other::--- default:user::rwx default:user:alice:rwx default:user:bob:r-x default:group::--- default:mask::rwx default:other::--- Default permissions on $GROUP_SCRATCH By default, the Unix permissions on the root directory $GROUP_SCRATCH don't allow read nor traversal access for others ( ie. any user not part of your PI group). If you need to share files with users outside of your own group, please contact us so we can set the appropriate permissions on your folder. For $SCRATCH , you're the owner of the directory and so you can change the permissions yourself. NFSv4 ACLs # $HOME and $GROUP_HOME also allow setting ACLs, albeit with different syntax and semantics than POSIX ACLs. The principle is very similar, though. An ACL in NFSv4 is a list of rules setting permissions on files or directories. A permission rule, or Access Control Entry (ACE), is of the form type:flags:principle:permissions . Commonly used entries for these fields are: type : A (allow) or D (deny) flags : g (group), d (directory-inherit), f (file-inherit), n (no-propagate-inherit), or i (inherit-only) principle : a named user ( user@sherlock ), a group, or one of three special principles: OWNER@ , GROUP@ , and EVERYONE@ . permissions : there are 14 permission characters, as well as the shortcuts R , W , and X . Here is a list of possible permissions that can be included in the permissions field (options are Case Sensitive) r read-data (files) / list-directory (directories) w write-data (files) / create-file (directories) x execute (files) / change-directory (directories) a append-data (files) / create-subdirectory (directories) t read-attributes: read the attributes of the file/directory. T write-attributes: write the attributes of the file/directory. n read-named-attributes: read the named attributes of the file/directory. N write-named-attributes: write the named attributes of the file/directory. c read-ACL: read the file/directory NFSv4 ACL. C write-ACL: write the file/directory NFSv4 ACL. o write-owner: change ownership of the file/directory. y synchronize: allow clients to use synchronous I/O with the server. d delete: delete the file/directory. Some servers will allow a delete to occur if either this permission is set in the file/directory or if the delete-child permission is set in its parent direcory. D delete-child: remove a file or subdirectory from within the given directory (directories only) A comprehensive listing of allowable field strings is given in the manual page nfs4_acl(5) To see what permissions are set on a particular file, use the nfs4_getfacl command. For example, newly created file1 may have default permissions listed by ls -l as -rw-r\u2014r\u2014 . Listing the permissions with nfs4_getfacl would display the following: $ nfs4_getfacl file1 A::OWNER@:rwatTnNcCoy A:g:GROUP@:rtncy A::EVERYONE@:rtncy To set permissions on a file, use the nfs4_setfacl command. For convenience, NFSv4 provides the shortcuts R , W and X for setting read, write, and execute permissions. For example, to add write permissions for the current group on file1 , use nfs4_setfacl with the -a switch: $ nfs4_setfacl -a A::GROUP@:W file1 This command switched the GROUP@ permission field from rtncy to rwatTnNcCoy . However, be aware that NFSv4 file permission shortcuts have a different meanings than the traditional Unix r , w , and x . For example issuing chmod g+w file1 will set GROUP@ to rwatncy . Although the shortcut permissions can be handy, often rules need to be more customized. Use nfs4_setfacl -e file1 to open the ACL for file1 in a text editor. Access Control Entries allow more fine grained control over file and directory permissions than does the chmod command. For example, if user joe wants to give read and write permissions to jack for her directory private , she would issue: $ nfs4_setfacl -R -a A::jack@sherlock:RW private/ The -R switch recursively applies the rule to the files and directories within private/ as well. To allow jack to create files and subdirectories within private/ with the permissions as granted above, inheritance rules need to be applied. $ nfs4_setfacl -R -a A:fdi:jack@sherlock:RW private/ By default, each permission is in the Deny state and an ACE is required to explicitly allow a permission. However, be aware that a server may silently override a users ACE, usually to a less permissive setting. For complete documentation and examples on using NFSv4 ACLs, please see the manual page at nfs4_acl(5) . Sharing data outside of Sherlock # If you'd like to share data stored on Sherlock with external collaborators, there are two possiblities: sponsor a SUNet ID 1 for these collaborators, and contact us us to create a account for them on Sherlock. This will grant them access to your resources on Sherlock (compute as well as storage) and give them access to your group shared files, like any other user in your group. if you don't want to grant full access to your Sherlock resources to your external collaborators, you can use the Globus data sharing feature. This won't require your collaborators to get Stanford accounts, and will allow easy sharing of the datasets of your choice. Globus Sharing is only available through the Oak endpoint Globus Sharing is only available on $OAK , using the Oak Globus Endpoint 2 ( srcc#oak ). For complete details about sharing data wih Globus, please see the Globus documentation at https://docs.globus.org/how-to/share-files/ a base-level SUNet ID (free) is sufficient to get an account on Sherlock. For more details about SUNet ID levels and associated services, please see the Stanford UIT SUNet IDs page . \u21a9 SUNet ID required \u21a9","title":"Data sharing"},{"location":"docs/storage/data-sharing/#sharing-data-locally-on-sherlock","text":"","title":"Sharing data locally on Sherlock"},{"location":"docs/storage/data-sharing/#traditional-unix-permissions","text":"Standard Unix file permissions are supported on Sherlock and provide read , write and execute permissions for the three distinct access classes. The access classes are defined as follows: Files and directories are owned by a user. The owner determines the file's user class . Distinct permissions apply to the owner. Files and directories are assigned a group, which define the file's group class . Distinct permissions apply to members of the file's group. The owner may be a member of the file's group. Users who are not the owner, nor a member of the group, comprise a file's others class . Distinct permissions apply to others. The following permissions apply to each class: The read permission grants the ability to read a file. When set for a directory, this permission grants the ability to read the names of files in the directory, but not to find out any further information about them such as contents, file type, size, ownership, permissions. The write permission grants the ability to modify a file. When set for a directory, this permission grants the ability to modify entries in the directory. This includes creating files, deleting files, and renaming files. The execute permission grants the ability to execute a file. This permission must be set for executable programs, including shell scripts, in order to allow the operating system to run them. When set for a directory, this permission grants the ability to access file contents and meta-information if its name is known, but not list files inside the directory, unless read is set also. Shared directories traversal If you need to give access to one of your files to another user, they will at least need execute permission on each directory within the path to that file. The effective permissions are determined based on the first class the user falls within in the order of user , group then others . For example, the user who is the owner of the file will have the permissions given to the user class regardless of the permissions assigned to the group class or others class. While traditional Unix permissions are sufficient in most cases to share files with all the users within the same group, they are not enough to share files with a specific subset of users, or with users from other groups. Access Control Lists (ACLs) can be used for that purpose. There are two type of ACLs supported on Sherlock depending on the underlying filesystem: Type Filesystems NFSv4 ACLs $HOME and $GROUP_HOME POSIX ACLs $SCRATCH , $GROUP_SCRATCH , $L_SCRATCH and $OAK","title":"Traditional Unix permissions"},{"location":"docs/storage/data-sharing/#posix-acls","text":"POSIX ACLs allows you to grant or deny access to files and directories for different users (or groups), independently of the file owner or group. Two types of POSIX ACLs can be defined: Access ACLs : grant permission for a specific file or directory. Default ACLs : allow to set a default set of ACLs that will be applied to any file or directory without any already defined ACL. Can only be set on directories. ACLs are set with the setfacl command, and displayed with getfacl . For more details and examples, please refer to this documentation . In the example below, we allow two users to access a restricted directory located at $GROUP_SCRATCH/restricted-dir/ : $ cd $GROUP_SCRATCH ### Create new directory $ mkdir restricted-dir ### Remove 'group' and 'other' access $ chmod g-rwx,o-rwx restricted-dir ### Give user bob read and traversal permissions to the directory $ setfacl -m u:bob:rX restricted-dir ### Use default ACLs (-d) to give user bob read access to all new ### files and sub-directories that will be created in \"restricted-dir\" $ setfacl -d -m u:bob:rX restricted-dir ### Give user alice read, write and traversal permissions for the directory $ setfacl -m u:alice:rwX restricted-dir ### Use default ACLs (-d) to give user alice read and write access to all ### new files and sub-directories $ setfacl -d -m u:alice:rwX restricted-dir ### Show ACLs $ getfacl restricted-dir # file: restricted-dir/ # owner: joe # group: grp # flags: -s- user::rwx user:bob:r-x group::--- mask::r-x other::--- default:user::rwx default:user:alice:rwx default:user:bob:r-x default:group::--- default:mask::rwx default:other::--- Default permissions on $GROUP_SCRATCH By default, the Unix permissions on the root directory $GROUP_SCRATCH don't allow read nor traversal access for others ( ie. any user not part of your PI group). If you need to share files with users outside of your own group, please contact us so we can set the appropriate permissions on your folder. For $SCRATCH , you're the owner of the directory and so you can change the permissions yourself.","title":"POSIX ACLs"},{"location":"docs/storage/data-sharing/#nfsv4-acls","text":"$HOME and $GROUP_HOME also allow setting ACLs, albeit with different syntax and semantics than POSIX ACLs. The principle is very similar, though. An ACL in NFSv4 is a list of rules setting permissions on files or directories. A permission rule, or Access Control Entry (ACE), is of the form type:flags:principle:permissions . Commonly used entries for these fields are: type : A (allow) or D (deny) flags : g (group), d (directory-inherit), f (file-inherit), n (no-propagate-inherit), or i (inherit-only) principle : a named user ( user@sherlock ), a group, or one of three special principles: OWNER@ , GROUP@ , and EVERYONE@ . permissions : there are 14 permission characters, as well as the shortcuts R , W , and X . Here is a list of possible permissions that can be included in the permissions field (options are Case Sensitive) r read-data (files) / list-directory (directories) w write-data (files) / create-file (directories) x execute (files) / change-directory (directories) a append-data (files) / create-subdirectory (directories) t read-attributes: read the attributes of the file/directory. T write-attributes: write the attributes of the file/directory. n read-named-attributes: read the named attributes of the file/directory. N write-named-attributes: write the named attributes of the file/directory. c read-ACL: read the file/directory NFSv4 ACL. C write-ACL: write the file/directory NFSv4 ACL. o write-owner: change ownership of the file/directory. y synchronize: allow clients to use synchronous I/O with the server. d delete: delete the file/directory. Some servers will allow a delete to occur if either this permission is set in the file/directory or if the delete-child permission is set in its parent direcory. D delete-child: remove a file or subdirectory from within the given directory (directories only) A comprehensive listing of allowable field strings is given in the manual page nfs4_acl(5) To see what permissions are set on a particular file, use the nfs4_getfacl command. For example, newly created file1 may have default permissions listed by ls -l as -rw-r\u2014r\u2014 . Listing the permissions with nfs4_getfacl would display the following: $ nfs4_getfacl file1 A::OWNER@:rwatTnNcCoy A:g:GROUP@:rtncy A::EVERYONE@:rtncy To set permissions on a file, use the nfs4_setfacl command. For convenience, NFSv4 provides the shortcuts R , W and X for setting read, write, and execute permissions. For example, to add write permissions for the current group on file1 , use nfs4_setfacl with the -a switch: $ nfs4_setfacl -a A::GROUP@:W file1 This command switched the GROUP@ permission field from rtncy to rwatTnNcCoy . However, be aware that NFSv4 file permission shortcuts have a different meanings than the traditional Unix r , w , and x . For example issuing chmod g+w file1 will set GROUP@ to rwatncy . Although the shortcut permissions can be handy, often rules need to be more customized. Use nfs4_setfacl -e file1 to open the ACL for file1 in a text editor. Access Control Entries allow more fine grained control over file and directory permissions than does the chmod command. For example, if user joe wants to give read and write permissions to jack for her directory private , she would issue: $ nfs4_setfacl -R -a A::jack@sherlock:RW private/ The -R switch recursively applies the rule to the files and directories within private/ as well. To allow jack to create files and subdirectories within private/ with the permissions as granted above, inheritance rules need to be applied. $ nfs4_setfacl -R -a A:fdi:jack@sherlock:RW private/ By default, each permission is in the Deny state and an ACE is required to explicitly allow a permission. However, be aware that a server may silently override a users ACE, usually to a less permissive setting. For complete documentation and examples on using NFSv4 ACLs, please see the manual page at nfs4_acl(5) .","title":"NFSv4 ACLs"},{"location":"docs/storage/data-sharing/#sharing-data-outside-of-sherlock","text":"If you'd like to share data stored on Sherlock with external collaborators, there are two possiblities: sponsor a SUNet ID 1 for these collaborators, and contact us us to create a account for them on Sherlock. This will grant them access to your resources on Sherlock (compute as well as storage) and give them access to your group shared files, like any other user in your group. if you don't want to grant full access to your Sherlock resources to your external collaborators, you can use the Globus data sharing feature. This won't require your collaborators to get Stanford accounts, and will allow easy sharing of the datasets of your choice. Globus Sharing is only available through the Oak endpoint Globus Sharing is only available on $OAK , using the Oak Globus Endpoint 2 ( srcc#oak ). For complete details about sharing data wih Globus, please see the Globus documentation at https://docs.globus.org/how-to/share-files/ a base-level SUNet ID (free) is sufficient to get an account on Sherlock. For more details about SUNet ID levels and associated services, please see the Stanford UIT SUNet IDs page . \u21a9 SUNet ID required \u21a9","title":"Sharing data outside of Sherlock"},{"location":"docs/storage/data-transfer/","text":"Transfer protocols # A number of methods allow transferring data in/out of Sherlock. For most cases, we recommend using SSH -based file transfer commands , such as scp , sftp , or rsync . They will provide the best performance for data transfers from and to campus. For large transfers, using DTNs is recommended Most casual data transfers could be done through the login nodes, by pointing your transfer tool to login.sherlock.stanford.edu . But because of resource limits on the login nodes, larger transfer may not work as expected. For transferring large amounts of data, Sherlock features a specific Data Transfer Node , with dedicated bandwidth, as well as a managed Globus endpoint , that can be used for scheduled, unattended data transfers. We also provide tools on Sherlock to transfer data to various Cloud providers , such as AWS, Google Drive, Dropbox, Box, etc. Prerequisites # Most of the commands detailed below require a terminal and an SSH client 1 on your local machine to launch commands. You'll need to start a terminal and type the given example commands at the prompt, omitting the initial $ character (it just indicates a command prompt, and then should not be typed in). Host keys # Upon your very first connection to Sherlock, you will be greeted by a warning such as : The authenticity of host 'login.sherlock.stanford.edu' can't be established. ECDSA key fingerprint is SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg. Are you sure you want to continue connecting (yes/no)? The same warning will be displayed if your try to connect to one of the Data Transfer Node ( DTN ) : The authenticity of host 'dtn.sherlock.stanford.edu' can't be established. ECDSA key fingerprint is SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg. Are you sure you want to continue connecting (yes/no)? This warning is normal: your SSH client warns you that it is the first time it sees that new computer. To make sure you are actually connecting to the right machine, you should compare the ECDSA key fingerprint shown in the message with one of the fingerprints below: Key type Key Fingerprint RSA SHA256:T1q1Tbq8k5XBD5PIxvlCfTxNMi1ORWwKNRPeZPXUfJA legacy format: f5:8f:01:46:d1:f9:66:5d:33:58:b4:82:d8:4a:34:41 ECDSA SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg legacy format: 70:4c:76:ea:ae:b2:0f:81:4b:9c:c6:5a:52:4c:7f:64 If they match, you can proceed and type \u2018yes\u2019. Your SSH program will then store that key and will verify it for every subsequent SSH connection, to make sure that the server you're connecting to is indeed Sherlock. Host keys warning # If you've connected to Sherlock 1.0 before, there's a good chance the Sherlock 1.0 keys were stored by your local SSH client. In that case, when connecting to Sherlock 2.0 using the sherlock.stanford.edu alias, you will be presented with the following message: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: POSSIBLE DNS SPOOFING DETECTED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ The RSA host key for sherlock.stanford.edu has changed, and the key for the corresponding IP address 171.66.97.101 is unknown. This could either mean that DNS SPOOFING is happening or the IP address for the host and its host key have changed at the same time. @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the RSA key sent by the remote host is SHA256:T1q1Tbq8k5XBD5PIxvlCfTxNMi1ORWwKNRPeZPXUfJA. Please contact your system administrator. You can just check that the SHA256 key listed in that warning message correctly matches the one listed in the table above, and if that's the case, you can safely remove the sherlock.stanford.edu entry from your ~/.ssh/known_hosts file with the following command on your local machine: $ ssh-keygen -R sherlock.stanford.edu and then connect again. You'll see the first-connection prompt mentioned above , and your SSH client will store the new keys for future connections. SSH -based protocols # User name In all the examples below, you'll need to replace <sunetid> by your actual SUNet ID. If you happen to use the same login name on your local machine, you can omit it. SCP (Secure Copy) # The easiest command to use to transfer files to/from Sherlock is scp . It works like the cp command, except it can work over the network to copy files from one computer to another, using the secure SSH protocol. The general syntax to copy a file to a remote server is: $ scp <source_file_path> <username>@<remote_host>:<destination_path>' For instance, the following command will copy the file named foo from your local machine to your home directory on Sherlock: $ scp foo <sunetid>@login.sherlock.stanford.edu: Note the : character, that separates the hostname from the destination path. Here, the destination path is empty, which will instruct scp to copy the file in your home directory. You can copy foo under a different name, or to another directory, with the following commands: $ scp foo <sunetid>@login.sherlock.stanford.edu:bar $ scp foo <sunetid>@login.sherlock.stanford.edu:~/subdir/baz To copy back files from Sherlock to your local machine, you just need to reverse the order of the arguments: $ scp <sunetid>@login.sherlock.stanford.edu:foo local_foo And finally, scp also support recursive copying of directories, with the -r option: $ scp -r dir/ <sunetid>@login.sherlock.stanford.edu:dir/ This will copy the dir/ directory and all of its contents in your home directory on Sherlock. SFTP (Secure File Transfer Protocol) # SFTP clients are interactive file transfer programs, similar to FTP, which perform all operations over an encrypted transport. A variety of graphical SFTP clients are available for different OSes: WinSCP SecureFX , Fetch 2 CyberDuck When setting up your connection to Sherlock in the above programs, use the following information: Hostname: login.sherlock.stanford.edu Port: 22 Username: SUNet ID Password: SUNet ID password OpenSSH also provides a command-line SFTP client, originally named sftp . To log in to Sherlock: $ sftp <sunetid>@login.sherlock.stanford.edu Connected to login.sherlock.stanford.edu. sftp> For more information about using the command-line SFTP client, you can refer to this tutorial for more details and examples. rsync # If you have complex hierarchies of files to transfer, or if you need to synchronize a set of files and directories between your local machine and Sherlock, rsync will be the best tool for the job. It will efficiently transfer and synchronize files across systems, by checking the timestamp and size of files. Which means that it won't re-transfer files that have not changed since the last transfer, and will complete faster. For instance, to transfer the whole ~/data/ folder tree from your local machine to your home directory on Sherlock, you can use the following command: $ rsync -a ~/data/ <sunetid>@login.sherlock.stanford.edu:data/ Note the slash ( / ) at the end of the directories name, which is important to instruct rsync to synchronize the whole directories. To get more information about the transfer rate and follow its progress, you can use additional options: $ rsync -avP ~/data/ <sunetid>@login.sherlock.stanford.edu:data/ sending incremental file list ./ file1 1,755,049 100% 2.01MB/s 0:00:00 (xfr#2, to-chk=226/240) file2 2,543,699 100% 2.48MB/s 0:00:00 (xfr#3, to-chk=225/240) file3 34,930,688 19% 72.62MB/s 0:00:08 [...] For more information about using the rsync , you can refer to this tutorial for more details and examples. SSHFS # Sometimes, moving files in and out of the cluster, and maintaining two copies of each of the files you work on, both on your local machine and on Sherlock, may be painful. Fortunately, Sherlock offers the ability to mount any of its filesystems to your local machine, using a secure and encrypted connection. With SSHFS, a FUSE-based filesystem implementation used to mount remote SSH -accessible filesystems, you can access your files on Sherlock as if they were locally stored on your own computer. This comes particularly handy when you need to access those files from an application that is not available on Sherlock, but that you already use or can install on your local machine. Like a data processing program that you have licensed for your own computer but can't use on Sherlock, a specific text editor that only runs on MacOS, or any data-intensive 3D rendering software that wouldn't work comfortably enough over a forwarded X11 connection. SSHFS is available for Linux , MacOS , and Windows . SSHFS on macOS SSHFS on macOS is known to try to automatically reconnect filesystem mounts after resuming from sleep or suspend, even without any valid credentials. As a result, it will generate a lot of failed connection attempts and likely make your IP address blacklisted on login nodes. Make sure to unmount your SSHFS drives before putting your macOS system to sleep to avoid this situation. For instance, on a Linux machine with SSHFS installed, you could mount your Sherlock home directory with the following commands: $ mkdir ~/sherlock_home $ sshfs <sunetid>@login.sherlock.stanford.edu:./ ~/sherlock_home And to unmount it: $ umount ~/sherlock_home For more information about using SSHFS on your local machine, you can refer to this tutorial for more details and examples. Globus # Globus improves SSH -based file transfer protocols by providing the following features: automates large data transfers, handles transient errors, and can resume failed transfers, simplifies the implementation of high-performance transfers between computing centers. Globus is a Software as a Service (SaaS) system that provides end-users with a browser interface to initiate data transfers between endpoints. Globus allows users to \"drag and drop\" files from one endpoint to another. Endpoints are terminals for data; they can be laptops or supercomputers, and anything in between. The Globus web service negotiates, monitors, and optimizes transfers through firewalls and across network address translation (NAT). Under certain circumstances, with high performance hardware transfer rates exceeding 1 GB/s are possible. For more information about Globus, please see the Globus documentation . Authentication # To use Globus, you will first need to authenticate at Globus.org . You can either sign up for a Globus account, or use your SUNet ID account for authentication to Globus (which will be required to authenticate to the Sherlock endpoint). To use your SUNet ID, choose \"Stanford University\" from the drop down menu at the Login page and follow the instructions from there. Transfer # Endpoint name The Globus endpoint name for Sherlock is SRCC Sherlock (aka srcc#sherlock ) You can use Globus to transfer data between your local workstation (e.g., your laptop or desktop) and Sherlock. In this workflow, you configure your local workstation as a Globus endpoint by installing the Globus Connect software. Log in to Globus.org Use the Manage Endpoints interface to \"add Globus Connect Personal\" as an endpoint (you'll need to install Globus Connect Personal on your local machine) Transfer Files , using your new workstation endpoint for one side of the transfer, and the Sherlock endpoint ( SRCC Sherlock ) on the other side. You can also transfer data between two remote endpoints, by choosing another endpoint you have access to instead of your local machine. CLI and API # Globus also provides a command-line interface (CLI) and application programming interface (API) as an alternative to its web interface. Please see the Globus CLI documentation and Globus API documentation for more details. Data Transfer Nodes (DTNs) # No shell The DTNs don't provide any interactive shell, so connecting via SSH directly won't work. It will only accept scp , sftp , rsync of bbcp connections. A pool of dedicated Data Transfer Nodes is available on Sherlock, to provide exclusive resources for large-scale data transfers. The main benefit of using it is that transfer tasks can't be disrupted by other users interactive tasks or filesystem access and I/O -related workloads on the login nodes. By using the Sherlock DTNs, you'll make sure that your data flows will go through a computer whose sole purpose is to move data around. It supports: SSH -based protocols (such as the ones described above ) BBCP Globus To transfer files via the DTNs, simply use dtn.sherlock.stanford.edu as a remote server hostname. For instance: $ scp foo <sunetid>@dtn.sherlock.stanford.edu:~/foo $HOME on DTNs One important difference to keep in mind when transferring files through the Sherlock DTNs is that the default destination path for files, unless specified, is the user $SCRATCH directory, not $HOME . That means that the following command: $ scp foo <sunetid>@dtn.sherlock.stanford.edu: will create the foo file in $SCRATCH/foo , and not in $HOME/foo . You can transfer file to your $HOME directory via the DTNs by specifying the full path as the destination: $ scp foo <sunetid>@dtn.sherlock.stanford.edu:$HOME/foo Cloud storage # If you need to backup some of your Sherlock files to cloud-based storage services, we also provide a set of utilities that can help. Google Drive # Google Drive storage for Stanford users Google Drive is free for educational institutions. Meaning you can get free and unlimited storage on Google Drive using your @stanford.edu account. See the University IT Google Drive page for more details. We provide the rclone tool on Sherlock to interact with Google Drive. You'll just need to load the rclone module to be able to use it to move your files from/to Google Drive: $ module load system rclone $ rclone --help Other services # If you need to access other cloud storage services, you can use rclone : it can be used to sync files and directories to and from Google Drive, Amazon S3, Box, Dropbox, Google Cloud Storage, Amazon Drive, Microsoft OneDrive and many more. $ ml load system rclone $ rclone -h For more details about how to use rclone , please see the official documentation . For more details, see the SSH clients page . \u21a9 Fetch is a commercial program, and is available as part of the Essential Stanford Software bundle. \u21a9","title":"Data transfer"},{"location":"docs/storage/data-transfer/#transfer-protocols","text":"A number of methods allow transferring data in/out of Sherlock. For most cases, we recommend using SSH -based file transfer commands , such as scp , sftp , or rsync . They will provide the best performance for data transfers from and to campus. For large transfers, using DTNs is recommended Most casual data transfers could be done through the login nodes, by pointing your transfer tool to login.sherlock.stanford.edu . But because of resource limits on the login nodes, larger transfer may not work as expected. For transferring large amounts of data, Sherlock features a specific Data Transfer Node , with dedicated bandwidth, as well as a managed Globus endpoint , that can be used for scheduled, unattended data transfers. We also provide tools on Sherlock to transfer data to various Cloud providers , such as AWS, Google Drive, Dropbox, Box, etc.","title":"Transfer protocols"},{"location":"docs/storage/data-transfer/#prerequisites","text":"Most of the commands detailed below require a terminal and an SSH client 1 on your local machine to launch commands. You'll need to start a terminal and type the given example commands at the prompt, omitting the initial $ character (it just indicates a command prompt, and then should not be typed in).","title":"Prerequisites"},{"location":"docs/storage/data-transfer/#host-keys","text":"Upon your very first connection to Sherlock, you will be greeted by a warning such as : The authenticity of host 'login.sherlock.stanford.edu' can't be established. ECDSA key fingerprint is SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg. Are you sure you want to continue connecting (yes/no)? The same warning will be displayed if your try to connect to one of the Data Transfer Node ( DTN ) : The authenticity of host 'dtn.sherlock.stanford.edu' can't be established. ECDSA key fingerprint is SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg. Are you sure you want to continue connecting (yes/no)? This warning is normal: your SSH client warns you that it is the first time it sees that new computer. To make sure you are actually connecting to the right machine, you should compare the ECDSA key fingerprint shown in the message with one of the fingerprints below: Key type Key Fingerprint RSA SHA256:T1q1Tbq8k5XBD5PIxvlCfTxNMi1ORWwKNRPeZPXUfJA legacy format: f5:8f:01:46:d1:f9:66:5d:33:58:b4:82:d8:4a:34:41 ECDSA SHA256:eB0bODKdaCWtPgv0pYozsdC5ckfcBFVOxeMwrNKdkmg legacy format: 70:4c:76:ea:ae:b2:0f:81:4b:9c:c6:5a:52:4c:7f:64 If they match, you can proceed and type \u2018yes\u2019. Your SSH program will then store that key and will verify it for every subsequent SSH connection, to make sure that the server you're connecting to is indeed Sherlock.","title":"Host keys"},{"location":"docs/storage/data-transfer/#host-keys-warning","text":"If you've connected to Sherlock 1.0 before, there's a good chance the Sherlock 1.0 keys were stored by your local SSH client. In that case, when connecting to Sherlock 2.0 using the sherlock.stanford.edu alias, you will be presented with the following message: @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: POSSIBLE DNS SPOOFING DETECTED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ The RSA host key for sherlock.stanford.edu has changed, and the key for the corresponding IP address 171.66.97.101 is unknown. This could either mean that DNS SPOOFING is happening or the IP address for the host and its host key have changed at the same time. @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the RSA key sent by the remote host is SHA256:T1q1Tbq8k5XBD5PIxvlCfTxNMi1ORWwKNRPeZPXUfJA. Please contact your system administrator. You can just check that the SHA256 key listed in that warning message correctly matches the one listed in the table above, and if that's the case, you can safely remove the sherlock.stanford.edu entry from your ~/.ssh/known_hosts file with the following command on your local machine: $ ssh-keygen -R sherlock.stanford.edu and then connect again. You'll see the first-connection prompt mentioned above , and your SSH client will store the new keys for future connections.","title":"Host keys warning"},{"location":"docs/storage/data-transfer/#ssh-based-protocols","text":"User name In all the examples below, you'll need to replace <sunetid> by your actual SUNet ID. If you happen to use the same login name on your local machine, you can omit it.","title":"SSH-based protocols"},{"location":"docs/storage/data-transfer/#scp-secure-copy","text":"The easiest command to use to transfer files to/from Sherlock is scp . It works like the cp command, except it can work over the network to copy files from one computer to another, using the secure SSH protocol. The general syntax to copy a file to a remote server is: $ scp <source_file_path> <username>@<remote_host>:<destination_path>' For instance, the following command will copy the file named foo from your local machine to your home directory on Sherlock: $ scp foo <sunetid>@login.sherlock.stanford.edu: Note the : character, that separates the hostname from the destination path. Here, the destination path is empty, which will instruct scp to copy the file in your home directory. You can copy foo under a different name, or to another directory, with the following commands: $ scp foo <sunetid>@login.sherlock.stanford.edu:bar $ scp foo <sunetid>@login.sherlock.stanford.edu:~/subdir/baz To copy back files from Sherlock to your local machine, you just need to reverse the order of the arguments: $ scp <sunetid>@login.sherlock.stanford.edu:foo local_foo And finally, scp also support recursive copying of directories, with the -r option: $ scp -r dir/ <sunetid>@login.sherlock.stanford.edu:dir/ This will copy the dir/ directory and all of its contents in your home directory on Sherlock.","title":"SCP (Secure Copy)"},{"location":"docs/storage/data-transfer/#sftp-secure-file-transfer-protocol","text":"SFTP clients are interactive file transfer programs, similar to FTP, which perform all operations over an encrypted transport. A variety of graphical SFTP clients are available for different OSes: WinSCP SecureFX , Fetch 2 CyberDuck When setting up your connection to Sherlock in the above programs, use the following information: Hostname: login.sherlock.stanford.edu Port: 22 Username: SUNet ID Password: SUNet ID password OpenSSH also provides a command-line SFTP client, originally named sftp . To log in to Sherlock: $ sftp <sunetid>@login.sherlock.stanford.edu Connected to login.sherlock.stanford.edu. sftp> For more information about using the command-line SFTP client, you can refer to this tutorial for more details and examples.","title":"SFTP (Secure File Transfer Protocol)"},{"location":"docs/storage/data-transfer/#rsync","text":"If you have complex hierarchies of files to transfer, or if you need to synchronize a set of files and directories between your local machine and Sherlock, rsync will be the best tool for the job. It will efficiently transfer and synchronize files across systems, by checking the timestamp and size of files. Which means that it won't re-transfer files that have not changed since the last transfer, and will complete faster. For instance, to transfer the whole ~/data/ folder tree from your local machine to your home directory on Sherlock, you can use the following command: $ rsync -a ~/data/ <sunetid>@login.sherlock.stanford.edu:data/ Note the slash ( / ) at the end of the directories name, which is important to instruct rsync to synchronize the whole directories. To get more information about the transfer rate and follow its progress, you can use additional options: $ rsync -avP ~/data/ <sunetid>@login.sherlock.stanford.edu:data/ sending incremental file list ./ file1 1,755,049 100% 2.01MB/s 0:00:00 (xfr#2, to-chk=226/240) file2 2,543,699 100% 2.48MB/s 0:00:00 (xfr#3, to-chk=225/240) file3 34,930,688 19% 72.62MB/s 0:00:08 [...] For more information about using the rsync , you can refer to this tutorial for more details and examples.","title":"rsync"},{"location":"docs/storage/data-transfer/#sshfs","text":"Sometimes, moving files in and out of the cluster, and maintaining two copies of each of the files you work on, both on your local machine and on Sherlock, may be painful. Fortunately, Sherlock offers the ability to mount any of its filesystems to your local machine, using a secure and encrypted connection. With SSHFS, a FUSE-based filesystem implementation used to mount remote SSH -accessible filesystems, you can access your files on Sherlock as if they were locally stored on your own computer. This comes particularly handy when you need to access those files from an application that is not available on Sherlock, but that you already use or can install on your local machine. Like a data processing program that you have licensed for your own computer but can't use on Sherlock, a specific text editor that only runs on MacOS, or any data-intensive 3D rendering software that wouldn't work comfortably enough over a forwarded X11 connection. SSHFS is available for Linux , MacOS , and Windows . SSHFS on macOS SSHFS on macOS is known to try to automatically reconnect filesystem mounts after resuming from sleep or suspend, even without any valid credentials. As a result, it will generate a lot of failed connection attempts and likely make your IP address blacklisted on login nodes. Make sure to unmount your SSHFS drives before putting your macOS system to sleep to avoid this situation. For instance, on a Linux machine with SSHFS installed, you could mount your Sherlock home directory with the following commands: $ mkdir ~/sherlock_home $ sshfs <sunetid>@login.sherlock.stanford.edu:./ ~/sherlock_home And to unmount it: $ umount ~/sherlock_home For more information about using SSHFS on your local machine, you can refer to this tutorial for more details and examples.","title":"SSHFS"},{"location":"docs/storage/data-transfer/#globus","text":"Globus improves SSH -based file transfer protocols by providing the following features: automates large data transfers, handles transient errors, and can resume failed transfers, simplifies the implementation of high-performance transfers between computing centers. Globus is a Software as a Service (SaaS) system that provides end-users with a browser interface to initiate data transfers between endpoints. Globus allows users to \"drag and drop\" files from one endpoint to another. Endpoints are terminals for data; they can be laptops or supercomputers, and anything in between. The Globus web service negotiates, monitors, and optimizes transfers through firewalls and across network address translation (NAT). Under certain circumstances, with high performance hardware transfer rates exceeding 1 GB/s are possible. For more information about Globus, please see the Globus documentation .","title":"Globus"},{"location":"docs/storage/data-transfer/#authentication","text":"To use Globus, you will first need to authenticate at Globus.org . You can either sign up for a Globus account, or use your SUNet ID account for authentication to Globus (which will be required to authenticate to the Sherlock endpoint). To use your SUNet ID, choose \"Stanford University\" from the drop down menu at the Login page and follow the instructions from there.","title":"Authentication"},{"location":"docs/storage/data-transfer/#transfer","text":"Endpoint name The Globus endpoint name for Sherlock is SRCC Sherlock (aka srcc#sherlock ) You can use Globus to transfer data between your local workstation (e.g., your laptop or desktop) and Sherlock. In this workflow, you configure your local workstation as a Globus endpoint by installing the Globus Connect software. Log in to Globus.org Use the Manage Endpoints interface to \"add Globus Connect Personal\" as an endpoint (you'll need to install Globus Connect Personal on your local machine) Transfer Files , using your new workstation endpoint for one side of the transfer, and the Sherlock endpoint ( SRCC Sherlock ) on the other side. You can also transfer data between two remote endpoints, by choosing another endpoint you have access to instead of your local machine.","title":"Transfer"},{"location":"docs/storage/data-transfer/#cli-and-api","text":"Globus also provides a command-line interface (CLI) and application programming interface (API) as an alternative to its web interface. Please see the Globus CLI documentation and Globus API documentation for more details.","title":"CLI and API"},{"location":"docs/storage/data-transfer/#data-transfer-nodes-dtns","text":"No shell The DTNs don't provide any interactive shell, so connecting via SSH directly won't work. It will only accept scp , sftp , rsync of bbcp connections. A pool of dedicated Data Transfer Nodes is available on Sherlock, to provide exclusive resources for large-scale data transfers. The main benefit of using it is that transfer tasks can't be disrupted by other users interactive tasks or filesystem access and I/O -related workloads on the login nodes. By using the Sherlock DTNs, you'll make sure that your data flows will go through a computer whose sole purpose is to move data around. It supports: SSH -based protocols (such as the ones described above ) BBCP Globus To transfer files via the DTNs, simply use dtn.sherlock.stanford.edu as a remote server hostname. For instance: $ scp foo <sunetid>@dtn.sherlock.stanford.edu:~/foo $HOME on DTNs One important difference to keep in mind when transferring files through the Sherlock DTNs is that the default destination path for files, unless specified, is the user $SCRATCH directory, not $HOME . That means that the following command: $ scp foo <sunetid>@dtn.sherlock.stanford.edu: will create the foo file in $SCRATCH/foo , and not in $HOME/foo . You can transfer file to your $HOME directory via the DTNs by specifying the full path as the destination: $ scp foo <sunetid>@dtn.sherlock.stanford.edu:$HOME/foo","title":"Data Transfer Nodes (DTNs)"},{"location":"docs/storage/data-transfer/#cloud-storage","text":"If you need to backup some of your Sherlock files to cloud-based storage services, we also provide a set of utilities that can help.","title":"Cloud storage"},{"location":"docs/storage/data-transfer/#google-drive","text":"Google Drive storage for Stanford users Google Drive is free for educational institutions. Meaning you can get free and unlimited storage on Google Drive using your @stanford.edu account. See the University IT Google Drive page for more details. We provide the rclone tool on Sherlock to interact with Google Drive. You'll just need to load the rclone module to be able to use it to move your files from/to Google Drive: $ module load system rclone $ rclone --help","title":"Google Drive"},{"location":"docs/storage/data-transfer/#other-services","text":"If you need to access other cloud storage services, you can use rclone : it can be used to sync files and directories to and from Google Drive, Amazon S3, Box, Dropbox, Google Cloud Storage, Amazon Drive, Microsoft OneDrive and many more. $ ml load system rclone $ rclone -h For more details about how to use rclone , please see the official documentation . For more details, see the SSH clients page . \u21a9 Fetch is a commercial program, and is available as part of the Essential Stanford Software bundle. \u21a9","title":"Other services"},{"location":"docs/storage/filesystems/","text":"The following sections describe the characteristics and best uses of each of the Sherlock's filesystems. $HOME # Summary $HOME is your home directory. It's the best place to keep your code and important data as it provides snapshots and off-site replication. It is not meant to host data that will be actively read and written to by compute jobs. Characteristics Type high speed, distributed NFS file system Quota 15 GB for the whole $HOME directory Snapshots yes (cf. Snapshots ) for more info) Backups off-site replication Purge policy not purged Scope all login and compute nodes Recommended usage # $HOME is best suited for personal configuration files, scripts, small reference files or datasets, source code and individual software installation When you log in, the system automatically sets the current working directory to $HOME : it's the location you'll end up when connecting to Sherlock. You can store your source code and build your executables there. We strongly recommend using $HOME to reference your home directory in scripts, rather than its explicit path. Checking quota usage # The sh_quota tool can be used to display quota usage on $HOME $ sh_quota -f HOME See the Checking Quotas section for more details. $GROUP_HOME # Summary $GROUP_HOME is your group home directory. It's the best place to keep your group's shared code, software installations and important data as it provides snapshots and off-site replication. It is not meant to host data that will be actively read and written to by compute jobs. $HOME and $GROUP_HOME are based on the same physical file system. Characteristics Type high speed, distributed NFS file system Quota 1 TB for the whole $GROUP_HOME directory Snapshots yes (cf. Snapshots ) for more info) Backups off-site replication Purge policy not purged Scope all login and compute nodes Recommended usage # $GROUP_HOME is best suited for group shared source code, common software installations, shared data sets and scripts. We strongly recommend using $GROUP_HOME to reference your group home directory in scripts, rather than its explicit path. Checking quota usage # The sh_quota tool can be used to display quota usage on $GROUP_HOME $ sh_quota -f GROUP_HOME See the Checking Quotas section for more details. $SCRATCH # Summary $SCRATCH is your personal scratch space. It's the best place to store temporary files, such as raw job output, intermediate files, unprocessed results, and so on. Purge policy Files are automatically purged from $SCRATCH after an inactivity period: files that are not modified after 90 days are automatically deleted, contents need to change for a file to be considered modified. The touch command does not modify file contents and thus does not extend a file's lifetime on the filesystem. $SCRATCH is not meant to store permanent data, and should only be used for data associated with currently running jobs. It's not a target for backups, archived data, etc. See the Expiration Policy section for details. Characteristics Type Parallel, high-performance Lustre file system Quota 100 TB / 50,000,000 inodes 2 Snapshots NO Backups NO Purge policy data not modified in the last 90 days are automatically purged Scope all login and compute nodes Recommended usage # $SCRATCH is best suited for large files, such as raw job output, intermediate job files, unprocessed simulation results, and so on. This is the recommended location to run jobs from, and to store files that will be read or written to during job execution. Old files are automatically purged on $SCRATCH so users should avoid storing long-term data there. Each compute node has a low latency, high-bandwidth Infiniband link to $SCRATCH . The aggregate bandwidth of the filesystem is about 75GB/s. So any job with high data performance requirements will take advantage from using $SCRATCH for I/O . We strongly recommend using $SCRATCH to reference your scratch directory in scripts, rather than its explicit path. Checking quota usage # The sh_quota tool can be used to display quota usage on $SCRATCH $ sh_quota -f SCRATCH See the Checking Quotas section for more details. Expiration policy # Inactive files are automatically purged Files that are not modified in the last 90 days will be automatically deleted from the filesystem. To manage available space and maintain optimal performance for all jobs, all files on $SCRATCH are subject to automatic purges. Meaning that after a period of inactivity, files that are not used anymore will be automatically deleted from the filesystem. File activity is defined based on the last time a file's contents (the actual data in the file) have been modified. Meaning that files whose contents have not been modified in the previous 90 days will be automatically deleted. Each time a file's contents are modified, the expiration countdown is reset, and the file gets another 90-day of lifetime. Metadata changes don't qualify as an update Modifying a file's contents is the only way to reset the expiration countdown and extend the file's lifetime on the filesystem. Metadata modifications such as: reading the file, renaming it, moving it to a different directory, changing its permissions or its ownership, \"touching\" it to update its last modification or access times, won't have any effect on the purge countdown. Purges are based on an internal filesystem property that reflects the last date a file's data has been modified, and which is unfortunately not readily accessible by users. Please note that tools like ls will only display the date of the last metadata 1 modification for a file, which is not necessarily relevant to determine a file's eligibility for deletion. For instance, using the touch command on a file to update its last modification date will only update the metadata, not the data, and as such, will not reset the purge countdown timer. Filesystem purges are a continuous process: they don't run at particular times, but are carried out in a permanent background fashion. Files are not necessarily deleted right away when they become eligible for deletion. For instance, if you create a file on February 1 st and don't ever modify it afterwards, it will be automatically become eligible for deletion on May 1 st , and can be deleted anytime after this date. Empty directories that would remain after all their files have been purged are are not automatically deleted, because user workflows may rely on and require specific directory trees to be present. And there's no good way to distinguish between a directory created empty intentionally, and a directory emptied by automatic purges. $GROUP_SCRATCH # $SCRATCH and $GROUP_SCRATCH are based on the same physical file system. Summary $GROUP_SCRATCH is your group shared scratch space. It's the best place to store temporary files, such as raw job output, intermediate files, or unprocessed results that need to be shared among users within a group. $GROUP_SCRATCH is NOT a backup target $GROUP_SCRATCH is not meant to store permanent data, and should only be used for data associated with currently running jobs. It's not a target for backups, archived data, etc. Characteristics Type parallel, high-performance Lustre file system Quota 100 TB / 50,000,000 inodes 2 Snapshots NO Backups NO Purge policy data not accessed in the last 90 days are automatically purged Scope all login and compute nodes Recommended usage # $GROUP_SCRATCH is best suited for large files, such as raw job output, intermediate job files, unprocessed simulation results, and so on. This is the recommended location to run jobs from, and to store files that will be read or written to during job execution. Old files are automatically purged on $GROUP_SCRATCH so users should avoid storing long-term data there. We strongly recommend using $GROUP_SCRATCH to reference your group scratch directory in scripts, rather than its explicit path. Checking quota usage # The sh_quota tool can be used to display quota usage on $GROUP_SCRATCH $ sh_quota -f GROUP_SCRATCH See the Checking Quotas section for more details. Expiration policy # As $SCRATCH and $GROUP_SCRATCH are on the same filesystem, the same expiration policy applies to both. Please see the $SCRATCH section above for more details. $L_SCRATCH # Summary $L_SCRATCH is local to each compute node, and could be used to store temporary files for jobs with high IOPS requirements. Files stored in $L_SCRATCH are purged at the end of the job. Characteristics Type local filesystem, specific to each node, based on SSD Quota n/a (usable space limited by the size of the physical storage devices, typically around 150 GB) Snapshots NO Backups NO Purge policy data immediately purged at the end of the job Scope locally on each node, not shared across nodes Recommended usage # $L_SCRATCH is best suited for small temporary files and applications which require low latency and high IOPS levels, typically intermediate job files, checkpoints, dumps of temporary states, etc. Files stored in $L_SCRATCH are local to each node and can't be accessed from other nodes, nor from login nodes. Please note that an additional, job-specific environment variable, $L_SCRATCH_JOB , will be set to a subdirectory of $L_SCRATCH for each job. So, if you have two jobs running on the same compute node, $L_SCRATCH will be the same and accessible from both jobs, while $L_SCRATCH_JOB will be different for each job. For instance, if you have jobs 98423 and 98672 running on this same nodes, the variables will be set as follows: Job id $L_SCRATCH L_SCRATCH_JOB 98423 /lscratch/kilian /lscratch/kilian/98423 98672 /lscratch/kilian /lscratch/kilian/98672 We strongly recommend using $L_SCRATCH to reference your local scratch directory in scripts, rather than its full path. Expiration policy # All files stored in $L_SCRATCH_JOB are automatically purged at the end of the job, whether the job was successful or not. If you need to conserve files that were generated in $L_SCRATCH_JOB after the job ends, don't forget to add a command at the end of your batch script to copy them to one of the more persistent storage locations, such as $HOME or $SCRATCH . Data stored in $L_SCRATCH will be purged at the end of a job, only if no other job from the same user is still running on the node. Which means that data stored in $L_SCRATCH (but in not $L_SCRATCH_JOB ) will persist on the node until the last job from the user terminates. $OAK # Summary $OAK is SRCC 's research data storage offering. It provides an affordable, longer-term storage option for labs and researchers, and is ideally suited to host large datasets, or curated, post-processed results from job campaigns, as well as final results used for publication. Order $OAK Oak storage can be easily ordered online using the Oak Storage Service page . $OAK is opt-in and is available as an option on Sherlock. Meaning that only members of groups which have purchased storage on Oak can access this filesystem. For complete details and characteristics, including pricing, please refer to the Oak Storage Service page . Characteristics Type parallel, capacitive Lustre filesystem Quota amount purchased (in 10 TB increments) Snapshots NO Backups optional cloud backup available please contact us for details Purge policy not purged Scope all login and compute nodes also available through gateways outside of Sherlock Recommended usage # $OAK is ideally suited for large shared datasets, archival data and curated, post-processed results from job campaigns, as well as final results used for publication. Although jobs can directly read and write to $OAK during execution, it is recommended to first stage files from $OAK to $SCRATCH at the beginning of a series of jobs, and save the desired results back from $SCRATCH to $OAK at the end of the job campaign. We strongly recommend using $OAK to reference your group home directory in scripts, rather than its explicit path. $OAK is not backed up $OAK is not backed up or replicated, by design, and deleted files cannot be recovered. We recommend all researchers to keep an additional copy of their important files (for instance, in Google Drive ). Cloud backup option For additional data security, SRCC now offers \"cloud backup\" of Oak data as a managed service option. For an additional monthly fee, data on Oak can be backed up to the cloud (researchers are responsible for cloud storage costs). Please contact us if you'd like additional information. Checking quota usage # The sh_quota tool can be used to display quota usage on $OAK $ sh_quota -f OAK See the Checking Quotas section for more details. Metadata are data such as a file's size, name, path, owner, permissions, etc. \u21a9 An inode (index node) is a data structure in a Unix-style file system that describes a file-system object such as a file or a directory. \u21a9 \u21a9","title":"Filesystems"},{"location":"docs/storage/filesystems/#home","text":"Summary $HOME is your home directory. It's the best place to keep your code and important data as it provides snapshots and off-site replication. It is not meant to host data that will be actively read and written to by compute jobs. Characteristics Type high speed, distributed NFS file system Quota 15 GB for the whole $HOME directory Snapshots yes (cf. Snapshots ) for more info) Backups off-site replication Purge policy not purged Scope all login and compute nodes","title":"$HOME"},{"location":"docs/storage/filesystems/#recommended-usage","text":"$HOME is best suited for personal configuration files, scripts, small reference files or datasets, source code and individual software installation When you log in, the system automatically sets the current working directory to $HOME : it's the location you'll end up when connecting to Sherlock. You can store your source code and build your executables there. We strongly recommend using $HOME to reference your home directory in scripts, rather than its explicit path.","title":"Recommended usage"},{"location":"docs/storage/filesystems/#checking-quota-usage","text":"The sh_quota tool can be used to display quota usage on $HOME $ sh_quota -f HOME See the Checking Quotas section for more details.","title":"Checking quota usage"},{"location":"docs/storage/filesystems/#group_home","text":"Summary $GROUP_HOME is your group home directory. It's the best place to keep your group's shared code, software installations and important data as it provides snapshots and off-site replication. It is not meant to host data that will be actively read and written to by compute jobs. $HOME and $GROUP_HOME are based on the same physical file system. Characteristics Type high speed, distributed NFS file system Quota 1 TB for the whole $GROUP_HOME directory Snapshots yes (cf. Snapshots ) for more info) Backups off-site replication Purge policy not purged Scope all login and compute nodes","title":"$GROUP_HOME"},{"location":"docs/storage/filesystems/#recommended-usage_1","text":"$GROUP_HOME is best suited for group shared source code, common software installations, shared data sets and scripts. We strongly recommend using $GROUP_HOME to reference your group home directory in scripts, rather than its explicit path.","title":"Recommended usage"},{"location":"docs/storage/filesystems/#checking-quota-usage_1","text":"The sh_quota tool can be used to display quota usage on $GROUP_HOME $ sh_quota -f GROUP_HOME See the Checking Quotas section for more details.","title":"Checking quota usage"},{"location":"docs/storage/filesystems/#scratch","text":"Summary $SCRATCH is your personal scratch space. It's the best place to store temporary files, such as raw job output, intermediate files, unprocessed results, and so on. Purge policy Files are automatically purged from $SCRATCH after an inactivity period: files that are not modified after 90 days are automatically deleted, contents need to change for a file to be considered modified. The touch command does not modify file contents and thus does not extend a file's lifetime on the filesystem. $SCRATCH is not meant to store permanent data, and should only be used for data associated with currently running jobs. It's not a target for backups, archived data, etc. See the Expiration Policy section for details. Characteristics Type Parallel, high-performance Lustre file system Quota 100 TB / 50,000,000 inodes 2 Snapshots NO Backups NO Purge policy data not modified in the last 90 days are automatically purged Scope all login and compute nodes","title":"$SCRATCH"},{"location":"docs/storage/filesystems/#recommended-usage_2","text":"$SCRATCH is best suited for large files, such as raw job output, intermediate job files, unprocessed simulation results, and so on. This is the recommended location to run jobs from, and to store files that will be read or written to during job execution. Old files are automatically purged on $SCRATCH so users should avoid storing long-term data there. Each compute node has a low latency, high-bandwidth Infiniband link to $SCRATCH . The aggregate bandwidth of the filesystem is about 75GB/s. So any job with high data performance requirements will take advantage from using $SCRATCH for I/O . We strongly recommend using $SCRATCH to reference your scratch directory in scripts, rather than its explicit path.","title":"Recommended usage"},{"location":"docs/storage/filesystems/#checking-quota-usage_2","text":"The sh_quota tool can be used to display quota usage on $SCRATCH $ sh_quota -f SCRATCH See the Checking Quotas section for more details.","title":"Checking quota usage"},{"location":"docs/storage/filesystems/#expiration-policy","text":"Inactive files are automatically purged Files that are not modified in the last 90 days will be automatically deleted from the filesystem. To manage available space and maintain optimal performance for all jobs, all files on $SCRATCH are subject to automatic purges. Meaning that after a period of inactivity, files that are not used anymore will be automatically deleted from the filesystem. File activity is defined based on the last time a file's contents (the actual data in the file) have been modified. Meaning that files whose contents have not been modified in the previous 90 days will be automatically deleted. Each time a file's contents are modified, the expiration countdown is reset, and the file gets another 90-day of lifetime. Metadata changes don't qualify as an update Modifying a file's contents is the only way to reset the expiration countdown and extend the file's lifetime on the filesystem. Metadata modifications such as: reading the file, renaming it, moving it to a different directory, changing its permissions or its ownership, \"touching\" it to update its last modification or access times, won't have any effect on the purge countdown. Purges are based on an internal filesystem property that reflects the last date a file's data has been modified, and which is unfortunately not readily accessible by users. Please note that tools like ls will only display the date of the last metadata 1 modification for a file, which is not necessarily relevant to determine a file's eligibility for deletion. For instance, using the touch command on a file to update its last modification date will only update the metadata, not the data, and as such, will not reset the purge countdown timer. Filesystem purges are a continuous process: they don't run at particular times, but are carried out in a permanent background fashion. Files are not necessarily deleted right away when they become eligible for deletion. For instance, if you create a file on February 1 st and don't ever modify it afterwards, it will be automatically become eligible for deletion on May 1 st , and can be deleted anytime after this date. Empty directories that would remain after all their files have been purged are are not automatically deleted, because user workflows may rely on and require specific directory trees to be present. And there's no good way to distinguish between a directory created empty intentionally, and a directory emptied by automatic purges.","title":"Expiration policy"},{"location":"docs/storage/filesystems/#group_scratch","text":"$SCRATCH and $GROUP_SCRATCH are based on the same physical file system. Summary $GROUP_SCRATCH is your group shared scratch space. It's the best place to store temporary files, such as raw job output, intermediate files, or unprocessed results that need to be shared among users within a group. $GROUP_SCRATCH is NOT a backup target $GROUP_SCRATCH is not meant to store permanent data, and should only be used for data associated with currently running jobs. It's not a target for backups, archived data, etc. Characteristics Type parallel, high-performance Lustre file system Quota 100 TB / 50,000,000 inodes 2 Snapshots NO Backups NO Purge policy data not accessed in the last 90 days are automatically purged Scope all login and compute nodes","title":"$GROUP_SCRATCH"},{"location":"docs/storage/filesystems/#recommended-usage_3","text":"$GROUP_SCRATCH is best suited for large files, such as raw job output, intermediate job files, unprocessed simulation results, and so on. This is the recommended location to run jobs from, and to store files that will be read or written to during job execution. Old files are automatically purged on $GROUP_SCRATCH so users should avoid storing long-term data there. We strongly recommend using $GROUP_SCRATCH to reference your group scratch directory in scripts, rather than its explicit path.","title":"Recommended usage"},{"location":"docs/storage/filesystems/#checking-quota-usage_3","text":"The sh_quota tool can be used to display quota usage on $GROUP_SCRATCH $ sh_quota -f GROUP_SCRATCH See the Checking Quotas section for more details.","title":"Checking quota usage"},{"location":"docs/storage/filesystems/#expiration-policy_1","text":"As $SCRATCH and $GROUP_SCRATCH are on the same filesystem, the same expiration policy applies to both. Please see the $SCRATCH section above for more details.","title":"Expiration policy"},{"location":"docs/storage/filesystems/#l_scratch","text":"Summary $L_SCRATCH is local to each compute node, and could be used to store temporary files for jobs with high IOPS requirements. Files stored in $L_SCRATCH are purged at the end of the job. Characteristics Type local filesystem, specific to each node, based on SSD Quota n/a (usable space limited by the size of the physical storage devices, typically around 150 GB) Snapshots NO Backups NO Purge policy data immediately purged at the end of the job Scope locally on each node, not shared across nodes","title":"$L_SCRATCH"},{"location":"docs/storage/filesystems/#recommended-usage_4","text":"$L_SCRATCH is best suited for small temporary files and applications which require low latency and high IOPS levels, typically intermediate job files, checkpoints, dumps of temporary states, etc. Files stored in $L_SCRATCH are local to each node and can't be accessed from other nodes, nor from login nodes. Please note that an additional, job-specific environment variable, $L_SCRATCH_JOB , will be set to a subdirectory of $L_SCRATCH for each job. So, if you have two jobs running on the same compute node, $L_SCRATCH will be the same and accessible from both jobs, while $L_SCRATCH_JOB will be different for each job. For instance, if you have jobs 98423 and 98672 running on this same nodes, the variables will be set as follows: Job id $L_SCRATCH L_SCRATCH_JOB 98423 /lscratch/kilian /lscratch/kilian/98423 98672 /lscratch/kilian /lscratch/kilian/98672 We strongly recommend using $L_SCRATCH to reference your local scratch directory in scripts, rather than its full path.","title":"Recommended usage"},{"location":"docs/storage/filesystems/#expiration-policy_2","text":"All files stored in $L_SCRATCH_JOB are automatically purged at the end of the job, whether the job was successful or not. If you need to conserve files that were generated in $L_SCRATCH_JOB after the job ends, don't forget to add a command at the end of your batch script to copy them to one of the more persistent storage locations, such as $HOME or $SCRATCH . Data stored in $L_SCRATCH will be purged at the end of a job, only if no other job from the same user is still running on the node. Which means that data stored in $L_SCRATCH (but in not $L_SCRATCH_JOB ) will persist on the node until the last job from the user terminates.","title":"Expiration policy"},{"location":"docs/storage/filesystems/#oak","text":"Summary $OAK is SRCC 's research data storage offering. It provides an affordable, longer-term storage option for labs and researchers, and is ideally suited to host large datasets, or curated, post-processed results from job campaigns, as well as final results used for publication. Order $OAK Oak storage can be easily ordered online using the Oak Storage Service page . $OAK is opt-in and is available as an option on Sherlock. Meaning that only members of groups which have purchased storage on Oak can access this filesystem. For complete details and characteristics, including pricing, please refer to the Oak Storage Service page . Characteristics Type parallel, capacitive Lustre filesystem Quota amount purchased (in 10 TB increments) Snapshots NO Backups optional cloud backup available please contact us for details Purge policy not purged Scope all login and compute nodes also available through gateways outside of Sherlock","title":"$OAK"},{"location":"docs/storage/filesystems/#recommended-usage_5","text":"$OAK is ideally suited for large shared datasets, archival data and curated, post-processed results from job campaigns, as well as final results used for publication. Although jobs can directly read and write to $OAK during execution, it is recommended to first stage files from $OAK to $SCRATCH at the beginning of a series of jobs, and save the desired results back from $SCRATCH to $OAK at the end of the job campaign. We strongly recommend using $OAK to reference your group home directory in scripts, rather than its explicit path. $OAK is not backed up $OAK is not backed up or replicated, by design, and deleted files cannot be recovered. We recommend all researchers to keep an additional copy of their important files (for instance, in Google Drive ). Cloud backup option For additional data security, SRCC now offers \"cloud backup\" of Oak data as a managed service option. For an additional monthly fee, data on Oak can be backed up to the cloud (researchers are responsible for cloud storage costs). Please contact us if you'd like additional information.","title":"Recommended usage"},{"location":"docs/storage/filesystems/#checking-quota-usage_4","text":"The sh_quota tool can be used to display quota usage on $OAK $ sh_quota -f OAK See the Checking Quotas section for more details. Metadata are data such as a file's size, name, path, owner, permissions, etc. \u21a9 An inode (index node) is a data structure in a Unix-style file system that describes a file-system object such as a file or a directory. \u21a9 \u21a9","title":"Checking quota usage"},{"location":"docs/storage/overview/","text":"Sherlock provides access to several file systems, each with distinct storage characteristics. Each user and PI group get access to a set of pre-defined directories in these file systems to store their data. Sherlock is a compute cluster, not a storage system Sherlock's storage resources are limited and are shared among many users. They are meant to store data and code associated with projects for which you are using Sherlock's computational resources. This space is for work actively being computed on with Sherlock, and should not be used as a target for backups from other systems. If you're looking for a long-term storage solution for research data, SRCC offers the Oak storage system , which is specifically intended for this usage. Those file systems are shared with other users, and are subject to quota limits and for some of them, purge policies (time-residency limits). Filesystem overview # Features and purpose # Name Type Backups / Snapshots Performance Purpose Cost $HOME , $GROUP_HOME NFS / low small, important files (source code, executables, configuration files...) free $SCRATCH , $GROUP_SCRATCH Lustre / high bandwidth large, temporary files (checkpoints, raw application output...) free $L_SCRATCH local SSD / low latency, high IOPS job specific output requiring high IOPS free $OAK Lustre option / moderate long term storage of research data volume-based 1 Access scope # Name Scope Access sharing level $HOME cluster user $GROUP_HOME cluster group $SCRATCH cluster user $GROUP_SCRATCH cluster group $L_SCRATCH compute node user $OAK cluster (optional, purchase required) group Group storage locations are typically shared between all the members of the same PI group. User locations are only accessible by the user. Quotas and limits # Info Quotas are applied on both volume (the amount of data stored in bytes) and inode: an inode (index node) is a data structure in a Unix-style file system that describes a file-system object such as a file or a directory. In practice, each filesystem entry (file, directory, link) counts as an inode. Name Quota type Volume quota Inode quota Retention $HOME directory 15 GB n/a \\(\\infty\\) $GROUP_HOME directory 1 TB n/a \\(\\infty\\) $SCRATCH directory 100 TB 50 million time limited $GROUP_SCRATCH directory 100 TB 50 million time limited $L_SCRATCH n/a n/a n/a job lifetime $OAK group amount purchased function of the volume purchased \\(\\infty\\) Quota types: directory : based on files location and account for all the files that are in a given directory. group : based on files ownership and account for all the files that belong to a given group. Retention types: \\(\\infty\\) : files are kept as long as the user account exists on Sherlock. time limited : files are kept for a fixed length of time after they've been last modified. Once the limit is reached, files expire and are automatically deleted. job lifetime : files are only kept for the duration of the job and are automatically purged when the job ends. Checking quotas # To check your quota usage on the different filesystems you have access to, you can use the sh_quota command: $ sh_quota +---------------------------------------------------------------------------+ | Disk usage for user kilian ( group: ruthm ) | +---------------------------------------------------------------------------+ | Filesystem | volume / limit | inodes / limit | +---------------------------------------------------------------------------+ HOME | 9 .4GB / 15 .0GB [|||||| 62 % ] | - / - ( -% ) GROUP_HOME | 562 .6GB / 1 .0TB [|||| | 56 % ] | - / - ( -% ) SCRATCH | 65 .0GB / 100 .0TB [ 0 % ] | 143 .8K / 50 .0M ( 0 % ) GROUP_SCRATCH | 172 .2GB / 100 .0TB [ 0 % ] | 53 .4K / 50 .0M ( 0 % ) OAK | 30 .8TB / 240 .0TB [ | 12 % ] | 6 .6M / 36 .0M ( 18 % ) +---------------------------------------------------------------------------+ Several options are provided to allow listing quotas for a specific filesystem only, or in the context of a different group (for users who are members of several PI groups). Please see the sh_quota usage information for details: $ sh_quota -h sh_quota: display user and group quota information for all accessible filesystems. Usage: sh_quota [ OPTIONS ] Optional arguments: -f FILESYSTEM only display quota information for FILESYSTEM. For instance: \"-f $HOME \" -g GROUP for users with multiple group memberships, display group quotas in the context of that group -n don ' t display headers -j JSON output ( implies -n ) Examples # For instance, to only display your quota usage on $HOME : $ sh_quota -f HOME If you belong to multiple groups, you can display the group quotas for your secondary groups with: $ sh_quota -g <group_name> And finally, for great output control, an option to display quota usage in JSON is provided via the -j option: $ sh_quota -f SCRATCH -j { \"SCRATCH\" : { \"quotas\" : { \"type\" : \"user\" , \"blocks\" : { \"usage\" : \"47476660\" , \"limit\" : \"21474836480\" } , \"inodes\" : { \"usage\" : \"97794\" , \"limit\" : \"20000000\" } } } } Where should I store my files? # Not all filesystems are equivalent Choosing the appropriate storage location for your files is an essential step towards making your utilization of the cluster the most efficient possible. It will make your own experience much smoother, yield better performance for your jobs and simulations, and contribute to make Sherlock a useful and well-functioning resource for everyone. Here is where we recommend storing different types of files and data on Sherlock: personal scripts, configuration files and software installations \u2192 $HOME group-shared scripts, software installations and medium-sized datasets \u2192 $GROUP_HOME temporary output of jobs, large checkpoint files \u2192 $SCRATCH curated output of job campaigns, large group-shared datasets, archives \u2192 $OAK Accessing filesystems # On Sherlock # Filesystem environment variables To facilitate access and data management, user and group storage location on Sherlock are identified by a set of environment variables, such as $HOME or $SCRATCH . We strongly recommend using those variables in your scripts rather than explicit paths, to facilitate transition to new systems for instance. By using those environment variables, you'll be sure that your scripts will continue to work even if the underlying filesystem paths change. To see the contents of these variables, you can use the echo command. For instance, to see the absolute path of your $SCRATCH directory: $ echo $SCRATCH /scratch/users/kilian Or for instance, to move to your group-shared home directory: $ cd $GROUP_HOME From other systems # External filesystems cannot be mounted on Sherlock For a variety of security, manageability and technical considerations, we can't mount external filesystems nor data storage systems on Sherlock. The recommended approach is to make Sherlock's data available on external systems. You can mount any of your Sherlock directories on any external system you have access to by using SSHFS. For more details, please refer to the Data Transfer page. For more information about Oak, its characteristics and cost model, please see the Oak Service Description page . \u21a9","title":"Overview"},{"location":"docs/storage/overview/#filesystem-overview","text":"","title":"Filesystem overview"},{"location":"docs/storage/overview/#features-and-purpose","text":"Name Type Backups / Snapshots Performance Purpose Cost $HOME , $GROUP_HOME NFS / low small, important files (source code, executables, configuration files...) free $SCRATCH , $GROUP_SCRATCH Lustre / high bandwidth large, temporary files (checkpoints, raw application output...) free $L_SCRATCH local SSD / low latency, high IOPS job specific output requiring high IOPS free $OAK Lustre option / moderate long term storage of research data volume-based 1","title":"Features and purpose"},{"location":"docs/storage/overview/#access-scope","text":"Name Scope Access sharing level $HOME cluster user $GROUP_HOME cluster group $SCRATCH cluster user $GROUP_SCRATCH cluster group $L_SCRATCH compute node user $OAK cluster (optional, purchase required) group Group storage locations are typically shared between all the members of the same PI group. User locations are only accessible by the user.","title":"Access scope"},{"location":"docs/storage/overview/#quotas-and-limits","text":"Info Quotas are applied on both volume (the amount of data stored in bytes) and inode: an inode (index node) is a data structure in a Unix-style file system that describes a file-system object such as a file or a directory. In practice, each filesystem entry (file, directory, link) counts as an inode. Name Quota type Volume quota Inode quota Retention $HOME directory 15 GB n/a \\(\\infty\\) $GROUP_HOME directory 1 TB n/a \\(\\infty\\) $SCRATCH directory 100 TB 50 million time limited $GROUP_SCRATCH directory 100 TB 50 million time limited $L_SCRATCH n/a n/a n/a job lifetime $OAK group amount purchased function of the volume purchased \\(\\infty\\) Quota types: directory : based on files location and account for all the files that are in a given directory. group : based on files ownership and account for all the files that belong to a given group. Retention types: \\(\\infty\\) : files are kept as long as the user account exists on Sherlock. time limited : files are kept for a fixed length of time after they've been last modified. Once the limit is reached, files expire and are automatically deleted. job lifetime : files are only kept for the duration of the job and are automatically purged when the job ends.","title":"Quotas and limits"},{"location":"docs/storage/overview/#checking-quotas","text":"To check your quota usage on the different filesystems you have access to, you can use the sh_quota command: $ sh_quota +---------------------------------------------------------------------------+ | Disk usage for user kilian ( group: ruthm ) | +---------------------------------------------------------------------------+ | Filesystem | volume / limit | inodes / limit | +---------------------------------------------------------------------------+ HOME | 9 .4GB / 15 .0GB [|||||| 62 % ] | - / - ( -% ) GROUP_HOME | 562 .6GB / 1 .0TB [|||| | 56 % ] | - / - ( -% ) SCRATCH | 65 .0GB / 100 .0TB [ 0 % ] | 143 .8K / 50 .0M ( 0 % ) GROUP_SCRATCH | 172 .2GB / 100 .0TB [ 0 % ] | 53 .4K / 50 .0M ( 0 % ) OAK | 30 .8TB / 240 .0TB [ | 12 % ] | 6 .6M / 36 .0M ( 18 % ) +---------------------------------------------------------------------------+ Several options are provided to allow listing quotas for a specific filesystem only, or in the context of a different group (for users who are members of several PI groups). Please see the sh_quota usage information for details: $ sh_quota -h sh_quota: display user and group quota information for all accessible filesystems. Usage: sh_quota [ OPTIONS ] Optional arguments: -f FILESYSTEM only display quota information for FILESYSTEM. For instance: \"-f $HOME \" -g GROUP for users with multiple group memberships, display group quotas in the context of that group -n don ' t display headers -j JSON output ( implies -n )","title":"Checking quotas"},{"location":"docs/storage/overview/#where-should-i-store-my-files","text":"Not all filesystems are equivalent Choosing the appropriate storage location for your files is an essential step towards making your utilization of the cluster the most efficient possible. It will make your own experience much smoother, yield better performance for your jobs and simulations, and contribute to make Sherlock a useful and well-functioning resource for everyone. Here is where we recommend storing different types of files and data on Sherlock: personal scripts, configuration files and software installations \u2192 $HOME group-shared scripts, software installations and medium-sized datasets \u2192 $GROUP_HOME temporary output of jobs, large checkpoint files \u2192 $SCRATCH curated output of job campaigns, large group-shared datasets, archives \u2192 $OAK","title":"Where should I store my files?"},{"location":"docs/storage/overview/#accessing-filesystems","text":"","title":"Accessing filesystems"},{"location":"docs/storage/overview/#on-sherlock","text":"Filesystem environment variables To facilitate access and data management, user and group storage location on Sherlock are identified by a set of environment variables, such as $HOME or $SCRATCH . We strongly recommend using those variables in your scripts rather than explicit paths, to facilitate transition to new systems for instance. By using those environment variables, you'll be sure that your scripts will continue to work even if the underlying filesystem paths change. To see the contents of these variables, you can use the echo command. For instance, to see the absolute path of your $SCRATCH directory: $ echo $SCRATCH /scratch/users/kilian Or for instance, to move to your group-shared home directory: $ cd $GROUP_HOME","title":"On Sherlock"},{"location":"docs/storage/overview/#from-other-systems","text":"External filesystems cannot be mounted on Sherlock For a variety of security, manageability and technical considerations, we can't mount external filesystems nor data storage systems on Sherlock. The recommended approach is to make Sherlock's data available on external systems. You can mount any of your Sherlock directories on any external system you have access to by using SSHFS. For more details, please refer to the Data Transfer page. For more information about Oak, its characteristics and cost model, please see the Oak Service Description page . \u21a9","title":"From other systems"},{"location":"docs/user-guide/gpu/","text":"To support the latest computing evolutions in many fields of science, Sherlock features a number of compute nodes with [GPUs][url_gpus] that can be used to run a variety of GPU -accelerated applications. Those nodes are available to everyone, but are a scarce, highly-demanded resource, so getting access to them may require some wait time in queue. Getting your own GPU nodes If you need frequent access to GPU nodes, we recommend considering becoming an owner on Sherlock , so you can have immediate access to your GPU nodes when you need them. GPU nodes # A limited number of GPU nodes are available in the gpu partition. Anybody running on Sherlock can submit a job there. As owners contribute to expand Sherlock, more GPU nodes are added to the owners partition, for use by PI groups which purchased their own compute nodes. There are a variety of different GPU configuration available in the gpu partition. To see the available GPU types, please see the GPU types section. Submitting a GPU job # To submit a GPU job, you'll need to use the --gpus (or -G ) option in your batch script or command line submission options. For instance, the following script will request one GPU for two hours in the gpu partition, and run the GPU -enabled version of gromacs : #!/bin/bash #SBATCH -p gpu #SBATCH -c 10 #SBATCH -G 1 ml load gromacs/2016.3 srun gmx_gpu ... You can also directly run GPU processes on compute nodes with srun . For instance, the following command will display details about the GPUs allocated to your job: $ srun -p gpu --gpus 2 nvidia-smi Fri Jul 28 12 :41:49 2017 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 375 .51 Driver Version: 375 .51 | | -------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | =============================== + ====================== + ====================== | | 0 Tesla P40 On | 0000 :03:00.0 Off | 0 | | N/A 26C P8 10W / 250W | 0MiB / 22912MiB | 0 % E. Process | +-------------------------------+----------------------+----------------------+ | 1 Tesla P40 On | 0000 :04:00.0 Off | 0 | | N/A 24C P8 10W / 250W | 0MiB / 22912MiB | 0 % E. Process | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | | ============================================================================= | | No running processes found | +-----------------------------------------------------------------------------+ GPU resources MUST be requested explicitly Jobs will be rejected at submission time if they don't explictly request GPU resources. The gpu partition only accepts jobs explicitly requesting GPU resources. If they don't, they will be rejected with the following message: $ srun -p gpu --pty bash srun: error: Unable to allocate resources: Job violates accounting/QOS policy ( job submit limit, user ' s size and/or time limits ) Interactive session # As for any other compute node, you can submit an interactive job and request a shell on a GPU node with the following command: $ srun -p gpu --gpus 1 --pty bash srun: job 38068928 queued and waiting for resources srun: job 38068928 has been allocated resources $ nvidia-smi --query-gpu = index,name --format = csv,noheader 0 , Tesla V100-SXM2-16GB GPU types # Since Sherlock features many different types of GPUs, each with its own technical characteristics, performance profiles and specificities, you may want to ensure that your job runs on a specific type of GPU . To that end, Slurm allows users to specify constraints when submitting jobs, which will indicate the scheduler that only nodes having features matching the job constraints could be used to satisfy the request. Multiple constraints may be specified and combined with various operators (please refer to the official Slurm documentation for details). The list of available features on GPU nodes can be obtained with the node_feat 1 command: $ node_feat -p gpu | grep GPU_ GPU_BRD:TESLA GPU_GEN:PSC GPU_MEM:16GB GPU_MEM:24GB GPU_SKU:TESLA_P100_PCIE GPU_SKU:TESLA_P40 node_feat will only list the features of nodes from partitions you have access to, so output may vary depending on your group membership. The different characteristics 2 of various GPU types are listed in the following table Slurm feature Description Possible values Example job constraint GPU_BRD GPU brand GEFORCE : GeForce / TITAN TESLA : Tesla #SBATCH -C GPU_BRD:TESLA GPU_GEN GPU generation PSC : Pascal MXW : Maxwell #SBATCH -C GPU_GEN:PSC GPU_MEM Amount of GPU memory 16GB , 24GB #SBATCH -C GPU_MEM:16GB GPU_SKU GPU model TESLA_P100_PCIE TESLA_P40 #SBATCH -C GPU_SKU:TESLA_P40 Depending on the partitions you have access to, more features may be available to be requested in your jobs. For instance, to request a Tesla GPU for you job, you can use the following submission options: $ srun -p owners -G 1 -C GPU_BRD:TESLA nvidia-smi -L GPU 0 : Tesla P100-SXM2-16GB ( UUID: GPU-4f91f58f-f3ea-d414-d4ce-faf587c5c4d4 ) Unsatisfiable constraints If you specify a constraint that can't be satisfied in the partition you're submitting your job to, the job will be rejected by the scheduler. For instance, requesting a GeForce GPU in the gpu partition, which only features Tesla GPUs, will result in an error: $ srun -p gpu -G 1 -C GPU_BRD:GEFORCE nvidia-smi -L srun: error: Unable to allocate resources: Requested node configuration is not available GPU compute modes # By default, GPUs on Sherlock are set in the Exclusive Process compute mode 3 , to provide the best performance and an isolated environment for jobs, out of the box. Some software may require GPUs to be set to a different compute mode, for instance to share a GPU across different processes within the same application. To handle that case, we developed a specific option, --gpu_cmode , that users can add to their srun and sbatch submission options, to choose the compute mode for the GPUs allocated to their job. Here's the list of the different compute modes supported on Sherlock's GPUs: GPU compute mode --gpu_cmode option Description \"Default\" shared Multiple contexts are allowed per device (NVIDIA default) \"Exclusive Process\" exclusive Only one context is allowed per device, usable from multiple threads at a time (Sherlock default) \"Prohibited\" prohibited No CUDA context can be created on the device By default, or if the --gpu_cmode option is not specified, GPUs will be set in the \"Exclusive Process\" mode, as demonstrated by this example command: $ srun -p gpu -G 1 nvidia-smi +-----------------------------------------------------------------------------+ | NVIDIA-SMI 387 .26 Driver Version: 387 .26 | | -------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | =============================== + ====================== + ====================== | | 0 Tesla P40 On | 00000000 :03:00.0 Off | 0 | | N/A 22C P8 10W / 250W | 0MiB / 22912MiB | 0 % E. Process | +-------------------------------+----------------------+----------------------+ With the --gpu_cmode option, the scheduler will set the GPU compute mode to the desired value before execution: $ srun -p gpu -G 1 --gpu_cmode = shared nvidia-smi +-----------------------------------------------------------------------------+ | NVIDIA-SMI 387 .26 Driver Version: 387 .26 | | -------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | =============================== + ====================== + ====================== | | 0 Tesla P40 On | 00000000 :03:00.0 Off | 0 | | N/A 22C P8 10W / 250W | 0MiB / 22912MiB | 0 % Default | +-------------------------------+----------------------+----------------------+ Tip \"Default\" is the name that the NVIDIA System Management Interface ( nvidia-smi ) uses to describe the mode where a GPU can be shared between different processes. It does not represent the default GPU compute mode on Sherlock, which is \"Exclusive Process\". Advanced options # A number of submission options are available when submitting GPU jobs, to request specific resource mapping or task binding options. Here are some examples to allocate a set of resources as a function of the number of requested GPUs: --cpus-per-gpu : requests a number of CPUs per allocated GPU . For instance, the following options will allocate 2 GPUs and 4 CPUs: $ salloc -p gpu -G 2 --cpus-per-gpu = 2 --gpus-per-node : requests a number of GPUs per node, --gpus-per-task : requests a number of GPUs per spawned task, --mem-per-gpu : allocates (host) memory per allocated GPU . Other options can help set particular GPU properties (topology, frequency...): --gpu-bind : specify task/ GPU binding mode. By default every spawned task can access every GPU allocated to the job. This option can help making sure that tasks are bound to the closest GPU , for better performance. --gpu-freq : specify GPU and memory frequency. For instance: $ srun -p test -G 1 --gpu-freq = highm1,verbose /bin/true GpuFreq = memory_freq:2600,graphics_freq:758 Those options are all available to the srun / sbatch / salloc commands, and more details about each of them can be found in the Slurm documentation . Conflicting options Given the multitude of options, it's very easy to submit a job with conflicting options. In most cases the job will be rejected. For instance: $ sbatch --gpus-per-task=1 --cpus-per-gpu=2 --cpus-per-task=1 ... Here, the first two options implicitly set cpu-per-task to 2, while the third option explicitly sets cpus-per-task to 1. So the job's requirements are conflicting and can't be satisfied. Environment and diagnostic tools # nvtop # GPU usage information can be shown with the nvtop tool. nvtop is available as a module , which can be loaded like this: $ ml load system nvtop nvtop provides an htop -like interactive view of GPU utilization. Users can monitor, estimate and fine tune their GPU resource requests with this tool. Percent GPU and memory utilization is shown as a user's GPU code is running. See node_feat -h for more details. \u21a9 The lists of values provided in the table are non exhaustive. \u21a9 The list of available GPU compute modes and relevant details are available in the CUDA Toolkit Documentation \u21a9","title":"GPU nodes"},{"location":"docs/user-guide/gpu/#gpu-nodes","text":"A limited number of GPU nodes are available in the gpu partition. Anybody running on Sherlock can submit a job there. As owners contribute to expand Sherlock, more GPU nodes are added to the owners partition, for use by PI groups which purchased their own compute nodes. There are a variety of different GPU configuration available in the gpu partition. To see the available GPU types, please see the GPU types section.","title":"GPU nodes"},{"location":"docs/user-guide/gpu/#submitting-a-gpu-job","text":"To submit a GPU job, you'll need to use the --gpus (or -G ) option in your batch script or command line submission options. For instance, the following script will request one GPU for two hours in the gpu partition, and run the GPU -enabled version of gromacs : #!/bin/bash #SBATCH -p gpu #SBATCH -c 10 #SBATCH -G 1 ml load gromacs/2016.3 srun gmx_gpu ... You can also directly run GPU processes on compute nodes with srun . For instance, the following command will display details about the GPUs allocated to your job: $ srun -p gpu --gpus 2 nvidia-smi Fri Jul 28 12 :41:49 2017 +-----------------------------------------------------------------------------+ | NVIDIA-SMI 375 .51 Driver Version: 375 .51 | | -------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | =============================== + ====================== + ====================== | | 0 Tesla P40 On | 0000 :03:00.0 Off | 0 | | N/A 26C P8 10W / 250W | 0MiB / 22912MiB | 0 % E. Process | +-------------------------------+----------------------+----------------------+ | 1 Tesla P40 On | 0000 :04:00.0 Off | 0 | | N/A 24C P8 10W / 250W | 0MiB / 22912MiB | 0 % E. Process | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: GPU Memory | | GPU PID Type Process name Usage | | ============================================================================= | | No running processes found | +-----------------------------------------------------------------------------+ GPU resources MUST be requested explicitly Jobs will be rejected at submission time if they don't explictly request GPU resources. The gpu partition only accepts jobs explicitly requesting GPU resources. If they don't, they will be rejected with the following message: $ srun -p gpu --pty bash srun: error: Unable to allocate resources: Job violates accounting/QOS policy ( job submit limit, user ' s size and/or time limits )","title":"Submitting a GPU job"},{"location":"docs/user-guide/gpu/#interactive-session","text":"As for any other compute node, you can submit an interactive job and request a shell on a GPU node with the following command: $ srun -p gpu --gpus 1 --pty bash srun: job 38068928 queued and waiting for resources srun: job 38068928 has been allocated resources $ nvidia-smi --query-gpu = index,name --format = csv,noheader 0 , Tesla V100-SXM2-16GB","title":"Interactive session"},{"location":"docs/user-guide/gpu/#gpu-types","text":"Since Sherlock features many different types of GPUs, each with its own technical characteristics, performance profiles and specificities, you may want to ensure that your job runs on a specific type of GPU . To that end, Slurm allows users to specify constraints when submitting jobs, which will indicate the scheduler that only nodes having features matching the job constraints could be used to satisfy the request. Multiple constraints may be specified and combined with various operators (please refer to the official Slurm documentation for details). The list of available features on GPU nodes can be obtained with the node_feat 1 command: $ node_feat -p gpu | grep GPU_ GPU_BRD:TESLA GPU_GEN:PSC GPU_MEM:16GB GPU_MEM:24GB GPU_SKU:TESLA_P100_PCIE GPU_SKU:TESLA_P40 node_feat will only list the features of nodes from partitions you have access to, so output may vary depending on your group membership. The different characteristics 2 of various GPU types are listed in the following table Slurm feature Description Possible values Example job constraint GPU_BRD GPU brand GEFORCE : GeForce / TITAN TESLA : Tesla #SBATCH -C GPU_BRD:TESLA GPU_GEN GPU generation PSC : Pascal MXW : Maxwell #SBATCH -C GPU_GEN:PSC GPU_MEM Amount of GPU memory 16GB , 24GB #SBATCH -C GPU_MEM:16GB GPU_SKU GPU model TESLA_P100_PCIE TESLA_P40 #SBATCH -C GPU_SKU:TESLA_P40 Depending on the partitions you have access to, more features may be available to be requested in your jobs. For instance, to request a Tesla GPU for you job, you can use the following submission options: $ srun -p owners -G 1 -C GPU_BRD:TESLA nvidia-smi -L GPU 0 : Tesla P100-SXM2-16GB ( UUID: GPU-4f91f58f-f3ea-d414-d4ce-faf587c5c4d4 ) Unsatisfiable constraints If you specify a constraint that can't be satisfied in the partition you're submitting your job to, the job will be rejected by the scheduler. For instance, requesting a GeForce GPU in the gpu partition, which only features Tesla GPUs, will result in an error: $ srun -p gpu -G 1 -C GPU_BRD:GEFORCE nvidia-smi -L srun: error: Unable to allocate resources: Requested node configuration is not available","title":"GPU types"},{"location":"docs/user-guide/gpu/#gpu-compute-modes","text":"By default, GPUs on Sherlock are set in the Exclusive Process compute mode 3 , to provide the best performance and an isolated environment for jobs, out of the box. Some software may require GPUs to be set to a different compute mode, for instance to share a GPU across different processes within the same application. To handle that case, we developed a specific option, --gpu_cmode , that users can add to their srun and sbatch submission options, to choose the compute mode for the GPUs allocated to their job. Here's the list of the different compute modes supported on Sherlock's GPUs: GPU compute mode --gpu_cmode option Description \"Default\" shared Multiple contexts are allowed per device (NVIDIA default) \"Exclusive Process\" exclusive Only one context is allowed per device, usable from multiple threads at a time (Sherlock default) \"Prohibited\" prohibited No CUDA context can be created on the device By default, or if the --gpu_cmode option is not specified, GPUs will be set in the \"Exclusive Process\" mode, as demonstrated by this example command: $ srun -p gpu -G 1 nvidia-smi +-----------------------------------------------------------------------------+ | NVIDIA-SMI 387 .26 Driver Version: 387 .26 | | -------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | =============================== + ====================== + ====================== | | 0 Tesla P40 On | 00000000 :03:00.0 Off | 0 | | N/A 22C P8 10W / 250W | 0MiB / 22912MiB | 0 % E. Process | +-------------------------------+----------------------+----------------------+ With the --gpu_cmode option, the scheduler will set the GPU compute mode to the desired value before execution: $ srun -p gpu -G 1 --gpu_cmode = shared nvidia-smi +-----------------------------------------------------------------------------+ | NVIDIA-SMI 387 .26 Driver Version: 387 .26 | | -------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | =============================== + ====================== + ====================== | | 0 Tesla P40 On | 00000000 :03:00.0 Off | 0 | | N/A 22C P8 10W / 250W | 0MiB / 22912MiB | 0 % Default | +-------------------------------+----------------------+----------------------+ Tip \"Default\" is the name that the NVIDIA System Management Interface ( nvidia-smi ) uses to describe the mode where a GPU can be shared between different processes. It does not represent the default GPU compute mode on Sherlock, which is \"Exclusive Process\".","title":"GPU compute modes"},{"location":"docs/user-guide/gpu/#advanced-options","text":"A number of submission options are available when submitting GPU jobs, to request specific resource mapping or task binding options. Here are some examples to allocate a set of resources as a function of the number of requested GPUs: --cpus-per-gpu : requests a number of CPUs per allocated GPU . For instance, the following options will allocate 2 GPUs and 4 CPUs: $ salloc -p gpu -G 2 --cpus-per-gpu = 2 --gpus-per-node : requests a number of GPUs per node, --gpus-per-task : requests a number of GPUs per spawned task, --mem-per-gpu : allocates (host) memory per allocated GPU . Other options can help set particular GPU properties (topology, frequency...): --gpu-bind : specify task/ GPU binding mode. By default every spawned task can access every GPU allocated to the job. This option can help making sure that tasks are bound to the closest GPU , for better performance. --gpu-freq : specify GPU and memory frequency. For instance: $ srun -p test -G 1 --gpu-freq = highm1,verbose /bin/true GpuFreq = memory_freq:2600,graphics_freq:758 Those options are all available to the srun / sbatch / salloc commands, and more details about each of them can be found in the Slurm documentation . Conflicting options Given the multitude of options, it's very easy to submit a job with conflicting options. In most cases the job will be rejected. For instance: $ sbatch --gpus-per-task=1 --cpus-per-gpu=2 --cpus-per-task=1 ... Here, the first two options implicitly set cpu-per-task to 2, while the third option explicitly sets cpus-per-task to 1. So the job's requirements are conflicting and can't be satisfied.","title":"Advanced options"},{"location":"docs/user-guide/gpu/#environment-and-diagnostic-tools","text":"","title":"Environment and diagnostic tools"},{"location":"docs/user-guide/gpu/#nvtop","text":"GPU usage information can be shown with the nvtop tool. nvtop is available as a module , which can be loaded like this: $ ml load system nvtop nvtop provides an htop -like interactive view of GPU utilization. Users can monitor, estimate and fine tune their GPU resource requests with this tool. Percent GPU and memory utilization is shown as a user's GPU code is running. See node_feat -h for more details. \u21a9 The lists of values provided in the table are non exhaustive. \u21a9 The list of available GPU compute modes and relevant details are available in the CUDA Toolkit Documentation \u21a9","title":"nvtop"},{"location":"docs/user-guide/ondemand/","text":"Introduction # The Sherlock OnDemand interface allows you to conduct your research on Sherlock through a web browser. You can manage files (create, edit and move them), submit and monitor your jobs, see their output, check the status of the job queue, run a Jupyter notebook and much more, without logging in to Sherlock the traditional way, via a SSH terminal connection. Quote In neuroimaging there are a number of software pipelines that output HTML reports heavy on images files. Sherlock OnDemand allows users to check those as they appear on their $SCRATCH folder, for quick quality control, instead of having to mount remote filesystems, download data locally or move to any other storage location. Since the data itself is already quite big and costly to move, OnDemand is extremely helpful for fast assessment. -- Carolina Ramirez, Williams PANLab More documentation # Open OnDemand was created by the Ohio Supercomputer Center . The following documentation is specifically intended for using OnDemand on Sherlock. For more complete documentation about OnDemand in general, please see the extensive documentation for OnDemand created by OSC , including many video tutorials. Connecting # Connection information To connect to Sherlock OnDemand, simply point your browser to https://login.sherlock.stanford.edu Sherlock OnDemand requires the same level of authentication than connecting to Sherlock over SSH . You will be prompted for your SUNet ID and password, and will go through the regular two-step authentication process. The Sherlock OnDemand Dashboard will then open. From there, you can use the menus across the top of the page to manage files, get a shell on Sherlock, submit jobs or open interactive applications such as Jupyter Notebooks or RStudio sessions. To end your Sherlock OnDemand session, click on the \"Log Out\" link at the top right of the Dashboard window and close your browser. Getting a shell # You can get shell access to Sherlock by choosing Clusters > Sherlock Shell Access from the top menu in the OnDemand Dashboard . In the window that will open, you'll be logged in to one of Sherlock' login nodes, exactly as if you were using SSH to connect. Except you don't need to install any SSH client on your local machine, configure Kerberos or deal with your SSH client configuration to avoid endless two-factor prompts . How cool is that? Managing files # To create, edit or move files, click on the Files menu from the Dashboard page. A dropdown menu will appear, listing your most common storage locations on Sherlock: $HOME , $GROUP_HOME , $SCRATCH . $GROUP_SCRATCH and $OAK 1 . Choosing one of the file spaces opens the File Explorer in a new browser tab. The files in the selected directory are listed. Left panel will always display $HOME No matter which directory you are in, your home directory is displayed in a panel on the left. There are two sets of buttons in the File Explorer. On the top left, just below the name of the current directory: Those buttons allow you to View , Edit , Rename , Download , Copy , Paste (after you have moved to a different directory) or Delete a file, or you can toggle the file selection with (Un)Select All . At the top of the window, on the right side: Button Function Go To Navigate to another directory or file system Open in Terminal Open a terminal window on Sherlock in a new browser tab New File Create a new, empty file New Dir Create a new subdirectory Upload Copy a file from your local machine to Sherlock Show Dotfiles Toggle the display of dotfiles (files starting by a . , which are usually hidden) Show Owner/Mode Toggle the display of owner and permisson settings Creating and editing jobs # You can create new job scripts, edit existing scripts, and submit them to the scheduler throught the Sherlock OnDemand interface. From the top menus in the Dashboard , choose Jobs > Job Composer . A Job Composer window will open. There are two tabs at the top: Jobs and Templates . In the Jobs tab, you'll find a list of the job you've submitted through OnDemand. The Templates tab will allow you to define your own job templates. Creating a new job script # To create a new job script. you'll need to follow the steps below. Select a template # Go to the Jobs tab in the Jobs Composer interface. You'll find a default template there: \" Simple Sequential Job \". To create a new job script, click the blue New Job > From Default Template button in the upper left. You'll see a green message at the top of the page indicating: \"Job was successfully created\". At the right of the Jobs page, you can see the Job Details , including the location of the script and the script name (by default, main_job.sh ). Under that, you will see the contents of the job script in a section named Submit Script . Edit the job script # You'll need to edit the job script, so it contains the commands and workflow that you want to submit to the scheduler. If you need more resources than the defaults, you must include options to change them in the job script. For more details, see the Running jobs section. You can edit the script in several ways: click the blue Edit Files button at the top of the Jobs tab in the Jobs Composer window, in the Jobs tab in the Jobs Composer window, find the Submit Script section at the bottom right. Click the blue Open Editor button. After you save the file, the editor window remains open, but if you return to the Jobs Composer window, you will see that the content of your script has changed. Edit the job options # In the Jobs tab in the Jobs Composer window, click the blue Job Options button. The options for the selected job such as name, the job script to run, and the account it run under are displayed and can be edited. Click Save or Cancel to return to the job listing. Submitting jobs # To submit a job, select in in the Jobs tab in the Jobs Composer page. Click the green Submit button to submit the selected job. A message at the top of the window shows whether the job submission was successful or not. If it is not, you can edit the job script or options and resubmit. When the job is submitted successfully, the status of the job in the Jobs Composer window will change to Queued or Running . When the job completes, the status will change to Completed . Monitoring jobs # From the Dashboard page, The Jobs > Active Jobs top-level menu will bring you to a live view of Sherlock's scheduler queue. You'll be able to see all the jobs currently in queue, including running and pending jobs, as well as eome details about individual jobs. At the bottom of the detailled view, you'll find two button that will bring you to the directory where that job's files are located, either in the File Manager or in a Shell session. Interactive applications # One of the main features of Sherlock OnDemand is the ability to run interactive applications difrectly from the web interface, without leaving your web browser. Jupyter Notebooks # You can run Jupyter Notebooks (using Python, Julia or other languages) through Sherlock OnDemand. Some preliminary setup may be required Before running your first Jupyter Notebook with IJulia , you'll need to run the following steps (this only need to be done once): $ ml julia $ julia julia> using Pkg; julia> Pkg.add(\"IJulia\") When you see the message that IJulia has been installed, you can end your interactive session. To start a Jupyter session from Sherlock OnDemand: Select Interactive Apps > Jupyter Notebook from the top menu in the Dashboard page, In the screen that opens, specify the different parameters for your job (time limit, number of nodes, CPUs, partition to use, etc.). You can also choose to be notified by email when your notebook start. Click the blue Launch button to start your JupyterHub session. You may have to wait in the queue for resources to become available for you. When your session starts, you can click on the blue Connect to Jupyter button to open your Jupyter Notebook. The Dashboard window will display information about your Jupyter session, including the name of the compute node it is running on, when it started, and how much time remains. In your new Jupyter Notebook tab, you'll see 3 tabs: Files, Running and Clusters. By default, you are in the Files tab, that displays the contents of your $HOME directory on Sherlock. You can navigate through your files there. Under the Running tab, you will see the list of all the notebooks or terminal sessions that you have currently running. You can now start a Jupyter Notebook: To open an exiting Jupyter Notebook, which is already stored on Sherlock, navigate to its location in the Files tab and click on its name. A new window running the notebook will open. To create a new Jupyter Notebook, click on the New button at the top right of the file listing, and choose the kernel of your choice from the drop down. To terminate your Jupyter Notebook session, go back to the Dashboard, and click on the My Interactive Sessions in the top menu. This will bring you to a page listing all your currently active interactive session. Identify the one you'd like to terminate and click on the red Delete button. RStudio # To run RStudio via Sherlock OnDemand: Select Interactive Apps > RStudio Server from the top menu in the Dashboard page, In the screen that opens, specify the different parameters for your job (time limit, number of nodes, CPUs, partition to use, etc.). You can also choose to be notified by email when your notebook start. Click the blue Launch button to start your RStudio session. You may have to wait in the queue for resources to become available. When your session starts, click the blue Connect to RStudio Server button. A new window opens with the RStudio interface. Tensorboard # To run Tensorboard via Sherlock OnDemand: Select Interactive Apps > Tensorboard from the top menu in the Dashboard page, In the screen that opens, specify the different parameters for your job (time limit, number of nodes, CPUs, partition to use, etc.). You can also choose to be notified by email when your notebook start. Click the blue Launch button to start your Tensorboard session. You may have to wait in the queue for resources to become available. When your session starts, click the blue Connect to Tensorboard button. A new window opens with the Tensorboard interface. if you have access to the Oak storage system . \u21a9","title":"OnDemand"},{"location":"docs/user-guide/ondemand/#introduction","text":"The Sherlock OnDemand interface allows you to conduct your research on Sherlock through a web browser. You can manage files (create, edit and move them), submit and monitor your jobs, see their output, check the status of the job queue, run a Jupyter notebook and much more, without logging in to Sherlock the traditional way, via a SSH terminal connection. Quote In neuroimaging there are a number of software pipelines that output HTML reports heavy on images files. Sherlock OnDemand allows users to check those as they appear on their $SCRATCH folder, for quick quality control, instead of having to mount remote filesystems, download data locally or move to any other storage location. Since the data itself is already quite big and costly to move, OnDemand is extremely helpful for fast assessment. -- Carolina Ramirez, Williams PANLab","title":"Introduction"},{"location":"docs/user-guide/ondemand/#more-documentation","text":"Open OnDemand was created by the Ohio Supercomputer Center . The following documentation is specifically intended for using OnDemand on Sherlock. For more complete documentation about OnDemand in general, please see the extensive documentation for OnDemand created by OSC , including many video tutorials.","title":"More documentation"},{"location":"docs/user-guide/ondemand/#connecting","text":"Connection information To connect to Sherlock OnDemand, simply point your browser to https://login.sherlock.stanford.edu Sherlock OnDemand requires the same level of authentication than connecting to Sherlock over SSH . You will be prompted for your SUNet ID and password, and will go through the regular two-step authentication process. The Sherlock OnDemand Dashboard will then open. From there, you can use the menus across the top of the page to manage files, get a shell on Sherlock, submit jobs or open interactive applications such as Jupyter Notebooks or RStudio sessions. To end your Sherlock OnDemand session, click on the \"Log Out\" link at the top right of the Dashboard window and close your browser.","title":"Connecting"},{"location":"docs/user-guide/ondemand/#getting-a-shell","text":"You can get shell access to Sherlock by choosing Clusters > Sherlock Shell Access from the top menu in the OnDemand Dashboard . In the window that will open, you'll be logged in to one of Sherlock' login nodes, exactly as if you were using SSH to connect. Except you don't need to install any SSH client on your local machine, configure Kerberos or deal with your SSH client configuration to avoid endless two-factor prompts . How cool is that?","title":"Getting a shell"},{"location":"docs/user-guide/ondemand/#managing-files","text":"To create, edit or move files, click on the Files menu from the Dashboard page. A dropdown menu will appear, listing your most common storage locations on Sherlock: $HOME , $GROUP_HOME , $SCRATCH . $GROUP_SCRATCH and $OAK 1 . Choosing one of the file spaces opens the File Explorer in a new browser tab. The files in the selected directory are listed. Left panel will always display $HOME No matter which directory you are in, your home directory is displayed in a panel on the left. There are two sets of buttons in the File Explorer. On the top left, just below the name of the current directory: Those buttons allow you to View , Edit , Rename , Download , Copy , Paste (after you have moved to a different directory) or Delete a file, or you can toggle the file selection with (Un)Select All . At the top of the window, on the right side: Button Function Go To Navigate to another directory or file system Open in Terminal Open a terminal window on Sherlock in a new browser tab New File Create a new, empty file New Dir Create a new subdirectory Upload Copy a file from your local machine to Sherlock Show Dotfiles Toggle the display of dotfiles (files starting by a . , which are usually hidden) Show Owner/Mode Toggle the display of owner and permisson settings","title":"Managing files"},{"location":"docs/user-guide/ondemand/#creating-and-editing-jobs","text":"You can create new job scripts, edit existing scripts, and submit them to the scheduler throught the Sherlock OnDemand interface. From the top menus in the Dashboard , choose Jobs > Job Composer . A Job Composer window will open. There are two tabs at the top: Jobs and Templates . In the Jobs tab, you'll find a list of the job you've submitted through OnDemand. The Templates tab will allow you to define your own job templates.","title":"Creating and editing jobs"},{"location":"docs/user-guide/ondemand/#creating-a-new-job-script","text":"To create a new job script. you'll need to follow the steps below.","title":"Creating a new job script"},{"location":"docs/user-guide/ondemand/#select-a-template","text":"Go to the Jobs tab in the Jobs Composer interface. You'll find a default template there: \" Simple Sequential Job \". To create a new job script, click the blue New Job > From Default Template button in the upper left. You'll see a green message at the top of the page indicating: \"Job was successfully created\". At the right of the Jobs page, you can see the Job Details , including the location of the script and the script name (by default, main_job.sh ). Under that, you will see the contents of the job script in a section named Submit Script .","title":"Select a template"},{"location":"docs/user-guide/ondemand/#edit-the-job-script","text":"You'll need to edit the job script, so it contains the commands and workflow that you want to submit to the scheduler. If you need more resources than the defaults, you must include options to change them in the job script. For more details, see the Running jobs section. You can edit the script in several ways: click the blue Edit Files button at the top of the Jobs tab in the Jobs Composer window, in the Jobs tab in the Jobs Composer window, find the Submit Script section at the bottom right. Click the blue Open Editor button. After you save the file, the editor window remains open, but if you return to the Jobs Composer window, you will see that the content of your script has changed.","title":"Edit the job script"},{"location":"docs/user-guide/ondemand/#edit-the-job-options","text":"In the Jobs tab in the Jobs Composer window, click the blue Job Options button. The options for the selected job such as name, the job script to run, and the account it run under are displayed and can be edited. Click Save or Cancel to return to the job listing.","title":"Edit the job options"},{"location":"docs/user-guide/ondemand/#submitting-jobs","text":"To submit a job, select in in the Jobs tab in the Jobs Composer page. Click the green Submit button to submit the selected job. A message at the top of the window shows whether the job submission was successful or not. If it is not, you can edit the job script or options and resubmit. When the job is submitted successfully, the status of the job in the Jobs Composer window will change to Queued or Running . When the job completes, the status will change to Completed .","title":"Submitting jobs"},{"location":"docs/user-guide/ondemand/#monitoring-jobs","text":"From the Dashboard page, The Jobs > Active Jobs top-level menu will bring you to a live view of Sherlock's scheduler queue. You'll be able to see all the jobs currently in queue, including running and pending jobs, as well as eome details about individual jobs. At the bottom of the detailled view, you'll find two button that will bring you to the directory where that job's files are located, either in the File Manager or in a Shell session.","title":"Monitoring jobs"},{"location":"docs/user-guide/ondemand/#interactive-applications","text":"One of the main features of Sherlock OnDemand is the ability to run interactive applications difrectly from the web interface, without leaving your web browser.","title":"Interactive applications"},{"location":"docs/user-guide/ondemand/#jupyter-notebooks","text":"You can run Jupyter Notebooks (using Python, Julia or other languages) through Sherlock OnDemand. Some preliminary setup may be required Before running your first Jupyter Notebook with IJulia , you'll need to run the following steps (this only need to be done once): $ ml julia $ julia julia> using Pkg; julia> Pkg.add(\"IJulia\") When you see the message that IJulia has been installed, you can end your interactive session. To start a Jupyter session from Sherlock OnDemand: Select Interactive Apps > Jupyter Notebook from the top menu in the Dashboard page, In the screen that opens, specify the different parameters for your job (time limit, number of nodes, CPUs, partition to use, etc.). You can also choose to be notified by email when your notebook start. Click the blue Launch button to start your JupyterHub session. You may have to wait in the queue for resources to become available for you. When your session starts, you can click on the blue Connect to Jupyter button to open your Jupyter Notebook. The Dashboard window will display information about your Jupyter session, including the name of the compute node it is running on, when it started, and how much time remains. In your new Jupyter Notebook tab, you'll see 3 tabs: Files, Running and Clusters. By default, you are in the Files tab, that displays the contents of your $HOME directory on Sherlock. You can navigate through your files there. Under the Running tab, you will see the list of all the notebooks or terminal sessions that you have currently running. You can now start a Jupyter Notebook: To open an exiting Jupyter Notebook, which is already stored on Sherlock, navigate to its location in the Files tab and click on its name. A new window running the notebook will open. To create a new Jupyter Notebook, click on the New button at the top right of the file listing, and choose the kernel of your choice from the drop down. To terminate your Jupyter Notebook session, go back to the Dashboard, and click on the My Interactive Sessions in the top menu. This will bring you to a page listing all your currently active interactive session. Identify the one you'd like to terminate and click on the red Delete button.","title":"Jupyter Notebooks"},{"location":"docs/user-guide/ondemand/#rstudio","text":"To run RStudio via Sherlock OnDemand: Select Interactive Apps > RStudio Server from the top menu in the Dashboard page, In the screen that opens, specify the different parameters for your job (time limit, number of nodes, CPUs, partition to use, etc.). You can also choose to be notified by email when your notebook start. Click the blue Launch button to start your RStudio session. You may have to wait in the queue for resources to become available. When your session starts, click the blue Connect to RStudio Server button. A new window opens with the RStudio interface.","title":"RStudio"},{"location":"docs/user-guide/ondemand/#tensorboard","text":"To run Tensorboard via Sherlock OnDemand: Select Interactive Apps > Tensorboard from the top menu in the Dashboard page, In the screen that opens, specify the different parameters for your job (time limit, number of nodes, CPUs, partition to use, etc.). You can also choose to be notified by email when your notebook start. Click the blue Launch button to start your Tensorboard session. You may have to wait in the queue for resources to become available. When your session starts, click the blue Connect to Tensorboard button. A new window opens with the Tensorboard interface. if you have access to the Oak storage system . \u21a9","title":"Tensorboard"},{"location":"docs/user-guide/running-jobs/","text":"Login nodes # Login nodes are not for computing Login nodes are shared among many users and therefore must not be used to run computationally intensive tasks. Those should be submitted to the scheduler which will dispatch them on compute nodes. The key principle of a shared computing environment is that resources are shared among users and must be scheduled. It is mandatory to schedule work by submitting jobs to the scheduler on Sherlock. And since login nodes are a shared resource, they must not be used to execute computing tasks. Acceptable use of login nodes include: lightweight file transfers, script and configuration file editing, job submission and monitoring. Resource limits are enforced To minimize disruption and ensure a confortable working environment for users, resource limits are enforced on login nodes, and processes started there will automatically be terminated if their resource usage (including CPU time, memory and run time) exceed those limits. Slurm commands # Slurm allows requesting resources and submitting jobs in a variety of ways. The main Slurm commands to submit jobs are listed in the table below: Command Description Behavior salloc Request resources and allocates them to a job Starts a new shell, but does not execute anything srun Request resources and runs a command on the allocated compute node(s) Blocking command: will not return until the job ends sbatch Request resources and runs a script on the allocated compute node(s) Asynchronous command: will return as soon as the job is submitted Interactive jobs # Dedicated nodes # Interactive jobs allow users to log in to a compute node to run commands interactively on the command line. They could be an integral part of an interactive programming and debugging workflow. The simplest way to establish an interactive session on Sherlock is to use the sdev command: $ sdev This will open a login shell using one core and 4 GB of memory on one node for one hour. The sdev sessions run on dedicated compute nodes. This ensures minimal wait times when you need to access a node for testing script, debug code or any kind of interactive work. sdev also provides X11 forwarding via the submission host (typically the login node you're connected to) and can thus be used to run GUI applications. Compute nodes # If you need more resources 1 , you can pass options to sdev , to request more CPU cores, more nodes, or even run in a different partition. sdev -h will provide more information: $ sdev -h sdev: start an interactive shell on a compute node. Usage: sdev [ OPTIONS ] Optional arguments: -c number of CPU cores to request ( OpenMP/pthreads, default: 1 ) -n number of tasks to request ( MPI ranks, default: 1 ) -N number of nodes to request ( default: 1 ) -m memory amount to request ( default: 4GB ) -p partition to run the job in ( default: dev ) -t time limit ( default: 01 :00:00 ) -r allocate resources from the named reservation ( default: none ) -J job name ( default: sdev ) -q quality of service to request for the job ( default: normal ) Note: the default partition only allows for limited amount of resources. If you need more, your job will be rejected unless you specify an alternative partition with -p. Another way to get an interactive session on a compute node is to use srun to execute a shell through the scheduler. For instance, to start a bash session on a compute node, with the default resource requirements (one core for 2 hours), you can run: $ srun --pty bash The main advantage of this approach is that it will allow you to specify the whole range of submission options that sdev may not support. Finally, if you prefer to submit an existing job script or other executable as an interactive job, you can use the salloc command: $ salloc script.sh If you don't provide a command to execute, salloc will start a Slurm job and allocate resources for it, but it will not automatically connect you to the allocated node(s). It will only start a new shell on the same node you launched salloc from, and set up the appropriate $SLURM_* environment variables. So you will typically need to look at them to see what nodes have been assigned to your job. For instance: $ salloc salloc: Granted job allocation 655914 $ echo $SLURM_NODELIST sh02-01n55 $ ssh sh02-01n55 [ ... ] sh02-01n55 ~ $ Connecting to nodes # Login to compute nodes Users are not allowed to login to compute nodes unless they have a job running there. If you SSH to a compute node without any active job allocation, you'll be greeted by the following message: $ ssh sh02-01n01 Access denied by pam_slurm_adopt: you have no active jobs on this node Connection closed $ Once you have a job running on a node, you can SSH directly to it and run additional processes 2 , or observe how you application behaves, debug issues, and so on. The salloc command supports the same parameters as sbatch , and can override any default configuration. Note that any #SBATCH directive in your job script will not be interpreted by salloc when it is executed in this way. You must specify all arguments directly on the command line for them to be taken into account. Batch jobs # Work in progress This page is a work in progress and is not complete yet. We are actively working on adding more content and information. Available resources # Whether you are submitting a batch job , or an or interactive job , it's important to know the resources that are available to you. For this reason, we provide sh_part , a command-line tool to help answer questions such as: which partitions do I have access to? how many jobs are running on them? how many CPUs can I use? where should I submit my jobs? sh_part can be executed on any login or compute node to see what partitions are available to you, and its output looks like this: $ sh_part QUEUE STA FREE TOTAL FREE TOTAL RESORC OTHER MAXJOBTIME CORES NODE GRES PARTITION TUS CORES CORES NODES NODES PENDNG PENDNG DAY-HR:MN /NODE MEM-GB (COUNT) normal * 153 1792 0 84 23k 127 7-00:00 20-24 128-191 - bigmem 29 88 0 2 0 8 1-00:00 32-56 512-3072 - dev 31 40 0 2 0 0 0-02:00 20 128 - gpu 47 172 0 8 116 1 7-00:00 20-24 191-256 gpu:4(S:0-1)(2),gpu:4(S:0)(6) The above example shows four possible partitions where jobs can be submitted: normal, bigmem, dev, or gpu. It also provides additional information such as the maximum amount of time allowed in each partition ( MAXJOBTIME ), the number of other jobs already in queue, along with the ranges of memory available on nodes in each partition. in the QUEUE PARTITION column, the * character indicates the default partition. the RESOURCE PENDING column shows the core count of pending jobs that are waiting on resources, the OTHER PENDING column lists core counts for jobs that are pending for other reasons, such as licenses, user, group or any other limit, the GRES column shows the number and type of Generic RESsources available in that partition (typically, GPUs), whichi CPU socket tehy're available from, and the number of nodes that feature that specific GRES combination. So for instance, in the output above, gpu:4(S:0-1)(2) means that the gpu partition features 2 nodes with 4 GPUs each, and that those GPUs are accessible from both CPU sockets ( S:0-1 ). Recurring jobs # Warning Cron tasks are not supported on Sherlock. Users are not allowed to create cron jobs on Sherlock, for a variety of reasons: resources limits cannot be easily enforced in cron jobs, meaning that a single user can end up monopolizing all the resources of a login node, no amount of resources can be guaranteed when executing a cron job, leading to unreliable runtime and performance, user cron jobs have the potential of bringing down whole nodes by creating fork bombs, if they're not carefully crafted and tested, compute and login nodes could be redeployed at any time, meaning that cron jobs scheduled there could go away without the user being notified, and cause all sorts of unexpected results, cron jobs could be mistakenly scheduled on several nodes and run multiple times, which could result in corrupted files. As an alternative, if you need to run recurring tasks at regular intervals, we recommend the following approach: by using the --begin job submission option, and creating a job that resubmits itself once it's done, you can virtually emulate the behavior and benefits of a cron job, without its disadvantages: your task will be scheduled on a compute node, and use all of the resources it requested, without being impacted by anything else. Depending on your recurring job's specificities, where you submit it and the state of the cluster at the time of execution, the starting time of that task may not be guaranteed and result in a delay in execution, as it will be scheduled by Slurm like any other jobs. Typical recurring jobs, such as file synchronization, database updates or backup tasks don't require strict starting times, though, so most users find this an acceptable trade-off. The table below summarizes the advantages and inconvenients of each approach: Cron tasks Recurring jobs Authorized on Sherlock Dedicated resources for the task Persistent across node redeployments Unique, controlled execution Precise schedule Recurrent job example # The script below presents an example of such a recurrent job, that would emulate a cron task. It will append a timestamped line to a cron.log file in your $HOME directory and run every 7 days. cron.sbatch #!/bin/bash #SBATCH --job-name=cron #SBATCH --begin=now+7days #SBATCH --dependency=singleton #SBATCH --time=00:02:00 #SBATCH --mail-type=FAIL ## Insert the command to run below. Here, we're just storing the date in a ## cron.log file date -R >> $HOME /cron.log ## Resubmit the job for the next execution sbatch $0 If the job payload (here the date command) fails for some reason and generates and error, the job will not be resubmitted, and the user will be notified by email. We encourage users to get familiar with the submission options used in this script by giving a look at the sbatch man page , but some details are given below: Submission option or command Explanation --job-name=cron makes it easy to identify the job, is used by the --dependency=singleton option to identify identical jobs, and will allow cancelling the job by name (because its jobid will change each time it's submitted) --begin=now+7days will instruct the scheduler to not even consider the job for scheduling before 7 days after it's been submitted --dependency=singleton will make sure that only one cron job runs at any given time --time=00:02:00 runtime limit for the job (here 2 minutes). You'll need to adjust the value depending on the task you need to run (shorter runtime requests usually result in the job running closer to the clock mark) --mail-type=FAIL will send an email notification to the user if the job ever fails sbatch $0 will resubmit the job script by calling its own name ( $0 ) after successful execution You can save the script as cron.sbatch or any other name, and submit it with: $ sbatch cron.sbatch It will start running for the first time 7 days after you submit it, and it will continue to run until you cancel it with the following command (using the job name, as defined by the --job-name option): $ scancel -n cron Persistent jobs # Recurring jobs described above are a good way to emulate cron jobs on Sherlock, but don't fit all needs, especially when a persistent service is required. For instance, workflows that require a persistent database connection would benefit from an ever-running database server instance. We don't provide persistent database services on Sherlock, but instructions and examples on how to submit database server jobs are provided for MariaDB or PostgreSQL . In case those database instances need to run pretty much continuously (within the limits of available resources and runtime maximums), the previous approach described in the recurring jobs section could fall a bit short. Recurring jobs are mainly designed for jobs that have a fixed execution time and don't reach their time limit, but need to run at given intervals (like synchronization or backup jobs, for instance). Because a database server process will never end within the job, and will continue until the job reaches its time limit, the last resubmission command ( sbatch $0 ) will actually never be executed, and the job won't be resubmitted. To work around this, a possible approach is to catch a specific signal sent by the scheduler at a predefined time, before the time limit is reached, and then re-queue the job. This is easily done with the Bash trap command, which can be instructed to re-submit a job when it receives the SIGUSR1 signal. Automatically resubmitting a job doesn't make it immediately runnable Jobs that are automatically re-submitted using this technique won't restart right away: the will get back in queue and stay pending until their execution conditions (priority, resources, usage limits...) are satisfied. Persistent job example # Here's the recurring job example from above, modified to: instruct the scheduler to send a SIGUSR1 signal to the job 90 seconds 3 before reaching its time limit (with the #SBATCH --signal option), re-submit itself upon receiving that SIGUSR1 signal (with the trap command) persistent.sbatch #!/bin/bash # #SBATCH --job-name=persistent #SBATCH --dependency=singleton #SBATCH --time=00:05:00 #SBATCH --signal=B:SIGUSR1@90 # catch the SIGUSR1 signal _resubmit () { ## Resubmit the job for the next execution echo \" $( date ) : job $SLURM_JOBID received SIGUSR1 at $( date ) , re-submitting\" sbatch $0 } trap _resubmit SIGUSR1 ## Insert the command to run below. Here, we're just outputing the date every ## 10 seconds, forever echo \" $( date ) : job $SLURM_JOBID starting on $SLURM_NODELIST \" while true ; do echo \" $( date ) : normal execution\" sleep 60 done Long running processes need to run in the background If your job's actual payload (the application or command you want to run) is running continuously for the whole duration of the job, it needs to be executed in the background, so the trap can be processed. To run your application in the background, just add a & at the end of the command and then add a wait statement at the end of the script, to make the shell wait until the end of the job. For instance, if you were to run a PostgreSQL database server , the while true ... done loop in the previous example could be replaced by something like this: postgres -i -D $DB_DIR & wait Persistent $JOBID # One potential issue with having a persistent job re-submit itself when it reaches its runtime limit is that it will get a different $JOBID each time it's (re-)submitted. This could be particularly challenging when other jobs depend on it, like in the database server scenario, where client jobs would need to start only if the database server is running. This can be achieved with job dependencies , but those dependencies have to be expressed using jobids, so having the server job's id changing at each re-submission will be difficult to handle. To avoid this, the re-submission command ( sbatch $0 ) can be replaced by a re-queuing command: scontrol requeue $SLURM_JOBID The benefit of that change is that the job will keep the same $JOBID across all re-submissions. And now, dependencies can be added to other jobs using that specific $JOBID , without having to worry about it changing. And there will be only one $JOBID to track for that database server job. The previous example can then be modified as follows: persistent.sbatch #!/bin/bash #SBATCH --job-name=persistent #SBATCH --dependency=singleton #SBATCH --time=00:05:00 #SBATCH --signal=B:SIGUSR1@90 # catch the SIGUSR1 signal _requeue () { echo \" $( date ) : job $SLURM_JOBID received SIGUSR1, re-queueing\" scontrol requeue $SLURM_JOBID } trap '_requeue' SIGUSR1 ## Insert the command to run below. Here, we're just outputing the date every ## 60 seconds, forever echo \" $( date ) : job $SLURM_JOBID starting on $SLURM_NODELIST \" while true ; do echo \" $( date ) : normal execution\" sleep 60 done Submitting that job will produce an output similar to this: Mon Nov 5 10 :30:59 PST 2018 : Job 31182239 starting on sh-06-34 Mon Nov 5 10 :30:59 PST 2018 : normal execution Mon Nov 5 10 :31:59 PST 2018 : normal execution Mon Nov 5 10 :32:59 PST 2018 : normal execution Mon Nov 5 10 :33:59 PST 2018 : normal execution Mon Nov 5 10 :34:59 PST 2018 : Job 31182239 received SIGUSR1, re-queueing slurmstepd: error: *** JOB 31182239 ON sh-06-34 CANCELLED AT 2018 -11-05T10:35:06 DUE TO JOB REQUEUE *** Mon Nov 5 10 :38:11 PST 2018 : Job 31182239 starting on sh-06-34 Mon Nov 5 10 :38:11 PST 2018 : normal execution Mon Nov 5 10 :39:11 PST 2018 : normal execution The job runs for 5 minutes, then received the SIGUSR1 signal, is re-queued, restarts for 5 minutes, and so on, until it's properly scancel led. The dedicated partition that sdev uses by default only allows up to 2 cores and 8 GB or memory per user at any given time. So if you need more resources for your interactive session, you may have to specify a different partition. See the Partitions section for more details. \u21a9 Please note that your SSH session will be attached to your running job, and that resources used by that interactive shell will count towards your job's resource limits. So if you start a process using large amounts of memory via SSH while your job is running, you may hit the job's memory limits, which will trigger its termination. \u21a9 Due to the resolution of event handling by the scheduler, the signal may be sent up to 60 seconds earlier than specified. \u21a9","title":"Running jobs"},{"location":"docs/user-guide/running-jobs/#login-nodes","text":"Login nodes are not for computing Login nodes are shared among many users and therefore must not be used to run computationally intensive tasks. Those should be submitted to the scheduler which will dispatch them on compute nodes. The key principle of a shared computing environment is that resources are shared among users and must be scheduled. It is mandatory to schedule work by submitting jobs to the scheduler on Sherlock. And since login nodes are a shared resource, they must not be used to execute computing tasks. Acceptable use of login nodes include: lightweight file transfers, script and configuration file editing, job submission and monitoring. Resource limits are enforced To minimize disruption and ensure a confortable working environment for users, resource limits are enforced on login nodes, and processes started there will automatically be terminated if their resource usage (including CPU time, memory and run time) exceed those limits.","title":"Login nodes"},{"location":"docs/user-guide/running-jobs/#slurm-commands","text":"Slurm allows requesting resources and submitting jobs in a variety of ways. The main Slurm commands to submit jobs are listed in the table below: Command Description Behavior salloc Request resources and allocates them to a job Starts a new shell, but does not execute anything srun Request resources and runs a command on the allocated compute node(s) Blocking command: will not return until the job ends sbatch Request resources and runs a script on the allocated compute node(s) Asynchronous command: will return as soon as the job is submitted","title":"Slurm commands"},{"location":"docs/user-guide/running-jobs/#interactive-jobs","text":"","title":"Interactive jobs"},{"location":"docs/user-guide/running-jobs/#dedicated-nodes","text":"Interactive jobs allow users to log in to a compute node to run commands interactively on the command line. They could be an integral part of an interactive programming and debugging workflow. The simplest way to establish an interactive session on Sherlock is to use the sdev command: $ sdev This will open a login shell using one core and 4 GB of memory on one node for one hour. The sdev sessions run on dedicated compute nodes. This ensures minimal wait times when you need to access a node for testing script, debug code or any kind of interactive work. sdev also provides X11 forwarding via the submission host (typically the login node you're connected to) and can thus be used to run GUI applications.","title":"Dedicated nodes"},{"location":"docs/user-guide/running-jobs/#compute-nodes","text":"If you need more resources 1 , you can pass options to sdev , to request more CPU cores, more nodes, or even run in a different partition. sdev -h will provide more information: $ sdev -h sdev: start an interactive shell on a compute node. Usage: sdev [ OPTIONS ] Optional arguments: -c number of CPU cores to request ( OpenMP/pthreads, default: 1 ) -n number of tasks to request ( MPI ranks, default: 1 ) -N number of nodes to request ( default: 1 ) -m memory amount to request ( default: 4GB ) -p partition to run the job in ( default: dev ) -t time limit ( default: 01 :00:00 ) -r allocate resources from the named reservation ( default: none ) -J job name ( default: sdev ) -q quality of service to request for the job ( default: normal ) Note: the default partition only allows for limited amount of resources. If you need more, your job will be rejected unless you specify an alternative partition with -p. Another way to get an interactive session on a compute node is to use srun to execute a shell through the scheduler. For instance, to start a bash session on a compute node, with the default resource requirements (one core for 2 hours), you can run: $ srun --pty bash The main advantage of this approach is that it will allow you to specify the whole range of submission options that sdev may not support. Finally, if you prefer to submit an existing job script or other executable as an interactive job, you can use the salloc command: $ salloc script.sh If you don't provide a command to execute, salloc will start a Slurm job and allocate resources for it, but it will not automatically connect you to the allocated node(s). It will only start a new shell on the same node you launched salloc from, and set up the appropriate $SLURM_* environment variables. So you will typically need to look at them to see what nodes have been assigned to your job. For instance: $ salloc salloc: Granted job allocation 655914 $ echo $SLURM_NODELIST sh02-01n55 $ ssh sh02-01n55 [ ... ] sh02-01n55 ~ $","title":"Compute nodes"},{"location":"docs/user-guide/running-jobs/#connecting-to-nodes","text":"Login to compute nodes Users are not allowed to login to compute nodes unless they have a job running there. If you SSH to a compute node without any active job allocation, you'll be greeted by the following message: $ ssh sh02-01n01 Access denied by pam_slurm_adopt: you have no active jobs on this node Connection closed $ Once you have a job running on a node, you can SSH directly to it and run additional processes 2 , or observe how you application behaves, debug issues, and so on. The salloc command supports the same parameters as sbatch , and can override any default configuration. Note that any #SBATCH directive in your job script will not be interpreted by salloc when it is executed in this way. You must specify all arguments directly on the command line for them to be taken into account.","title":"Connecting to nodes"},{"location":"docs/user-guide/running-jobs/#batch-jobs","text":"Work in progress This page is a work in progress and is not complete yet. We are actively working on adding more content and information.","title":"Batch jobs"},{"location":"docs/user-guide/running-jobs/#available-resources","text":"Whether you are submitting a batch job , or an or interactive job , it's important to know the resources that are available to you. For this reason, we provide sh_part , a command-line tool to help answer questions such as: which partitions do I have access to? how many jobs are running on them? how many CPUs can I use? where should I submit my jobs? sh_part can be executed on any login or compute node to see what partitions are available to you, and its output looks like this: $ sh_part QUEUE STA FREE TOTAL FREE TOTAL RESORC OTHER MAXJOBTIME CORES NODE GRES PARTITION TUS CORES CORES NODES NODES PENDNG PENDNG DAY-HR:MN /NODE MEM-GB (COUNT) normal * 153 1792 0 84 23k 127 7-00:00 20-24 128-191 - bigmem 29 88 0 2 0 8 1-00:00 32-56 512-3072 - dev 31 40 0 2 0 0 0-02:00 20 128 - gpu 47 172 0 8 116 1 7-00:00 20-24 191-256 gpu:4(S:0-1)(2),gpu:4(S:0)(6) The above example shows four possible partitions where jobs can be submitted: normal, bigmem, dev, or gpu. It also provides additional information such as the maximum amount of time allowed in each partition ( MAXJOBTIME ), the number of other jobs already in queue, along with the ranges of memory available on nodes in each partition. in the QUEUE PARTITION column, the * character indicates the default partition. the RESOURCE PENDING column shows the core count of pending jobs that are waiting on resources, the OTHER PENDING column lists core counts for jobs that are pending for other reasons, such as licenses, user, group or any other limit, the GRES column shows the number and type of Generic RESsources available in that partition (typically, GPUs), whichi CPU socket tehy're available from, and the number of nodes that feature that specific GRES combination. So for instance, in the output above, gpu:4(S:0-1)(2) means that the gpu partition features 2 nodes with 4 GPUs each, and that those GPUs are accessible from both CPU sockets ( S:0-1 ).","title":"Available resources"},{"location":"docs/user-guide/running-jobs/#recurring-jobs","text":"Warning Cron tasks are not supported on Sherlock. Users are not allowed to create cron jobs on Sherlock, for a variety of reasons: resources limits cannot be easily enforced in cron jobs, meaning that a single user can end up monopolizing all the resources of a login node, no amount of resources can be guaranteed when executing a cron job, leading to unreliable runtime and performance, user cron jobs have the potential of bringing down whole nodes by creating fork bombs, if they're not carefully crafted and tested, compute and login nodes could be redeployed at any time, meaning that cron jobs scheduled there could go away without the user being notified, and cause all sorts of unexpected results, cron jobs could be mistakenly scheduled on several nodes and run multiple times, which could result in corrupted files. As an alternative, if you need to run recurring tasks at regular intervals, we recommend the following approach: by using the --begin job submission option, and creating a job that resubmits itself once it's done, you can virtually emulate the behavior and benefits of a cron job, without its disadvantages: your task will be scheduled on a compute node, and use all of the resources it requested, without being impacted by anything else. Depending on your recurring job's specificities, where you submit it and the state of the cluster at the time of execution, the starting time of that task may not be guaranteed and result in a delay in execution, as it will be scheduled by Slurm like any other jobs. Typical recurring jobs, such as file synchronization, database updates or backup tasks don't require strict starting times, though, so most users find this an acceptable trade-off. The table below summarizes the advantages and inconvenients of each approach: Cron tasks Recurring jobs Authorized on Sherlock Dedicated resources for the task Persistent across node redeployments Unique, controlled execution Precise schedule","title":"Recurring jobs"},{"location":"docs/user-guide/running-jobs/#recurrent-job-example","text":"The script below presents an example of such a recurrent job, that would emulate a cron task. It will append a timestamped line to a cron.log file in your $HOME directory and run every 7 days. cron.sbatch #!/bin/bash #SBATCH --job-name=cron #SBATCH --begin=now+7days #SBATCH --dependency=singleton #SBATCH --time=00:02:00 #SBATCH --mail-type=FAIL ## Insert the command to run below. Here, we're just storing the date in a ## cron.log file date -R >> $HOME /cron.log ## Resubmit the job for the next execution sbatch $0 If the job payload (here the date command) fails for some reason and generates and error, the job will not be resubmitted, and the user will be notified by email. We encourage users to get familiar with the submission options used in this script by giving a look at the sbatch man page , but some details are given below: Submission option or command Explanation --job-name=cron makes it easy to identify the job, is used by the --dependency=singleton option to identify identical jobs, and will allow cancelling the job by name (because its jobid will change each time it's submitted) --begin=now+7days will instruct the scheduler to not even consider the job for scheduling before 7 days after it's been submitted --dependency=singleton will make sure that only one cron job runs at any given time --time=00:02:00 runtime limit for the job (here 2 minutes). You'll need to adjust the value depending on the task you need to run (shorter runtime requests usually result in the job running closer to the clock mark) --mail-type=FAIL will send an email notification to the user if the job ever fails sbatch $0 will resubmit the job script by calling its own name ( $0 ) after successful execution You can save the script as cron.sbatch or any other name, and submit it with: $ sbatch cron.sbatch It will start running for the first time 7 days after you submit it, and it will continue to run until you cancel it with the following command (using the job name, as defined by the --job-name option): $ scancel -n cron","title":"Recurrent job example"},{"location":"docs/user-guide/running-jobs/#persistent-jobs","text":"Recurring jobs described above are a good way to emulate cron jobs on Sherlock, but don't fit all needs, especially when a persistent service is required. For instance, workflows that require a persistent database connection would benefit from an ever-running database server instance. We don't provide persistent database services on Sherlock, but instructions and examples on how to submit database server jobs are provided for MariaDB or PostgreSQL . In case those database instances need to run pretty much continuously (within the limits of available resources and runtime maximums), the previous approach described in the recurring jobs section could fall a bit short. Recurring jobs are mainly designed for jobs that have a fixed execution time and don't reach their time limit, but need to run at given intervals (like synchronization or backup jobs, for instance). Because a database server process will never end within the job, and will continue until the job reaches its time limit, the last resubmission command ( sbatch $0 ) will actually never be executed, and the job won't be resubmitted. To work around this, a possible approach is to catch a specific signal sent by the scheduler at a predefined time, before the time limit is reached, and then re-queue the job. This is easily done with the Bash trap command, which can be instructed to re-submit a job when it receives the SIGUSR1 signal. Automatically resubmitting a job doesn't make it immediately runnable Jobs that are automatically re-submitted using this technique won't restart right away: the will get back in queue and stay pending until their execution conditions (priority, resources, usage limits...) are satisfied.","title":"Persistent jobs"},{"location":"docs/user-guide/running-jobs/#persistent-job-example","text":"Here's the recurring job example from above, modified to: instruct the scheduler to send a SIGUSR1 signal to the job 90 seconds 3 before reaching its time limit (with the #SBATCH --signal option), re-submit itself upon receiving that SIGUSR1 signal (with the trap command) persistent.sbatch #!/bin/bash # #SBATCH --job-name=persistent #SBATCH --dependency=singleton #SBATCH --time=00:05:00 #SBATCH --signal=B:SIGUSR1@90 # catch the SIGUSR1 signal _resubmit () { ## Resubmit the job for the next execution echo \" $( date ) : job $SLURM_JOBID received SIGUSR1 at $( date ) , re-submitting\" sbatch $0 } trap _resubmit SIGUSR1 ## Insert the command to run below. Here, we're just outputing the date every ## 10 seconds, forever echo \" $( date ) : job $SLURM_JOBID starting on $SLURM_NODELIST \" while true ; do echo \" $( date ) : normal execution\" sleep 60 done Long running processes need to run in the background If your job's actual payload (the application or command you want to run) is running continuously for the whole duration of the job, it needs to be executed in the background, so the trap can be processed. To run your application in the background, just add a & at the end of the command and then add a wait statement at the end of the script, to make the shell wait until the end of the job. For instance, if you were to run a PostgreSQL database server , the while true ... done loop in the previous example could be replaced by something like this: postgres -i -D $DB_DIR & wait","title":"Persistent job example"},{"location":"docs/user-guide/running-jobs/#persistent-jobid","text":"One potential issue with having a persistent job re-submit itself when it reaches its runtime limit is that it will get a different $JOBID each time it's (re-)submitted. This could be particularly challenging when other jobs depend on it, like in the database server scenario, where client jobs would need to start only if the database server is running. This can be achieved with job dependencies , but those dependencies have to be expressed using jobids, so having the server job's id changing at each re-submission will be difficult to handle. To avoid this, the re-submission command ( sbatch $0 ) can be replaced by a re-queuing command: scontrol requeue $SLURM_JOBID The benefit of that change is that the job will keep the same $JOBID across all re-submissions. And now, dependencies can be added to other jobs using that specific $JOBID , without having to worry about it changing. And there will be only one $JOBID to track for that database server job. The previous example can then be modified as follows: persistent.sbatch #!/bin/bash #SBATCH --job-name=persistent #SBATCH --dependency=singleton #SBATCH --time=00:05:00 #SBATCH --signal=B:SIGUSR1@90 # catch the SIGUSR1 signal _requeue () { echo \" $( date ) : job $SLURM_JOBID received SIGUSR1, re-queueing\" scontrol requeue $SLURM_JOBID } trap '_requeue' SIGUSR1 ## Insert the command to run below. Here, we're just outputing the date every ## 60 seconds, forever echo \" $( date ) : job $SLURM_JOBID starting on $SLURM_NODELIST \" while true ; do echo \" $( date ) : normal execution\" sleep 60 done Submitting that job will produce an output similar to this: Mon Nov 5 10 :30:59 PST 2018 : Job 31182239 starting on sh-06-34 Mon Nov 5 10 :30:59 PST 2018 : normal execution Mon Nov 5 10 :31:59 PST 2018 : normal execution Mon Nov 5 10 :32:59 PST 2018 : normal execution Mon Nov 5 10 :33:59 PST 2018 : normal execution Mon Nov 5 10 :34:59 PST 2018 : Job 31182239 received SIGUSR1, re-queueing slurmstepd: error: *** JOB 31182239 ON sh-06-34 CANCELLED AT 2018 -11-05T10:35:06 DUE TO JOB REQUEUE *** Mon Nov 5 10 :38:11 PST 2018 : Job 31182239 starting on sh-06-34 Mon Nov 5 10 :38:11 PST 2018 : normal execution Mon Nov 5 10 :39:11 PST 2018 : normal execution The job runs for 5 minutes, then received the SIGUSR1 signal, is re-queued, restarts for 5 minutes, and so on, until it's properly scancel led. The dedicated partition that sdev uses by default only allows up to 2 cores and 8 GB or memory per user at any given time. So if you need more resources for your interactive session, you may have to specify a different partition. See the Partitions section for more details. \u21a9 Please note that your SSH session will be attached to your running job, and that resources used by that interactive shell will count towards your job's resource limits. So if you start a process using large amounts of memory via SSH while your job is running, you may hit the job's memory limits, which will trigger its termination. \u21a9 Due to the resolution of event handling by the scheduler, the signal may be sent up to 60 seconds earlier than specified. \u21a9","title":"Persistent $JOBID"},{"location":"docs/user-guide/troubleshoot/","text":"Sherlock is a resource for ressearch, and as such, it is in perpetual evolution, as hardware, applications, libraries, and modules are added, updated, and/or modified on a regular basis. Sometimes issues can appear where none existed before. When you find something missing or a behavior that seems odd, please let us know . How to submit a support request # Google it first! When encountering issues with software, if the misbehavior involves an error message, the first step should always be to look up the error message online. There's a good chance somebody stumbled upon the same hurdles before, and may even provide some fix or workaround. One of the most helpful Google searches is your_application sbatch . For example if you're having trouble submitting jobs or allocating resources (CPUs, time, memory) with Cell Ranger, search for cellranger sbatch to see how others have successfully run your application on a cluster. If you're facing issues you can't figure out, we're here to help. Feel free to email us at srcc-support@stanford.edu , but please keep the following points in mind to ensure a timely and relevant response to your support requests. Please provide relevant information We need to understand the issue you're facing, and in most cases, we need to be able to reproduce it , so it could be diagnosed and addressed. Please make sure to provide enough information so we could help you in the best possible way. This typically involves providing the following information: your SUNet ID, some context about your problem (were you submitting a job, copying a file, compiling an application?), if relevant, the full path to the files involved in your question or problem, the name of node where you received the error (usually displayed in your command-line prompt), the command(s) you ran, and/or the job submission script(s) you used, the relevant job ID(s), the exact , entire error message (or trace) you received. Error messages are critical This is very important. Without proper error messages, there is nothing we can do to help. And \" it doesn't work \" is not a proper error message. You can avoid email back and forth where we ask for all the relevant details, and thus delay the problem resolution, by providing all this information from the start. This will help us get to your problem immediately.","title":"Troubleshooting"},{"location":"docs/user-guide/troubleshoot/#how-to-submit-a-support-request","text":"Google it first! When encountering issues with software, if the misbehavior involves an error message, the first step should always be to look up the error message online. There's a good chance somebody stumbled upon the same hurdles before, and may even provide some fix or workaround. One of the most helpful Google searches is your_application sbatch . For example if you're having trouble submitting jobs or allocating resources (CPUs, time, memory) with Cell Ranger, search for cellranger sbatch to see how others have successfully run your application on a cluster. If you're facing issues you can't figure out, we're here to help. Feel free to email us at srcc-support@stanford.edu , but please keep the following points in mind to ensure a timely and relevant response to your support requests. Please provide relevant information We need to understand the issue you're facing, and in most cases, we need to be able to reproduce it , so it could be diagnosed and addressed. Please make sure to provide enough information so we could help you in the best possible way. This typically involves providing the following information: your SUNet ID, some context about your problem (were you submitting a job, copying a file, compiling an application?), if relevant, the full path to the files involved in your question or problem, the name of node where you received the error (usually displayed in your command-line prompt), the command(s) you ran, and/or the job submission script(s) you used, the relevant job ID(s), the exact , entire error message (or trace) you received. Error messages are critical This is very important. Without proper error messages, there is nothing we can do to help. And \" it doesn't work \" is not a proper error message. You can avoid email back and forth where we ask for all the relevant details, and thus delay the problem resolution, by providing all this information from the start. This will help us get to your problem immediately.","title":"How to submit a support request"}]}